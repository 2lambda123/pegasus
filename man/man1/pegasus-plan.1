.\"  Copyright 2010-2011 University Of Southern California
.\"
.\" Licensed under the Apache License, Version 2.0 (the "License");
.\" you may not use this file except in compliance with the License.
.\" You may obtain a copy of the License at
.\"
.\"  http://www.apache.org/licenses/LICENSE-2.0
.\"
.\"  Unless required by applicable law or agreed to in writing,
.\"  software distributed under the License is distributed on an "AS IS" BASIS,
.\"  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
.\"  See the License for the specific language governing permissions and
.\" limitations under the License.
.\"
.\"
.\" $Id$
.\"
.\" Authors: Karan Vahi, Gaurang Mehta
.\"
.TH "pegasus-plan" "1" "3.0.3" "PEGASUS Workflow Planner"
.SH NAME
pegasus-plan \- runs Pegasus to generate the executable workflow
.SH SYNOPSIS
.B pegasus\-plan
\-h|\-\-help
.PP
.B pegasus\-plan
\-V|\-\-version
.PP
.B pegasus\-plan
[\-Dprop [..]]  \-d <dax file> [\-b prefix] [\--conf <path to properties file>]
[\-c f1[,f2[..]]] [\-C <clustering technique>] [\-D <base directory for o/p files>]
[\-f] [ --inherited-rc-files] [\-j job-prefix] [\-n] [\-o <output site>]
[\-r[directoryname]] [\--relative-dir <relative directory to base directory>]
[\--relative-submit-dir <relative submit directory to the base directory>]
[\-s site1[,site2[..]]] [\-v] [\-q] [\-V] [\-h]   
.SH DESCRIPTION
The 
.B pegasus-plan
command takes in as input the DAX and generates an executable workflow
usually in form of 
.B condor
submit files, which 
can be submitted to an 
.I execution
site for execution.

.PP
As part of generating an executable workflow, the planner needs to discover
.TP
.B data
The Pegasus Workflow Planner ensures that all the data required for the execution
of the executable workflow is transferred to the execution site by adding transfer
nodes at appropriate points in the DAG. This is done by looking up an appropriate
.B Replica Catalog 
to determine the locations of the input files for the various jobs.
At present the default replica mechanism used is RLS . 
.IP
The Pegasus Workflow Planner also tries to reduce the workflow, unless specified 
otherwise. This is done by deleting the jobs whose output files have been found
in some location in the Replica Catalog . At present no cost metrics are used.
However preference is given to a location corresponding to the execution site
.IP
The planner can also add nodes to transfer all the materialized files to an output site.
The location on the output site is determined by looking up the site catalog file,
the path to which is picked up from the 
.B pegasus.catalog.site.file
property value.
.TP
.B executables
.IP
The planner looks up a Transformation Catalog to discover locations of the executables
referred to in the executable workflow. Users can specify INSTALLED or STAGEABLE
executables in the catalog. Stageable executables can be used by Pegasus to stage 
executables to resources where they are not pre-installed.
.TP
.B resources
.IP
The layout of the sites , where Pegasus can schedule jobs of a workflow are described 
in the Site Catalog. The planner looks up the site catalog to determine for a site what 
directories a job can be executed in, what servers to use for staging in and out data and
what jobmanagers ( if applicable) can be used for submitting jobs.
.P
The data and executable locations can now be specified in DAX'es conforming to DAX schema 
version 3.2 or higher.
.SH ARGUMENTS
Any option will be displayed with its long options synonym(s).
.TP
.B \-Dprop
The -D options allows an experienced user to override certain
properties which influence the program execution, among them the
default location of the user's properties file and the PEGASUS home location. 
One may set several CLI properties by giving this option multiple times.
.I The -D option(s) must be the first option on the command line. 
A CLI property take precedence over the properties file property 
of the same key.
.TP
.B \-d \fIfilename
.PD 0
.TP
.PD 1
.B \-\-dax \fIfilename
The DAX is the XML input file that describles an
.B abstract 
workflow.
.IP
This is a mandatory option, which has to be used.
.TP
.B \-b \fIprefix
.PD 0
.TP
.PD 1
.B \-\-basename \fIprefix
The basename prefix to be used while constructing per workflow files
like the dagman file (.dag file) and other workflow specific files
that are created by Condor. Usually this prefix, is taken from the
name attribute specified in the root element of the dax files.
.TP
.B \-c \fIlist of cache files
.PD 0
.TP
.PD 1
.B \-\-cache \fIlist of cache files
A comma separated list of paths to replica cache files that override
the results from the replica catalog for a particular lfn.
.IP 
Each entry in the cache file describes a LFN , the corresponding PFN and
the associated attributes. The pool attribute should be specified for
each entry.
.nf
\f(CB
LFN_1 PFN_1 pool=[site handle 1] 
LFN_2 PFN_2 pool=[site handle 2]
 ...
LFN_N PFN_N [site handle N]
\fP
.fi
.IP
To treat the cache files as supplemental replica catalogs set the
property 
.I pegasus.catalog.replica.cache.asrc 
to true. This results in the mapping in the cache files to be merged
with the mappings in the replica catalog. Thus, for a particular lfn
both the entries in the cache file and replica catalog are available
for replica selection.

.TP
.B \-C \fI comma separated list of clustering styles.
.PD 0
.TP
.PD 1
.B \-\-cluster \fI comma separated list of clustering styles.
This mode of operation results in clustering of n compute jobs into a
larger jobs to reduce remote scheduling overhead. You can specify a
list of clustering techniques to recursively apply them to the
workflow. For example, this allows you to cluster some jobs in the
workflow using horizontal clustering and then use label based
clustering on the intermediate workflow to do vertical clustering.
.IP
The clustered jobs can be run at the remote site, either sequentially
or by using mpi. This can be specified by setting the property
.I pegasus.job.aggregator.
The property can be overriden by associating the PEGASUS profile key
.I collapser
either with athe transformation in the transformation catalog or the
execution site in the site catalog. The value specified (to the
property or the profile), is the logical name of the transformation
that is to be used for clustering jobs. Note that clustering will only
happen if the corresponding transformations are catalogued in the
transformation catalog.
.IP
PEGASUS ships with a clustering executable
.I seqexec
that can be found in
.I $PEGASUS_HOME/bin
directory. It runs the jobs in the clustered job sequentially on the
same node at the remote site.
.IP
In addition, a mpi wrapper
.I mpiexec
is distributed as source with the PEGASUS. It can be found in
$PEGASUS_HOME/src/tools/cluster
directory. The wrapper is run on every mpi node, with the first one
being the master and the rest of the ones as workers. The number of
instances of mpiexec that are invoked is equal to the value of the
globus rsl key nodecount. The master distributes the smaller
constituent jobs to the workers. For e.g. If there were 10 jobs in the
clustered job and nodecount was 5, then one node acts as master, and
the
10 jobs are distributed amongst the 4 slaves on demand.  The master
hands off a job to the slave node as and when it gets free. So
initially all the 4 nodes are given a single job each, and then as and
when they get done are handed more jobs till all the 10 jobs have been
executed.
.IP
By default, seqexec is used for clustering jobs unless overridden
in the properties or by the pegasus profile key collapser.
.IP
The following type of clustering styles are currently supported
.TP
.B horizontal
is the style of clustering in which jobs on the same level are
aggregated into larger jobs. A level of the workflow is defined as the
greatest distance of a node, from the root of the workflow. Clustering
occurs only on jobs of the same type i.e they refer to the same
logical transformation in the transformation catalog. 
.IP
The granularity of clustering can be specified by associating either
the PEGASUS profile key 
.I clusters.size
or the PEGASUS profile key
.I clusters.num
with the transformation.
The clusters.size key indicates how many jobs need to be clustered into
the larger clustered job. The clusters.num key indicates how many clustered
jobs are to be created for a particular level at a particular
execution site. If both keys are specified for a particular
transformation, then the clusters.num key value is used to determine the
clustering granularity.
.TP
.B label
is the style of clustering in which you can label the jobs in your
workflow. The jobs with the same level are put in the same clustered
job. This allows you to aggregate jobs across levels, or in a manner
that is best suited to your application.
.IP
To label the workflow, you need to associate PEGASUS profiles with the
jobs in the DAX. The profile key to use for labelling the workflow can
be set by the property 
.I pegasus.clusterer.label.key.
It defaults to label, meaning if you have a PEGASUS profile key label
with jobs, the jobs with the same value for the pegasus profile key label
will go into the same clustered job. 

.TP
.B \-D \fIdir name
.PD 0
.TP
.PD 1
.B \--dir \fIdir name
The base directory where you want the output of the Pegasus Workflow
Planner usually condor submit files, to be generated. Pegasus creates
a directory structure in this base directory on the basis of username,
VO Group and the label of the workflow in the DAX.
.IP
By default the base directory is the directory from which one runs the
.B pegasus-plan
command.

.TP
.B \-f
.PD 0
.TP
.PD 1
.B \-\-force
This bypasses the reduction phase in which the abstract DAG is
reduced, on the basis of the locations of the output files returned by
the replica catalog. This is analogous to a 
.B make style
generation of the executable workflow.

.TP
.B \-g
.PD 0
.TP
.PD 1
.B \-\-group
The VO Group to which the user belongs to.

.TP
.B \-h
.PD 0
.TP
.PD 1
.B \-\-help
Displays all the options to the
.B pegasus-plan
command.

.TP
.PD 0
.B \--inherited-rc-files \fIcomma separated list of replica catalog files
A comma separated list of paths to replica files. Locations mentioned in these
have a lower priority than the locations in the DAX file. This option is usually
used internally for hierarichal workflows, where the file locations mentioned in 
the parent ( encompassing) workflow DAX, passed to the sub workflows ( corresponding)
to the dax jobs.

.TP
.B \-j
.PD 0
.TP
.PD 1
.B \-\-job-prefix
The job prefix to be applied for constructing the filenames for the
job submit files.


.TP
.B \-n 
.PD 0
.TP
.PD 1
.B \-\-nocleanup
.IP
This results in the generation of the separate cleanup workflow that
removes the directories created during the execution of the executable
workflow. The cleanup workflow is to be submitted after the executable
workflow has finished. 
If this option is not specified, then Pegasus adds cleanup nodes to
the executable workflow itself that cleanup files on the remote sites
when they are no longer required.

.TP
.B \-o \fIoutput site
.PD 0
.TP
.PD 1
.B \-\-o \fIoutput site
The
.B output
site where all the materialized data is transferred to.
.IP
By default the
.B materialized data
remains in the working directory on the
.B execution
site where it was created. Only those output files are transferred to
an
output site for which  transfer attribute is set to true in the DAX.

.TP
.B \-q
.PD 0
.TP
.PD 1
.B \-\-quiet
decreases the logging level.

.TP
.PD 0
.B \-r\fI[dirname]
.TP
.PD 1
.B \-\-randomdir\fI[=dirname]
Pegasus Worfklow Planner adds create directory jobs to the executable
workflow that create a directory in which all jobs for that workflow
execute on a particular site. The directory created is in the working
directory (specified in the site catalog with each site). 
.IP
By default, Pegasus duplicates the relative directory structure on the
submit host on the remote site. The user can specify this option
without arguments to create a random timestamp based name for the
execution directory that are created by the create dir jobs.
The user can can specify the optional argument to this option to
specify the basename of the directory that is to be created.
.IP
The create dir jobs refer to the 
.B dirmanager
executable that is shipped as part of the PEGASUS worker package. The
transformation catalog is searched for the transformation named
.B pegasus::dirmanager 
for all the remote sites where the workflow has been
scheduled. Pegasus can create a default path for the dirmanager
executable, if 
.B PEGASUS_HOME
environment variable is associated with the sites in the site catalog
as an environment profile.

.TP
.PD 0
.B \--relative-dir \fIdir name
The directory relative to the base directory where the executable
workflow it to be generated and executed. This overrides the default directory
structure that Pegasus creates based on username, VO Group and the DAX
label.

.TP
.PD 0
.B \--relative-submit-dir \fIdir name
The directory relative to the base directory where the executable
workflow it to be generated. This overrides the default directory
structure that Pegasus creates based on username, VO Group and the DAX
label. By specifying \--relative-dir and \--relative-submit-dir you
can have different relative execution directory on the remote site and
different relative submit directory on the submit host.

.TP
.B \-s \fIlist of execution sites
.PD 0
.TP
.PD 1
.B \-\-sites \fIlist of execution sites
A comma separated list of execution sites on which the workflow is to be
executed. Each of the sites should have an entry in the site catalog,
that is being used. To run on the submit host, specify the execution
site as 
.B local
.IP
In case this option is not specified, all the sites in the site
catalog are picked up as candidates for running the workflow.

.TP
.B \-s
.PD 0
.TP
.PD 1
.B \-\-submit
Submits the generated 
.B executable workflow
using 
.B pegasus-run
script in $PEGASUS_HOME/bin directory.
.IP
By default, the Pegasus Workflow Planner only generates the Condor submit
files and does not submit them. 

.TP
.B \-v
.PD 0
.TP
.PD 1
.B \-\-verbose
increases the verbosity of messages about what is going on.
.IP
By default, all FATAL, ERROR, CONSOLE and WARN messages are logged.
.IP
The logging hierarchy is as follows
.nf
\f(CB
FATAL 
ERROR 
CONSOLE 
WARN 
INFO 
CONFIG 
DEBUG 
TRACE 
\fP
.fi
.IP
For example, to see the INFO, CONFIG and DEBUG messages additionally, set 
.B \-vvv 
.

.TP
.B \-V
.PD 0
.TP
.PD 1
.B \-\-version
Displays the current version number of the  Pegasus Workflow Management System.
.SH "RETURN VALUE"
If the Pegasus Workflow Planner is able to generate an executable workflow successfully, the exitcode will be 0. All runtime errors result in an
exitcode of 1. This is usually in the case when you have misconfigured
your catalogs etc. In the case of an error occuring while loading a
specific module implementation at run time, the exitcode will be
2. This is usually due to factory methods failing while loading a
module.  In case of any other error occuring during the running of the
command, the exitcode will be 1. In most cases, the error message
logged should give a clear indication as to where things went wrong.
.SH "PEGASUS PROPERTIES"
This is not an exhaustive list of properties used. For the complete
description and list of properties refer to 
.B $PEGASUS_HOME/doc/advanced-properties.pdf
.TP
.B pegasus.selector.site
Identifies what type of site selector you want to use. If not
specified the default value of 
.B Random
is used. Other supported modes are 
.B RoundRobin
and 
.B NonJavaCallout
that calls out to a external site selector.
.TP
.B pegasus.catalog.replica
Specifies the type of replica catalog to be used. 
.IP
If not specified, then the value defaults to 
.B RLS
.
.TP
.B pegasus.catalog.replica.url
Contact string to access the replica catalog. In case of RLS it is the
RLI url.
.TP
.B pegasus.dir.exec
A suffix to the workdir in the site catalog to determine the current
working directory. If relative, the value will be appended to the
working directory from the site.config file. If absolute it
constitutes the  working directory.
.TP 
.B pegasus.catalog.transformation
Specifies the type of transformation catalog to be used. One can use either a
file based or a database based transformation catalog.  At present the
default is  
.B Text
.TP 
.B pegasus.catalog.transformation.file 
The location of file to use as transformation catalog.
.IP 
If not specified, then the default location of $PEGASUS_HOME/var/tc.data
is used.
.TP 
.B pegasus.catalog.site
Specifies the type of site catalog to be used. One can use either a
text based or an xml based site catalog.  At present the default is 
.B XML3
.TP
.B pegasus.catalog.site.file
The location of file to use as a site catalog.
If not specified, then default value of
$PEGASUS_HOME/etc/sites.xml is used in case of the xml based site catalog
and $PEGASUS_HOME/etc/sites.txt in case of the text based site catalog.
.TP
.B pegasus.code.generator 
The code generator to use. By default, Condor submit files are generated for
the executable workflow. Setting to 
.B Shell
results in Pegasus generating a shell script that can be executed on the 
submit host.
.SH FILES
.TP
.B $PEGASUS_HOME/etc/dax-3.2.xsd
is the suggested location of the latest DAX schema to produce DAX
output.
.TP
.B $PEGASUS_HOME/etc/sc-3.0.xsd
is the suggested location of the latest Site Catalog schema that is
used to create the XML3 version of the site catalog
.TP
.B $PEGASUS_HOME/etc/tc.data.text
is the suggested location for the file corresponding to the 
.I Transformation Catalog
.TP
.B $PEGASUS_HOME/etc/sites.xml3 | $PEGASUS_HOME/etc/sites.xml
is the suggested location for the file containing the site information.
.TP
.B $PEGASUS_HOME/lib/pegasus.jar
contains all compiled Java bytecode to run the Pegasus Workflow Planner.

.SH "SEE ALSO"
.BR pegasus-sc-client(1)
.BR pegasus-tc-client(1)
.BR pegasus-rc-client(1)
.SH RESTRICTIONS
Plenty. Read the user guide carefully.
.SH AUTHORS
Karan Vahi    <vahi at isi dot edu>
.br
Gaurang Mehta <gmehta at isi dot edu>
.PP
Pegasus Workflow Planner -
.B http://pegasus.isi.edu
