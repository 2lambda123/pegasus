.\" This file or a portion of this file is licensed under the terms of
.\" Globus Toolkit Public License, found at $VDS_HOME/GTPL or
.\" http://www.globus.org/toolkit/download/license.html.
.\" These notices must appear in redistibutions of this file
.\" or without modification.
.\" 
.\" Redistributions of this Software, with or without modification, must reproduce
.\" the GTPL in:
.\" (1) the Software, or
.\" (2) the Documentation or
.\" some other similar material which is provided with the Software (if any).
.\" 
.\" Copyright 1999-2004
.\" University of Chicago and The University of Southern California.
.\" All rights reserved.
.\" 
.\" Author: Gaurang Mehta gmehta@isi.edu
.\" 
.\" $REVISION$
.TH "gnemdag" "1" "October, 10th 2004" "Gaurang Mehta gmehta@isi.edu" ""
.SH "NAME"
\fBgenmdag\fR \- A client that partitions an abstract DAX into small daxs and generates a MegaDag.
.SH "SYNOPSIS"
\fBgenmdag\fR \-d <\fIdax file\fR> \-p <\fIexecution pools\fR> [\-o <\fIoutput pool\fR>]
.br 
        [\-e | [\-t <\fIBFS\fR | \fIOne2One\fR>] [\-m < \fIdag | noop | daglite\fR > ] ]
.br 
        [\-D <\fIdir for submit files\fR>]  [\-c <\fIcache files\fR>] [\-r[\fI=dir name\fR]]
.br 
        [\fI\-f\fR] [\fI\-a\fR] [\fI\-C\fR] [\fI\-v\fR] [\fI\-V\fR] [\fI\-h\fR] 
.SH "DESCRIPTION"
The \fBgenmdag\fR command is a client to invoke the Pegasus Deferred planning mode.
It takes in as input the DAX generated by the Abstract Planner of the VDS and partitions 
it according to the selected partition algorithm to generate partition daxes. 
The genmdag client then generates a \fBMEGADAG\fR of one of the three different types 
(\fIDAG, DAGLITE, NOOP\fR) in the form of condor submit files which can then be submitted to condor for execution.
.SH "MANDATORY OPTIONS"
.TP 
\fB\-d | \-\-dax\fR  \fIdax file\fR
The dax file containing the abstract dag , which has been generated in phase one , by the Abstract Planner.
.TP 
\fB\-p | \-\-pools\fR \fIlist of pools\fR
A comma separated list of pools on which the dag is to be executed.
.br 
The entry for the pools should be in the pool.config file.
.br 
If one wants to run the jobs on the CondorG only and not on a pool, then specify the execution pool as local.
.SH "OTHER OPTIONS"
.TP 
\fB\-e | \-\-euryale\fR
A deferred mode where each job is a partition in itself.
.br 
This option is used to auto set the patition type to \fIOne2One\fR and the megadag mode to \fIDaglite\fR.
.TP 
\fB\-t | \-\-type\fR \fIBFS | One2One\fR
The partitioning technique that is to be used for partitioning the dax into smaller daxes.
The default technique used is BFS. 
.br 
The type option cannot be used when using the \fIEuryale\fR option.
.IP 
\fBBFS\fR
.br 
Breadth First Search mode. The dax is partitioned based on a breadth first search and results in a level based partitioning.
.IP 
\fBOne2One\fR
.br 
One Job per partition mode. In this mode each job is partitioned to be its own partition and planning is done on a job by job basis.
.TP 
\fB\-m | \-\-megadag\fR \fIdag | noop | daglite\fR
The mode that is used for deferred/intime/late planning. At
present, there are 3 defferred modes incorporated. The dag approach
works with any partitioning scheme, whereas the noop and daglite
approach only work with a One2One partitioning mode, where each
job is considered as a separate partition.
.br 
The megadag option cannot be used when using the \fIEuryale\fR option.
.IP 
\fBDAG\fR
.br 
In this mode, the megadag that is created ends up running
a dagman for each of the partitions, created by the partitioner.
This approach should work well, in the scenario where there are
a fair number of jobs in the partition. A BFS/level based
partitioning should work well in this case. This is the default mode.
.IP 
\fBNOOP\fR
.br 
In this mode, only one instance of DAGMAN is run per workflow.
When generating the megadag, the single jobs in the partitions are
are expanded to a set of noop jobs(linear chain), that are
overwritten when Pegasus is run as the prescript to the first job
in the linear chain.
.IP 
\fBDAGLITE\fR
.br 
In this mode, only one instance of DAGMAN is run per workflow.
When generating the megadag, the single jobs in the partitions
are mapped to daglite jobs that take care of (stagein,compute,stageout,transfer) a.k.a VDS super node. 
The submit files for the stagein,compute,stageout and transfer are
generated when Pegasus is run as a prescript to the daglite job.
.TP 
\fB\-c | \-\-cache\fR \fIcache files\fR
A comma separated list of cache files that are to be used to specify
the locations of the transient files in case of deferred planning.
.TP 
\fB\-D | \-\-dir\fR \fIdirectory\fR
The directory in which you want the condor submit files,
and data to be generated. By default it is the directory
from which one runs the Concrete Planner
.TP 
\fB\-o | \-\-output\fR \fIoutput pool\fR
The output pool on which you want the materialized data
to be transferred to. The pool should be specified
in the pool.config file, and the location to which
it is transferred to is picked from the corresponding entry.
.TP 
\fB\-r | \-\-randomdir\fR\fI[=dir name]\fR
Creates a random directory on the execution pools, where
the jobs are executed. This is done by adding a create directory
job in the dag, before any compute jobs for that pool. The create
directory looks for a makedir transformation on the execution pool
in the transformation catalog. Please note that makedir is not
standard mkdir but a executable distributed with VDS.
The random directory is created in the exec mount points of the
execution pools, which are specified in the pool configuration file.
The name of the random directory is timestamp based to guarentee
uniqueness that can be overriden by the user by specifying the
optional argument to the option.
.TP 
\fB\-f | \-\-force\fR
To make a build dag, skips the Reduction Engine.
.TP 
\fB\-a | \-\-authenticate\fR
Authentication is performed against the remote jobmanagers
and the gridftp servers for the pools that are specified at runtime.
At present for the gridftp server no gsi authentication is done.
However, a check alive test is done by opening a socket to the
server. If for a particular jobmanager or a gridftp server
authentication is not successful, it is not used for scheduling
any jobs long as the underlying pool interface supports a soft
state removal.
.TP 
\fB\-v | \-\-verbose\fR
The messages displayed while running are more detailed. Should help in debugging.
.TP 
\fB\-V | \-\-version\fR
Displays the version number of the Griphyn Virtual Data System software.
.TP 
\fB\-h | \-\-help\fR
Generates this help.
.SH "PROPERTIES"
This is not an exhaustive list of properties used. For the complete
description and list of properties refer to
.br 
\fB$VDS_HOME/etc/sample.properties.\fR
.TP 
\fBvds.replica.mode\fR
Allows changing the Replica Mechanism backend implementation.
.br 
At present only one that corresponds to the Replica Location Service (\fIRLS\fR) is supported in this distribution.
.TP 
\fBvds.rls.url\fR
Contact string which points to a Replica Location Index (\fIRLI\fR).
.TP 
\fBvds.dir.exec\fR
A suffix to the Exec\-mount point to determine the current working
directory. If relative, the value will be appended to the working
directory from the pool.config file. If absolute it constitutes the 
working directory.
.TP 
\fBvds.tc.mode\fR
Allows changing the Transformation Catalog (TC)backend implementation.
.br 
Current supported implementations are Old File, New File and MySQL DB.
.TP 
\fBvds.tc.fi le\fR
The location of file to use as transformation catalog.
.TP 
\fBvds.pool.mode\fR
The mode of specifying the pool configuration file. It can either be
xml or single.
.br 
At present the default is \fBsingle\fR. The use of  \fBxml\fR mode is strongly advised , as it supports profiles and multiple
jobmanagers per pool per universe.
.TP 
\fBvds.pool.fi le\fR
The location of file that has the configurations for all known pools.
.SH "FILES"
.TP 
.B $VDS_HOME/etc/dax\-1.7.xsd
is the suggested location of the latest DAX schema to produce DAX
output.
.TP 
.B $VDS_HOME/var/tc.data
is the suggested location for the file corresponding to the Transformation Catalog
.TP 
.B $VDS_HOME/etc/properties
is the location to specify properties to change what Tranformation Catalog Implementation to use and the implementation related \fBPROPERTIES\fR.
.TP 
.B gvds.jar
contains all compiled Java bytecode to run the Griphyn Virtual Data System.
.SH "ENVIRONMENT VARIABLES"
.TP 
\fB$VDS_HOME\fR 
Path to the VDS installation directory.
.TP 
\fB$JAVA_HOME
Path to the JAVA 1.4.x installation directory.
.TP 
\fB$CLASSPATH
The classpath should be set to contain all necessary VDS files for the execution environment.
To automatically add the \fICLASSPATH\fR to you environment, in the \fI$VDS_HOME\fR directory run the script \fIsource setup\-user\-env.csh\fR or \fIsource setup\-user\-env.sh\fR.
.SH "SEE ALSO"
gendax(1), gencdag(1)
.SH "AUTHORS"
Gaurang Mehta <gmehta at isi dot edu>,
.PP 
Pegasus
.B http://pegasus.isi.edu
.br 
Chimera
.B http://www.griphyn.org/chimera/
.br 
GriPhyN
.BR http://www.griphyn.org/
