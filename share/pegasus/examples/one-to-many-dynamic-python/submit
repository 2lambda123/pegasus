#!/bin/bash

set -e


##################################################################################
#
#  Settings
#
CLUSTER_HOSTNAME="obelix.isi.edu"
CLUSTER_SCHEDULER="condor"
CLUSTER_WORK_DIR="/nfs/ccg3/scratch/gmehta"
CLUSTER_PEGASUS_HOME="/ccg/software/pegasus/dev/trunk"
CLUSTER_GLOBUS_LOCATION="/ccg/software/globus/default"
CLUSTER_SOFTWARE_LOCATION="/nfs/ccg3/scratch/gmehta/soft"
##################################################################################



TOPDIR=`pwd`

# figure out where Pegasus is installed
export PEGASUS_HOME=`which pegasus-plan | sed 's:/bin/pegasus-plan::'`
if [ "x$PEGASUS_HOME" = "x" ]; then
    echo "Unable to determine location of your Pegasus install"
    echo "Please make sure pegasus-plan is in your path"
    exit 1
fi 

if [ "x$GLOBUS_LOCATION" = "x" ]; then
    echo "Please set GLOBUS_LOCATION to the location of your Pegasus install"
    exit 1
fi 

# generate the input file
if [ -e input ]; then
    rm input
fi

for i in 1 2 3 4 5 6 7 8 9 10; do
    echo "This is sample input Line" $i >>input
done
# generate the dax
export PYTHONPATH=`pegasus-config --python`

export CLUSTER_SOFTWARE_LOCATION

./root-workflow.py $CLUSTER_PEGASUS_HOME >root-workflow.dax

# create the site catalog
cat >sites.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-3.0.xsd" version="3.0">
    <site handle="local" arch="x86_64" os="LINUX">
        <grid type="gt2" contact="localhost/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/>
        <head-fs>
            <scratch>
                <shared>
                    <file-server protocol="file" url="file://" mount-point="$TOPDIR/scratch"/>
                    <internal-mount-point mount-point="$TOPDIR/scratch" free-size="100G" total-size="30G"/>
                </shared>
            </scratch>
            <storage>
                <shared>
                    <file-server protocol="file" url="file://" mount-point="$TOPDIR/outputs"/>
                    <internal-mount-point mount-point="$TOPDIR/outputs" free-size="100G" total-size="30G"/>
                </shared>
            </storage>
        </head-fs>
        <replica-catalog  type="LRC" url="rlsn://dummyValue.url.edu" />
        <profile namespace="env" key="PEGASUS_HOME" >$PEGASUS_HOME</profile>
        <profile namespace="env" key="GLOBUS_LOCATION" >$GLOBUS_LOCATION</profile>
    </site>
    <site handle="TestCluster" arch="x86_64" os="LINUX">
        <grid type="gt2" contact="$CLUSTER_HOSTNAME/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/>
        <grid type="gt2" contact="$CLUSTER_HOSTNAME/jobmanager-$CLUSTER_SCHEDULER" scheduler="unknown" jobtype="compute"/>
        <head-fs>
            <scratch>
                <shared>
                    <file-server protocol="gsiftp" url="gsiftp://$CLUSTER_HOSTNAME" mount-point="$CLUSTER_WORK_DIR"/>
                    <internal-mount-point mount-point="$CLUSTER_WORK_DIR"/>
                </shared>
            </scratch>
            <storage>
            </storage>
        </head-fs>
        <replica-catalog  type="LRC" url="rlsn://dummyValue.url.edu" />
        <profile namespace="env" key="PEGASUS_HOME" >$CLUSTER_PEGASUS_HOME</profile>
        <profile namespace="env" key="GLOBUS_LOCATION" >$CLUSTER_GLOBUS_LOCATION</profile>
    </site>
</sitecatalog>
EOF

# plan and submit the  workflow
pegasus-plan \
    --conf pegasusrc \
    --sites TestCluster,local \
    --dir work \
    --output local \
    --dax root-workflow.dax \
    --submit \
    --nocleanup \
    -v

