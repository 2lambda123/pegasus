#!/usr/bin/perl -w
# author Prasanth Thomas
# propose: Runs statistics tools on pegasus workflow execution

use strict; # Perl pragma to restrict unsafe constructs
use FileHandle; #  Supply object methods for filehandles
use Getopt::Long qw(:config no_ignore_case bundling); #  Extended processing of command line options
use Term::ANSIColor qw(:constants colored); # Color screen output using ANSI escape sequences
$Term::ANSIColor::AUTORESET = 1;
use Data::Dumper; # help debug
use File::Basename;
use File::Path qw(rmtree);
use File::Copy;
use File::Spec;
use File::Temp qw/ tempfile tempdir  /;
use Cwd;

# use local modules
use Work::Common;

my $MAX_LOG_FILE = 1000;
my $job_state_file_name = 'jobstate.log';
my ($log_dir) = undef;
my($keep) = undef;

$SIG{'INT'} = 'clean_exit';
END{
	remove_logs();
}

&main();


sub print_usage() {
	print "\n";
	print "Usage : pegasus-statistics <submit directory> \n";
	print GREEN "Optional :\n";
	print "\t -o|--output: write outputs in given directory\n";
	print "\t -m|--monitord: invokes pegasus-monitord before running pegasus-statistics\n";
	print "\t -c|--condor: specifies a pure condor run with no GRID_SUBMIT events\n";
	print "\t -k|--keep: keeps the logs of the pegasus-statistics run  \n";
	print "\t -h|--help: display this help message\n";
}

sub remove_logs(){
# purpose : removes logs if keep option is not set.
	if($log_dir){
		if(!$keep){
			rmtree($log_dir) or print "Unable to delete $log_dir . $! \n";
		}else{
			print "Logs are stored at $log_dir \n";
		}
	}
}

sub clean_exit(){
# purpose : makes a clean exit in case of interrupt event.
	exit(1);
}

sub main(){
	my ($help,$monitord, $condor)=(undef,undef,undef);
	my ($output_dir) =(undef);
	
	if(!GetOptions(
		"output|o=s"=>\$output_dir,
		"monitord|m"=>\$monitord,
		"condor|c"=>\$condor,
		"keep|k"=>\$keep,
		"help|h"=>\$help)){
			 print "Unable to parse the options .$!\n";
			 print_usage();
			 exit 1;
		}
		
		
	if ($help){
		print_usage();
		exit 0;
	}
	
	if(!$ARGV[0]){
		print "You need to provide submit directory. \n";
		print_usage();
		exit 1;
	}
	my ($submit_dir) = $ARGV[0];
	
	#sanity check first                                                                                                                            
	if( !defined $ENV{PEGASUS_HOME} ){
	    print STDERR "ERROR: PEGASUS_HOME is not set. Please source the setup-with-pegasus script.\n";
	    exit 1;
	}
	if($output_dir){
		$output_dir = File::Spec->rel2abs($output_dir);
	}
	my (%config) = slurp_braindb( $submit_dir ) or die "ERROR: open braindump.txt in directory $submit_dir: $!\n";
	my($dag_file_name , $jsd_file_path) =  ($config{'dag'} ,$config{'jsd'});
	
	if(!$dag_file_name){
			print STDERR "ERROR: Unable to find the dag file name in the braindump.txt file.\n";
			exit 1;
	}
	if(!$jsd_file_path){
			print STDERR "ERROR: Unable to find the jobstate file path in the braindump.txt file.\n";
			exit 1;
	}
	$log_dir = tempdir('pegasus_statistics_XXXXXX' , TMPDIR=> 1) or die "Unable to create temp directory. $!";
	if($monitord){
		my $job_state_backup = undef;
		my ($job_state_base_file)= File::Spec->catfile( $submit_dir, $job_state_file_name);
		if(-e "$job_state_base_file"){
			# Invoke only if jobstate.log is there
			$job_state_backup = setup_monitord($job_state_base_file);
		}
		my($dagman_out_file) = File::Spec->catfile( $submit_dir ,$dag_file_name .".dagman.out");
		my($monitord_status , $monitord_summary_msg)  = invoke_monitord($dagman_out_file,$jsd_file_path );
		if($monitord_status !=0 ){
			if($job_state_backup){
			# Revert back the jobstate file
				if(!move($job_state_backup ,$job_state_base_file)) {
					print STDERR "ERROR : Failed to create a revert back the jobstate file . $! \n";
				}
			}
			
			exit 1;
		}
		
	}
	
	if(!$output_dir){
		$output_dir =  File::Spec->catdir($submit_dir,"statistics");
		if (-d "$output_dir") {
			print STDERR "WARNING: Output directory $output_dir exists. Overwriting the contents ....\n";
			rmtree($output_dir) or die "Unable to delete $output_dir . $! \n";
		}
		mkdir ($output_dir) or die "Unable to create $output_dir . $! \n";
	}else{
		if (!(-d "$output_dir")) {
			print STDERR "WARNING: Output directory $output_dir doesn't exists. Creating the directory ....\n";
			mkdir ($output_dir) or die "Unable to create $output_dir . $! \n";
		}
	}
	
	my($dag_file_path) =  File::Spec->catfile("$submit_dir","$dag_file_name");
	my($workflow_statistics_status, $workflow_statistics_summary_msg) = print_workflow_statistics($submit_dir,$jsd_file_path,$dag_file_path,$condor);
	# Executing genstat command
	my($genstats_status ,$genstats_summary_msg) =run_genstats($dag_file_path ,$jsd_file_path,$output_dir ,$condor );
	## Executing genstats-breakdown command
	my($genstats_breakdown_status ,$genstats_breakdown_summary_msg) =run_genstats_breakdown($dag_file_path ,$submit_dir ,$output_dir ,$condor  );
	
	print "******************************************** SUMMARY ********************************************\n";
	print $workflow_statistics_summary_msg.$genstats_summary_msg.$genstats_breakdown_summary_msg;
	
	print "**************************************************************************************************\n";
	
	exit 0;
}


sub get_job_list($){
	# purpose : parses dag file to find all the jobs
	# returns : the job list
	my($dagPath) =@_;
	open(DAGIN, "$dagPath") || die "$dagPath not found\n";
	my @job_list;
	foreach my $line (<DAGIN>) {
        chomp($line);
        $line =~ s/\#.*//;
	    $line =~ s/^\s+//;
	    $line =~ s/\s+$//;
	    next unless length($line);
	    if ($line =~ '^JOB') {
	    	my @tokens = split(' ', $line);
            my $job = $tokens[1];
            push(@job_list,$job);
        }
    }
    
   return @job_list; 
}

sub get_task_count($){
	# purpose : parses the clustered job .in file to find the task count
	# returns : the number of tasks ,undef in case of error 
	my ($in_path) =@_;
	my $task_count =0;
	my @job_list;
	if(open(CLUSTERJOBIN,"$in_path")){
		foreach my $line (<CLUSTERJOBIN>) {
	        chomp($line);
	        $line =~ s/\#.*//;
		    $line =~ s/^\s+//;
		    $line =~ s/\s+$//;
		    next unless length($line);
		   	++$task_count;
	    }
	    
    }
    return $task_count ==0?undef:$task_count;
}

sub print_workflow_statistics($$$$){
	# purpose : determine workflow duration command
	# returns : status code and status message
	my($submit_dir,$jsd,$dag_file_path,$condor) =@_;
	my $foundStart = 0;
    my $globalStartTime = undef;
    my $globalEndTime = undef;
    my $status = 1;
    my $summary_msg ='';
    my %job_status_hash =();
    my %job_state_hoh = (); 
	open(JOBSTATE, "$jsd") || die "Unable to open $jsd .$!\n";
	foreach my $line (<JOBSTATE>) {
        if ($line =~ /INTERNAL/) {
            if ($line =~ /MONITORD_STARTED*/) {
            	my @tokens = split(' ', $line);
                if (!$foundStart) {
                    $foundStart = 1;
                    $globalStartTime = $tokens[0];
                }
            } else {
                if ($line =~ /MONITORD_FINISHED ([0-9])*/) {
                    if ($1 != 0) {
                        print STDOUT "Workflow execution failed/restarted.\n";
                    }
                    my @tokens = split(' ', $line);
                    $globalEndTime = $tokens[0];
                }
            }
        }else{
        	chomp($line);
            my @tokens = split(' ', $line);
            my $timestamp = $tokens[0];
            my $job = $tokens[1];
            my $event = $tokens[2];
            if($event eq 'SUBMIT') {
            	$job_status_hash{$job} = $event;
            }elsif($event eq 'JOB_SUCCESS'){
            	$job_status_hash{$job} = $event;
            }elsif($event eq 'JOB_FAILURE'){
            	$job_status_hash{$job} = $event;
            }
            $job_state_hoh{$job}{$event} = $timestamp;
        }
    }
    
    # Getting the job list
    my @job_list = get_job_list($dag_file_path);
    my $total_job_count = scalar(@job_list); # total jobs in the dag file 
    my $current_dir = getcwd();
    # Change the directory to submit directory
    chdir $submit_dir || die "Cannot chdir to $submit_dir\n";
    my ($total_wall_time ,$total_wall_time_status_msg) = (0, ' ');
    print STDOUT "******  calculating workflow execution wall time  ***** \n";
    print STDOUT "Please wait, this may take a few minutes ...\n";
    foreach my $job (@job_list) {
    	if($condor){
    		if(defined( $job_state_hoh{$job})){
    			if (defined($job_state_hoh{$job}{'JOB_TERMINATED'}) and defined($job_state_hoh{$job}{'EXECUTE'}) ){
    				$total_wall_time += $job_state_hoh{$job}{'JOB_TERMINATED'}  - $job_state_hoh{$job}{'EXECUTE'};
    			}elsif (defined($job_state_hoh{$job}{'JOB_TERMINATED'}) and defined($job_state_hoh{$job}{'SUBMIT'}) ){
    				$total_wall_time += $job_state_hoh{$job}{'JOB_TERMINATED'}  - $job_state_hoh{$job}{'SUBMIT'};
    			}else{
    				$total_wall_time = undef;
    				$total_wall_time_status_msg .= "Failed to find the runtime for the job '$job' \n";
    				last;
    			}
    		}else{
    			$total_wall_time = undef;
    			$total_wall_time_status_msg .= "Failed to find the runtime for the job '$job' \n";
    			last;
    		}
    	}else{
			my @grepLines = `grep -h '<invocation' $job.out* 2>&1`;
			my $job_kruntime = undef;
	        foreach my $line (@grepLines) {
				chomp($line);
				my $i1 = index($line, "duration=\"");
				$line = substr($line, $i1 + 10);
				my $i2 = index($line, "\"");
				$line= substr($line, 0, $i2);
				if ($line =~ /^[\.0-9]*$/) {
					$total_wall_time += $line;
					$job_kruntime = $line;
				}
			}
			# If kickstart files are missing, try to get it from the jobstate.log
			if(!$job_kruntime){
				if(defined( $job_state_hoh{$job})){
	    			if (defined($job_state_hoh{$job}{'JOB_TERMINATED'}) and defined($job_state_hoh{$job}{'EXECUTE'}) ){
	    				$total_wall_time += $job_state_hoh{$job}{'JOB_TERMINATED'}  - $job_state_hoh{$job}{'EXECUTE'};
	    			}elsif (defined($job_state_hoh{$job}{'JOB_TERMINATED'}) and defined($job_state_hoh{$job}{'SUBMIT'}) ){
	    				$total_wall_time += $job_state_hoh{$job}{'JOB_TERMINATED'}  - $job_state_hoh{$job}{'SUBMIT'};
	    			}else{
	    				$total_wall_time = undef;
	    				$total_wall_time_status_msg .= "Failed to find the runtime for the job '$job' \n";
	    				last;
	    			}
	    		}else{
	    			$total_wall_time = undef;
	    			$total_wall_time_status_msg .= "Failed to find the runtime for the job '$job' \n";
	    			last;
	    		}
			}
			
		}
	}
	if(!$total_wall_time){ 
    	print STDERR "WARNING: Unable to find the total execution wall time.$total_wall_time_status_msg ....\n";
    }
    print STDOUT "****** Finished calculating workflow execution wall time  ***** \n";
  	
  	#Finding total task count
  	my $total_task_count =0;
  	my $total_task_count_msg ='';
	print STDOUT "******  calculating total tasks  ***** \n";
    print STDOUT "Please wait, this may take a few minutes ...\n";
	my $task_count = 0; 
	foreach my $job (@job_list) {
		$job =~ s/^\s+//; 
		if($job =~ /^merge_/){
			my($in_file) = File::Spec->catfile( $submit_dir ,$job .".in");
			$task_count = get_task_count($in_file);
			if($task_count){
				$total_task_count += $task_count;
			}else{
				$total_task_count = undef;
				$total_task_count_msg = "Failed to find the task count for the job '$job' \n";
				
			}
		
		}else{
			++$total_task_count;
		}
	}
	if(!$total_task_count){ 
    	print STDERR "WARNING: Unable to find the total tasks .$total_task_count_msg ....\n";
    }
    print STDOUT "****** Finished calculating total tasks    ***** \n";
    # Revert back to the old directory
    chdir $current_dir || die "Cannot chdir to $current_dir\n";
    
    my $job_state_count = scalar(keys %job_status_hash); # total jobs that have been submitted as per the jobstate file
    my ($job_succeeded_count,$job_failed_count, $job_unknown_count,$job_unsubmitted_count) =(0,0,0,0);
    while (my($key, $value) = each(%job_status_hash)){
     	if($value eq 'JOB_SUCCESS') {
     		++$job_succeeded_count;
     	}elsif($value eq 'JOB_FAILURE') {
     		++$job_failed_count;
     	}elsif($value eq 'SUBMIT') {
     		++$job_unknown_count;
     	}
   }
   	 if($globalStartTime && $globalEndTime){
    	my $duration =($globalEndTime -$globalStartTime );
    	$summary_msg .= sprintf("%-30s % 12d \n", "Total workflow execution time      :",  $duration); 
    }else{
    	print STDERR "WARNING: Failed to find the workflow execution time ....\n";
    	$summary_msg .= "Failed to find the workflow execution time ....\n";
    }
    if($total_wall_time){
    	$summary_msg .= sprintf("%-30s % 12d \n", "Total workflow execution wall time :", $total_wall_time); 
    }else{
    	$summary_msg .= "Unable to find the total execution wall time.$total_wall_time_status_msg";
    }
   	$job_unsubmitted_count = $total_job_count - $job_state_count;
   	$summary_msg .= sprintf("%-30s % 12d \n","Total jobs                         :", $total_job_count );
   	 if($total_task_count){
    	$summary_msg .= sprintf("%-30s % 12d \n","Total tasks                        :", $total_task_count ); 
    }else{
    	$summary_msg .= "Unable to find the total tasks.$total_task_count_msg";
    }
   	$summary_msg .= sprintf("%-30s % 12d \n","# jobs succeeded                   :", $job_succeeded_count );
   	$summary_msg .= sprintf("%-30s % 12d \n","# jobs failed                      :", $job_failed_count );
   	$summary_msg .= sprintf("%-30s % 12d \n","# jobs unsubmitted                 :",$job_unsubmitted_count );
   	$summary_msg .= sprintf("%-30s % 12d \n","# jobs unknown                     :", $job_unknown_count);
   	
   	return ($status,$summary_msg );
}




sub invoke_monitord($$){
# purpose : executing pegasus-monitord command
# returns : status code and status message

	my($dagman_out_file,$job_state_file) = @_;
	my(@args);
	my $summary_msg;
	print STDOUT "******  pegasus-monitord  ***** \n";
	# Adding arguments
	push(@args ,"-j ".$job_state_file); # adding color option
	push(@args ,"$dagman_out_file"); #/adding show-jobnames option
	
	# create pegasus-monitord command
	my (@pegasus_monitord_directory_path) = ("$ENV{PEGASUS_HOME}","bin");
	my ($pegasus_monitord_path) =  File::Spec->catfile( @pegasus_monitord_directory_path, 'pegasus-monitord');
	my ($pegasus_monitord_command) = "$pegasus_monitord_path ".join(" ",@args);
	
	
	print STDOUT "Executing command :-\n$pegasus_monitord_command \n";
	my($status,$exec_msg) = execute_command($pegasus_monitord_command,'pegasus-monitord');
	if($status == 0  ){
		print STDOUT "****** Finished executing pegasus-monitord  ***** \n";
		$summary_msg = "Finished executing pegasus-monitord\n";		
	}else{
		print STDERR "ERROR : Failed to execute pegasus-monitord command . $exec_msg\n";
		$summary_msg ="ERROR : Failed to execute pegasus-monitord  . $exec_msg\n";
	}
	return ($status, $summary_msg);
	
}


sub setup_monitord($){
	#purpose : makes set up for pegasus-monitord command, by creating a backup of jobstate.log file
	#returns : job state backup file path
	my ($job_state_base_file) =@_;
	my ($count) =0;
	my ($job_state_tmp_file);
	while($count < $MAX_LOG_FILE){
		if($count <10){
			$job_state_tmp_file = $job_state_base_file.".00".$count;
		}elsif($count <100){
			$job_state_tmp_file = $job_state_base_file.".0".$count;
		}else{
			$job_state_tmp_file = $job_state_base_file.".".$count;
		}
		if(-e "$job_state_tmp_file"){
			$count++;
		}else{
			if(!move($job_state_base_file,$job_state_tmp_file)) {
				print STDERR "ERROR : Failed to create a backup of jobstate file  $job_state_base_file . $! \n";
				exit 1;
			}
			return $job_state_tmp_file;
		}	
	}
	print STDERR "ERROR : Failed to create a backup of jobstate file  $job_state_base_file . Exceeded the rotation limit. \n";
	exit 1;
}


sub run_genstats($$$$){
# purpose : executing genstats command
# returns : status code and status message
	my(  $dag_file_path , $jobstate_log, $output_dir ,$condor )=(@_);
	my(@args);
	my $summary_msg;
	print STDOUT "******  genstats *****  \n";
	#Adding arguments
	push(@args ,"--dag ".$dag_file_path); # adding dag file argument
	push(@args ,"--output ".$output_dir); #/adding output dir argument
	push(@args ,"--jobstate-log ".$jobstate_log); # adding job state argument	
	if($condor){
		push(@args ,"--condor"); #adding pure condor run argument
	}
	# creating genstats command 
	my (@genstats_directory_path) = ("$ENV{PEGASUS_HOME}","libexec","statistics" );
	my ($genstats_path) =  File::Spec->catfile( @genstats_directory_path, 'genstats');
	my ($genstats_command) = "$genstats_path ".join(" ",@args);
	
	print STDOUT "Executing command :-\n $genstats_command \n";
	print STDOUT "Please wait, this may take a few minutes ...\n";
	my($status,$exec_msg) = execute_command($genstats_command,'genstats');
	if($status == 0  ){
		my (@genstats_misc_files) =  (File::Spec->catfile($output_dir ,'dag'),File::Spec->catfile($output_dir ,'dax'),File::Spec->catfile($output_dir ,'files'));
		foreach my $file (@genstats_misc_files) {
	 		if (!unlink($file)) {
	    		print STDERR "WARNING : Failed to remove file . $file\n";
			}
		}
		
		my ($genstats_job_path) =  File::Spec->catfile($output_dir ,'jobs');
		my ($genstats_out_path) =  File::Spec->catfile($output_dir ,'out');
		print STDOUT "****** Finished executing genstats  ***** \n";
		print STDOUT "The genstats result is created at $output_dir \n************ \n";
		$summary_msg = "Workflow events with time starting with zero is created at $genstats_out_path\n";
		$summary_msg .= "Job statistics is created at $genstats_job_path\n";
	}else{
		print STDERR "ERROR : Failed to execute genstats command . $exec_msg\n";
		$summary_msg = "ERROR : Failed to create job statistics . $exec_msg\n";
	}
	return ($status,$summary_msg);
	
}

sub run_genstats_breakdown($$$$){
# purpose : executing genstats-breakdown command
# returns : status code and status message
	my ($dag_file_path , $submit_dir , $output_dir ,$condor )=(@_);
	my (@args);
	my ($submit_dirs) = $submit_dir;
	my (@sub_workflow_submit_dirs) = get_sub_workflow_list($dag_file_path);
	my ($number_of_elements) = scalar(@sub_workflow_submit_dirs);
	my $summary_msg;
	
	if($number_of_elements > 0){
		invoke_monitord_for_sub_workflow(@sub_workflow_submit_dirs);
		$submit_dirs .= " ".join(" ",@sub_workflow_submit_dirs);
	}
	my $submit_dirs_file =&create_submit_directories_file($submit_dirs);
    print STDOUT "******  genstats-breakdown *****  \n";
    my $output_file = 	File::Spec->catfile($output_dir ,"breakdown.txt");
	#Adding arguments
	push(@args ,"--output ".$output_file); #/adding output file argument
	if($condor){
		push(@args ,"--condor"); #adding pure condor run argument
	}
	push(@args ,"-f ".$submit_dirs_file); #adding submit directories
	
	# creating genstats-breakdown command 
	my (@genstats_breakdown_directory_path) = ("$ENV{PEGASUS_HOME}","libexec","statistics");
	my ($genstats_breakdown_path) =  File::Spec->catfile( @genstats_breakdown_directory_path, 'genstats-breakdown');
	my ($genstats_breakdown_command) = "$genstats_breakdown_path ".join(" ", @args);
	
	print STDOUT "Executing command :-\n $genstats_breakdown_command \n";
	print STDOUT "Please wait, this may take a few minutes ...\n";
	my($status,$exec_msg) = execute_command($genstats_breakdown_command, 'genstats_breakdown');
	if($status == 0  ){
		print STDOUT "****** Finished executing genstats-breakdown  ***** \n";
		print STDOUT "The genstats breakdown result is created at $output_file \n************ \n";
		$summary_msg = "Logical transformation statistics is created at $output_file\n";
	}else{
		print STDERR "ERROR:Failed to execute genstats-breakdown command . $exec_msg\n";
		$summary_msg ="ERROR:Failed to create logical transformations statistics. $exec_msg\n";
	}
	return ($status ,$summary_msg);
	
}

sub invoke_monitord_for_sub_workflow(@){
	# purpose : Invoke pegasus monitord for sub workflow
	
	my(@sub_workflow_submit_dirs) = @_;
	print STDOUT "******  invoking monitord for sub workflows *****  \n";
	print STDOUT "Please wait, this may take a few minutes ...\n";
	foreach my $submit_dir (@sub_workflow_submit_dirs) {
		my (%config) = slurp_braindb( $submit_dir ) or die "ERROR: open braindump.txt in directory $submit_dir: $!\n";
		my($dag_file_name , $jsd_file_path) =  ($config{'dag'} ,$config{'jsd'});
		if(!$dag_file_name){
				print STDERR "ERROR: Unable to find the dag file name in the braindump.txt file in $submit_dir.\n";
				exit 1;
		}
		if(!$jsd_file_path){
				print STDERR "ERROR: Unable to find the jobstate file path in the braindump.txt file in $submit_dir.\n";
				exit 1;
		}
		my $job_state_backup = undef;
		my ($job_state_base_file)= File::Spec->catfile( $submit_dir, $job_state_file_name);
		if(-e "$job_state_base_file"){
			# Invoke only if jobstate.log is there
			$job_state_backup = setup_monitord($job_state_base_file);
		}
		my($dagman_out_file) = File::Spec->catfile( $submit_dir ,$dag_file_name .".dagman.out");
		my($monitord_status , $monitord_summary_msg)  = invoke_monitord($dagman_out_file,$jsd_file_path );
		if($monitord_status !=0 ){
			if($job_state_backup){
			# Revert back the jobstate file
				if(!move($job_state_backup ,$job_state_base_file)) {
					print STDERR "ERROR : Failed to create a revert back the jobstate file . $! \n";
				}
			}
			
			exit 1;
		}
	}
	print STDOUT "****** Finished invoking monitord for sub workflows  ***** \n";
}

sub create_submit_directories_file($){
	# purpose : creates a file with all the submit directories path.
	#returns : file path
	my($submit_dirs) =@_;
	my ($out_fh,$out_fn) = tempfile("submit_directory_XXXX",SUFFIX => '.in',DIR =>$log_dir);
	
	open ($out_fh, ">$out_fn") or die "Unable to write to file $out_fn. $! \n";
	my @submit_directories_arr = split(' ',$submit_dirs);
	foreach my $submit_dir (@submit_directories_arr) {
		print $out_fh "$submit_dir\n";
	}
	close $out_fh; 
	return $out_fn;
}

sub get_sub_workflow_list($){
	# purpose : find the list of sub workflows from the dag file
	# returns : list of sub workflows
	my($root_dag_file_path) =(@_);
	my($job_name ,$submit_file_name);
	my(@sub_workflow_list) ;
	my (@dag_path_list);
	my $dag_file_path;
	my ($dagbase,$submit_dir ,$type ) ;
    my ($submit_file_path,$sub_wf_submit_dir);
    my($sub_wf_submit_file_name);
    my (%config);
    my($sub_dag_file_name);
    my ($sub_dag_file_path);
    my(@sub_workflow_submit_dirs);
	
	push(@dag_path_list,$root_dag_file_path);
	while(@dag_path_list){
		$dag_file_path = shift(@dag_path_list);
		@sub_workflow_list =();
		open CONFIG, "$dag_file_path" or die "Unable to open dag file: $dag_file_path . $! \n";
		# Getting sub workflows from dag file
		while (my $line = <CONFIG>) {
	    	chomp $line;
	    	$line =~ s/\#.*//;
	    	$line =~ s/^\s+//; 
	    	$line =~ s/^\s+//;
	    	next unless length($line);
	    	if( $line =~m/^JOB\s.*/i ){
	    		my @values = split(/\s+/, $line);
	    		$job_name =$values[1];
	    		$submit_file_name = $values[2];
	    		if($job_name  =~m/^pegasus-plan.*/i){
	  				push(@sub_workflow_list,$submit_file_name);
	  			}
	    	}
	    }
	    close CONFIG;
	 	
	 	($dagbase,$submit_dir ,$type) = fileparse( $dag_file_path  ,qr{\..*});
	 	foreach $sub_wf_submit_file_name (@sub_workflow_list){
	 		 $submit_file_path = File::Spec->catfile($submit_dir,$sub_wf_submit_file_name);
		     $sub_wf_submit_dir = &parse_submit_file($submit_file_path);
		     if($sub_wf_submit_dir){
		        %config = slurp_braindb( $sub_wf_submit_dir ) or die "ERROR: open braindump.txt in directory $sub_wf_submit_dir: $!\n";
	     	    $sub_dag_file_name = $config{'dag'};
	     	    push (@sub_workflow_submit_dirs ,$sub_wf_submit_dir);
	     		if($sub_dag_file_name){
	     			$sub_dag_file_path = File::Spec->catfile($sub_wf_submit_dir,$sub_dag_file_name);
	     			push(@dag_path_list,$sub_dag_file_path);
		     	}else{
		     		print STDERR "WARNING: Unable to find dag file name in the braindump file in $sub_wf_submit_dir.\n";
		     	}
		     }else{
		     	print "Skipping sub workflow $sub_wf_submit_file_name \n"
		     }
		     
		}   
	}
	return @sub_workflow_submit_dirs;
}

sub parse_submit_file($){
	# purpose : parses the submit file to find the 'initialdir' configuration value.
	# returns : 'initialdir' configuration value if present , undef otherwise
	
	my ($submit_file)=(@_);
	if(open CONFIG, "$submit_file"){ 
		for (<CONFIG>) {
	    	chomp;
	    	s/\#.*//;
	    	s/^\s+//;
	    	s/\s+$//;
	    	next unless length;
	    	my ($var, $val) = split(/\s*=\s*/, $_, 2);
	    	if ($var eq 'initialdir'){
	    		close(CONFIG);
				return $val;
			}
	    	
		}
		close(CONFIG);
		print STDERR "WARNING: Unable to find 'initialdir' configuration value in the submit file $submit_file.\n";
		return undef;
	}else{
		print STDERR "WARNING: Unable to open submit file: $submit_file . $! \n";
		return undef;
	}
	
}


sub  execute_command($$){
# purpose : executes command and returns the status and error message
	# returns : status and error message
	my ($command , $prefix)=(@_);
	my ($error_msg) = (undef);
	my ($out_fh,$out_fn) = tempfile($prefix."_XXXX",SUFFIX => '.out',DIR =>$log_dir);
	my ($err_fh,$err_fn) = tempfile($prefix."_XXXX",SUFFIX => '.err',DIR =>$log_dir);
	close($out_fh);
	close($err_fh);
	my($ret) = system("$command  1>$out_fn 2>$err_fn");
	if($ret != 0){
		$error_msg = $!;
	}
	return ($ret , $error_msg);
}

