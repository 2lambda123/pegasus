<?xml version="1.0"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
                      "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="monitoring_debugging_stats">
   <title>Monitoring, Debugging and Statistics </title>
   <section>
       <title>pegasus-status</title>
    <para>To monitor the execution of the workflow lets run the pegasus-status
    command as suggested by the output of the pegasus-run command above.</para>

    <programlisting>$ <emphasis>pegasus-status /nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0002</emphasis>


-- Submitter: smarty.isi.edu : &lt;128.9.72.26:53194&gt; : smarty.isi.edu
 ID      OWNER/NODENAME   SUBMITTED     RUN_TIME ST PRI SIZE CMD
22417.0   gmehta          7/11 18:13   0+00:03:58 R  0   9.8  condor_dagman -f -
22423.0    |-rc_tx_analy  7/11 18:16   0+00:00:54 R  2   0.0  kickstart -n pegas
22424.0    |-rc_tx_findr  7/11 18:16   0+00:00:00 I  2   0.0  kickstart -n pegas
22425.0    |-rc_tx_prepr  7/11 18:16   0+00:00:00 I  2   0.0  kickstart -n pegas</programlisting>

    <para>The above output shows that several jobs are running under the main
    DAGMan process. Keep a lookout to track whether a workflow is running or
    not. If you do not see any of your job in the output for sometime (say 30
    seconds), we know the workflow has finished. We need to wait, as there might
    be delay in CondorDAGMAN releasing the next job into the queue after a job
    has finished successfully.</para>

    <para>If output of pegasus-status is empty, then either your workflow
    has</para>

    <itemizedlist>
      <listitem>
        <para>successfully completed</para>
      </listitem>

      <listitem>
        <para>stopped midway due to non recoverable error.</para>
      </listitem>
    </itemizedlist>


   </section>
   <section>
       <title>pegasus-analyzer</title>
       <para>...</para>
   </section>
   <section>
       <title>pegasus-statistics</title>
       <para>pegasus-statistics generates workflow execution statistics. To generate statistics run the command as shown below.</para>
       <programlisting>$ <emphasis>pegasus-statistics /scratch/grid-setup/run0001/</emphasis>


...

******************************************** SUMMARY ********************************************
Total workflow execution time      :         1741 
Total workflow execution wall time :      276.963 
Total jobs                         :           17 
Total tasks                        :           17 
# jobs succeeded                   :           17 
# jobs failed                      :            0 
# jobs unsubmitted                 :            0 
# jobs unknown                     :            0 

Workflow execution statistics created at :
/scratch/grid-setup/run0001/statistics/workflow

Workflow events with time starting with zero is created at :
/scratch/grid-setup/run0001/statistics/out

Job statistics is created at : 
/scratch/grid-setup/run0001/statistics/jobs

Logical transformation statistics is created at :
/scratch/grid-setup/run0001/statistics/breakdown.txt
**************************************************************************************************</programlisting>       
   
   <para>By default the output gets generated to statistics folder inside the submit directory. pegasus-statistics generates the following statistics list and tables.</para>

    <para><emphasis role="bold">Workflow statistics table</emphasis></para>
    <para> Workflow statistics table contains information about the workflow run like total execution time, job's failed etc. A sample table is shown below. </para>
	<para><link linkend="???">/scratch/grid-setup/run0001</link></para>
    <table>
      <title>Table 3.1</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>Total workflow execution time</entry>

            <entry>1741</entry>
          </row>

          <row>
            <entry>Total workflow execution wall time</entry>

            <entry>276.963</entry>
          </row>

          <row>
            <entry>Total jobs</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry>Total tasks</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry># jobs succeeded</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry># jobs failed</entry>

            <entry>0</entry>
          </row>

          <row>
            <entry># jobs unsubmitted</entry>

            <entry>0</entry>
          </row>

          <row>
            <entry># jobs unknown</entry>

            <entry>0</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
    
    <para><link linkend="???">All</link></para>
    <table>
      <title>Table 3.2</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>Total workflow execution time</entry>

            <entry>1741</entry>
          </row>

          <row>
            <entry>Total workflow execution wall time</entry>

            <entry>276.963</entry>
          </row>

          <row>
            <entry>Total jobs</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry>Total tasks</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry># jobs succeeded</entry>

            <entry>17</entry>
          </row>

          <row>
            <entry># jobs failed</entry>

            <entry>0</entry>
          </row>

          <row>
            <entry># jobs unsubmitted</entry>

            <entry>0</entry>
          </row>

          <row>
            <entry># jobs unknown</entry>

            <entry>0</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para><emphasis role="bold">Job statistics table</emphasis></para>

    <para>Job statistics table contains the following details about the jobs
    in the workflow. A sample table is shown below.</para>

    <itemizedlist>
      <listitem>
        <para>Job - the name of the job</para>
      </listitem>

      <listitem>
        <para>Site - the site where the job ran</para>
      </listitem>

      <listitem>
        <para>Kickstart - the actual duration of the job in seconds on the
        remote compute node</para>
      </listitem>

      <listitem>
        <para>Post - the postscript time as reported by DAGMan</para>
      </listitem>

      <listitem>
        <para>DAGMan - the time between the last parent job  of a job completes and the job gets submitted</para>
      </listitem>

      <listitem>
        <para>CondorQTime - the time between submission by DAGMan and the
        remote Grid submission. It is an estimate of the time spent in the
        condor q on the submit node</para>
      </listitem>

      <listitem>
        <para>Resource - the time between the remote Grid submission and start
        of remote execution . It is an estimate of the time job spent in the
        remote queue</para>
      </listitem>

      <listitem>
        <para>Runtime - the time spent on the resource as seen by Condor
        DAGMan . Is always &gt;=kickstart</para>
      </listitem>

      <listitem>
        <para>CondorQLen - the number of outstanding jobs in the queue when
        this job was released</para>
      </listitem>

      <listitem>
        <para>Seqexec - the time taken for the completion of a clustered job</para>
      </listitem>

      <listitem>
        <para>Seqexec-Delay- the time difference between the time for the completion of a clustered job and sum of all the individual tasks kickstart time</para>
      </listitem>
    </itemizedlist>

	<table>
      <title>Table 3.3</title>

      <tgroup align="center" cols="11">
        <thead>
          <row>
            <entry align="center">Job</entry>

            <entry align="center">Site</entry>

            <entry align="center">Kickstart</entry>

            <entry align="center">Post</entry>

            <entry align="center">DAGMan</entry>

            <entry align="center">CondorQTime</entry>

            <entry align="center">Resource</entry>

            <entry align="center">Runtime</entry>

            <entry align="center">CondorQLen</entry>

            <entry align="center">Seqexec</entry>

            <entry align="center">Seqexec-Delay</entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>analyze_ID0000004</entry>

            <entry>ISIViz</entry>

            <entry>60.16</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>23.00</entry>

            <entry>145.00</entry>

            <entry>160.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_analyze_ID0000004</entry>

            <entry>ISIViz</entry>

            <entry>8.05</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>15.00</entry>

            <entry>20.00</entry>

            <entry>101.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_findrange_ID0000003</entry>

            <entry>ISIViz</entry>

            <entry>0.97</entry>

            <entry>5.00</entry>

            <entry>8.00</entry>

            <entry>10.00</entry>

            <entry>5.00</entry>

            <entry>110.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_preprocess_ID0000001</entry>

            <entry>ISIViz</entry>

            <entry>1.00</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>20.00</entry>

            <entry>0.00</entry>

            <entry>20.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_stage_out_local_ISIViz_0_0</entry>

            <entry>ISIViz</entry>

            <entry>0.99</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>20.00</entry>

            <entry>0.00</entry>

            <entry>150.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_stage_out_local_ISIViz_1_0</entry>

            <entry>ISIViz</entry>

            <entry>1.16</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>17.00</entry>

            <entry>5.00</entry>

            <entry>15.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>clean_up_stage_out_local_ISIViz_2_0</entry>

            <entry>ISIViz</entry>

            <entry>10.28</entry>

            <entry>6.00</entry>

            <entry>7.00</entry>

            <entry>15.00</entry>

            <entry>20.00</entry>

            <entry>100.00</entry>

            <entry>2</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>create_dir_diamond_0_ISIViz</entry>

            <entry>ISIViz</entry>

            <entry>0.33</entry>

            <entry>5.00</entry>

            <entry>14.00</entry>

            <entry>15.00</entry>

            <entry>0.00</entry>

            <entry>20.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>findrange_ID0000002</entry>

            <entry>ISIViz</entry>

            <entry>60.25</entry>

            <entry>6.00</entry>

            <entry>7.00</entry>

            <entry>21.00</entry>

            <entry>20.00</entry>

            <entry>290.00</entry>

            <entry>3</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>findrange_ID0000003</entry>

            <entry>ISIViz</entry>

            <entry>60.37</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>26.00</entry>

            <entry>25.00</entry>

            <entry>822.00</entry>

            <entry>2</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>preprocess_ID0000001</entry>

            <entry>ISIViz</entry>

            <entry>60.48</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>15.00</entry>

            <entry>20.00</entry>

            <entry>235.00</entry>

            <entry>1</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>register_ISIViz_2_0</entry>

            <entry>local</entry>

            <entry>3.58</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>5.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>stage_in_local_ISIViz_0</entry>

            <entry>local</entry>

            <entry>1.88</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>stage_out_local_ISIViz_0_0</entry>

            <entry>local</entry>

            <entry>1.82</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>5.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>stage_out_local_ISIViz_1_0</entry>

            <entry>local</entry>

            <entry>1.72</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>5.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>stage_out_local_ISIViz_1_1</entry>

            <entry>local</entry>

            <entry>2.15</entry>

            <entry>5.00</entry>

            <entry>6.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>

          <row>
            <entry>stage_out_local_ISIViz_2_0</entry>

            <entry>local</entry>

            <entry>1.76</entry>

            <entry>5.00</entry>

            <entry>7.00</entry>

            <entry>0.00</entry>

            <entry>0.00</entry>

            <entry>5.00</entry>

            <entry>0</entry>

            <entry>-</entry>

            <entry>-</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para><emphasis role="bold">Logical transformation statistics
    table</emphasis></para>
    <para> Logical transformation statistics table contains information about each type of transformation in the workflow. A sample table is shown below. </para>
	<para><link linkend="???">/scratch/grid-setup/run0001</link></para>
    <table>
      <title>Table 3.4</title>

      <tgroup align="center" cols="7">
        <thead>
          <row>
            <entry align="center">Transformation</entry>

            <entry align="center">Count</entry>

            <entry align="center">Mean</entry>

            <entry align="center">Variance</entry>

            <entry align="center">Min</entry>

            <entry align="center">Max</entry>

            <entry align="center">Total</entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>pegasus::dirmanager </entry>

            <entry>1</entry>

            <entry>0.33</entry>

            <entry>0.00</entry>

            <entry>0.33</entry>

            <entry>0.33</entry>

            <entry>0.33</entry>
          </row>

          <row>
            <entry>diamond::analyze:2.0</entry>

            <entry>1</entry>

            <entry>60.16</entry>

            <entry>0.00</entry>

            <entry>60.16</entry>

            <entry>60.16</entry>

            <entry>60.16</entry>
          </row>

          <row>
            <entry>diamond::findrange:2.0</entry>

            <entry>2</entry>

            <entry>60.31</entry>

            <entry>0.01</entry>

            <entry>60.25</entry>

            <entry>60.37</entry>

            <entry>120.62</entry>
          </row>

          <row>
            <entry>diamond::preprocess:2.0</entry>

            <entry>1</entry>

            <entry>60.48</entry>

            <entry>0.00</entry>

            <entry>60.48</entry>

            <entry>60.48</entry>

            <entry>60.48</entry>
          </row>

          <row>
            <entry>pegasus::cleanup</entry>

            <entry>6</entry>

            <entry>3.74</entry>

            <entry>18.15</entry>

            <entry>0.97</entry>

            <entry>10.28</entry>

            <entry>22.46</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
	<para><link linkend="???">All</link></para>
 	<table>
      <title>Table 3.5</title>

      <tgroup align="center" cols="7">
        <thead>
          <row>
            <entry align="center">Transformation</entry>

            <entry align="center">Count</entry>

            <entry align="center">Mean</entry>

            <entry align="center">Variance</entry>

            <entry align="center">Min</entry>

            <entry align="center">Max</entry>

            <entry align="center">Total</entry>
          </row>
        </thead>

        <tbody>
          <row>
            <entry>pegasus::dirmanager </entry>

            <entry>1</entry>

            <entry>0.33</entry>

            <entry>0.00</entry>

            <entry>0.33</entry>

            <entry>0.33</entry>

            <entry>0.33</entry>
          </row>

          <row>
            <entry>diamond::analyze:2.0</entry>

            <entry>1</entry>

            <entry>60.16</entry>

            <entry>0.00</entry>

            <entry>60.16</entry>

            <entry>60.16</entry>

            <entry>60.16</entry>
          </row>

          <row>
            <entry>diamond::findrange:2.0</entry>

            <entry>2</entry>

            <entry>60.31</entry>

            <entry>0.01</entry>

            <entry>60.25</entry>

            <entry>60.37</entry>

            <entry>120.62</entry>
          </row>

          <row>
            <entry>diamond::preprocess:2.0</entry>

            <entry>1</entry>

            <entry>60.48</entry>

            <entry>0.00</entry>

            <entry>60.48</entry>

            <entry>60.48</entry>

            <entry>60.48</entry>
          </row>

          <row>
            <entry>pegasus::cleanup</entry>

            <entry>6</entry>

            <entry>3.74</entry>

            <entry>18.15</entry>

            <entry>0.97</entry>

            <entry>10.28</entry>

            <entry>22.46</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
   
    <para><emphasis role="bold">Workflow events list</emphasis></para>
    <para>Workflow events list contains the events listed with time starting with zero. A sample list is shown below.</para>
    <programlisting>1287528335 INTERNAL *** MONITORD_STARTED ***
0 INTERNAL *** DAGMAN_STARTED 517.0 ***
14 create_dir_diamond_0_ISIViz SUBMIT 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz EXECUTE 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz GLOBUS_SUBMIT 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz GRID_SUBMIT 518.0 ISIViz - 1
49 create_dir_diamond_0_ISIViz JOB_TERMINATED 518.0 ISIViz - 1
....
1741 clean_up_stage_out_local_ISIViz_2_0 POST_SCRIPT_SUCCESS 0 ISIViz - 16
1741 clean_up_analyze_ID0000004 POST_SCRIPT_TERMINATED 534.0 ISIViz - 17
1741 clean_up_analyze_ID0000004 POST_SCRIPT_SUCCESS 0 ISIViz - 17
1741 INTERNAL *** DAGMAN_FINISHED 0 ***
1287530077 INTERNAL *** MONITORD_FINISHED 0 ***</programlisting>    
   </section>
   <section>
       <title>pegasus-plot</title>
       
       <para>pegasus-plot generates graphs and charts to
    	visualize workflow execution. To generate graphs and charts run the command as shown below.</para>
    	
    	<programlisting>$ <emphasis>pegasus-plot /scratch/grid-setup/run0001/</emphasis>


...

******************************************** SUMMARY ********************************************
The workflow execution Gantt chart is created at -
png format :- /scratch/grid-setup/run0001/graph/diamond-2.png 
eps format :- /scratch/grid-setup/run0001/graph/diamond-2.eps 

The host over time chart is created at -
png format :-/scratch/grid-setup/run0001/graph/diamond-host.png 
eps format :-/scratch/grid-setup/run0001/graph/diamond-host.eps

JPEG file corresponding to the dag is created at: 
/scratch/grid-setup/run0001/graph/diamond-dag.jpg 

JPEG file corresponding to the dax is created at: 
/scratch/grid-setup/run0001/graph/blackdiamond-dax.jpg 
**************************************************************************************************</programlisting>

	<para>By default the output gets generated to graph folder inside the submit directory. pegasus-plot generates the following graphs and charts.</para>
	 <para><emphasis role="bold">Gantt workflow execution chart</emphasis></para>
	 <para> Gantt chart of the workflow execution run. A sample chart is shown below. </para>
    <figure>
      <title>Figure 4.1</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/diamond-2.png" />
        </imageobject>
      </mediaobject>
    </figure>

    <para><emphasis role="bold">Host over time chart</emphasis></para>
    <para> Host over time chart of the workflow execution run. A sample chart is shown below. </para>
    <figure>
      <title>Figure 4.2</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/diamond-host.png" />
        </imageobject>
      </mediaobject>
    </figure>

    <para><emphasis role="bold">Dag Graph</emphasis></para>
    <para> Graph representation of the DAG file. A sample graph is shown below. </para>
    <figure>
      <title>Figure 4.3</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/diamond-dag.jpg" />
        </imageobject>
      </mediaobject>
    </figure>

    <para><emphasis role="bold">Dax Graph</emphasis></para>
    <para> Graph representation of the DAX file. A sample graph is shown below. </para>
    <figure>
      <title>Figure 4.4</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/blackdiamond-dax.jpg" />
        </imageobject>
      </mediaobject>
    </figure> 
   </section>
    <section>
    <title>pegasus-remove</title>

    <para>If you want to abort your workflow for any reason you can use the
    pegasus-remove command listed in the output of pegasus-run invocation or by
    specifiying the Dag directory for the workflow you want to terminate.</para>

    <programlisting>$ <emphasis>pegasus-remove /nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0001</emphasis></programlisting>

   </section>
   <section>
       <title>Files in work directory</title>
    <para>Another way to monitor the workflow is to check the jobstate.log file.
    This is the output file of the monitoring daemon that is parsing all the
    condor log files to determine the status of the jobs. It logs the events
    seen by Condor into a more readable form for us.</para>

    <programlisting>$ <emphasis>less jobstate.log</emphasis>

1184202818 INTERNAL *** DAGMAN_STARTED ***
1184202831 black-diamond_0_viz_cdir SUBMIT 22418.0 clus1 -
1184202846 black-diamond_0_viz_cdir EXECUTE 22418.0 clus1 -
1184202846 black-diamond_0_viz_cdir GLOBUS_SUBMIT 22418.0 clus1 -
1184202846 black-diamond_0_viz_cdir GRID_SUBMIT 22418.0 clus1 -
1184202977 black-diamond_0_viz_cdir JOB_TERMINATED 22418.0 clus1 -
1184202977 black-diamond_0_viz_cdir POST_SCRIPT_STARTED - clus1 -
1184202982 black-diamond_0_viz_cdir POST_SCRIPT_TERMINATED 22418.0 clus1 -
1184202982 black-diamond_0_viz_cdir POST_SCRIPT_SUCCESS - clus1 -

...
...

1184205172 new_rc_register_analyze_ID000004 POST_SCRIPT_SUCCESS - local -
1184205302 cln_analyze_ID000004 JOB_TERMINATED 22436.0 clus1 -
1184205302 cln_analyze_ID000004 POST_SCRIPT_STARTED - clus1 -
1184205307 cln_analyze_ID000004 POST_SCRIPT_TERMINATED 22436.0 clus1 -
1184205307 cln_analyze_ID000004 POST_SCRIPT_SUCCESS - clus1 -
1184205307 INTERNAL *** DAGMAN_FINISHED ***
1184205311 INTERNAL *** TAILSTATD_FINISHED 0 **</programlisting>

    <para>The above shows the create dir job being submitted and then executed
    on the grid. In addition it lists that job is being run on the grid site
    clus1 The various states of the job while it goes through submission to
    execution to postprocessing are in UPPERCASE.</para>

    <para>At the bottom of the output we see that DAGMAN and TAILSTATD have
    FINISHED and with and exit code of zero "0" which signifies that the
    workflow ran successfully. If there were any errors then the TAILSTATD would
    exit with a non zero exitcode and the failed jobs would have a job state of
    FAILURE next to it.</para>
    <para>If your workflow fails then you can look at the job name (second
    column in the output) which has failed and check the contents of the
    kickstart record output stored in the jobname.out.NNN file where NNN can be
    000 to 999 or the jobname.err file</para>

    <para>One can also monitor the status of the running workflow by looking at
    the output of the Condor DAGMan output file.</para>

    <programlisting>$ <emphasis>tail -f black-diamond-0.dag.dagman.out

7/11 18:52:27 Node new_rc_tx_analyze_ID000004_0 job proc (22435.0) completed suc
cessfully.
7/11 18:52:27 Node new_rc_tx_analyze_ID000004_0 job completed
7/11 18:52:27 Running POST script of Node new_rc_tx_analyze_ID000004_0...
7/11 18:52:27 Number of idle job procs: 0
7/11 18:52:27 Of 17 nodes total:
7/11 18:52:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
7/11 18:52:27   ===     ===      ===     ===     ===        ===      ===
7/11 18:52:27    14       0        0       1       0          2        0</emphasis></programlisting>

    <para>You will see lines like the one above scrolling by giving you
    statistics of home many jobs have been finished, failed, running or queued.
    It will also tell if you the workflow has finished if the DAGMan finishes
    and the name of any jobs that failed.</para>

    </section>
   <section>
       <title>Resubmitting failed workflows</title>
   
    <para>Pegasus will remove the DAGMan and all the jobs related to the DAGMan
    from the condor queue. A rescue DAG will be generated in case you want to
    resubmit the same workflow and continue execution from where it last
    stopped. A rescue DAG only skips jobs that have completely finished. It does
    not continue a partially running job unless the executable supports
    checkpointing.</para>

    <para>To resubmit an aborted or failed workflow with the same submit files
    and rescue Dag just rerun the pegasus-run command</para>

    <programlisting>$ <emphasis>pegasus-run -Dpegasus.user.properties=/nfs/asd2/gmehta/PEGASUS/dags\
/gmehta/pegasus/black-diamond/run0001/pegasus.61698.properties \
--nodatabase /nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0001
</emphasis></programlisting>

</section>
</chapter>

