<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="components">
  <title>Pegasus Components</title>
  
  <para>The Pegasus Workflow Management System consists of several main
  elements and components that work together to automate the processing of large scale workflows.</para>
  
  <itemizedlist>

   <listitem>DAX</listitem>

   <listitem>DAG</listitem>
   
   <listitem>Catalogs (Basics)</listitem>

   <listitem>Pegasus Mapper</listitem>

   <listitem>Condor DagMan</listitem>

   <listitem>Condor Schedd</listitem>
   
   <listitem>Submit Directory</listitem>

  </itemizedlist>

   <para>The Pegasus Workflow Management System also includes monitoring tools and features system recovery capabilities that make the system robust and efficient.</para>
   
   <itemizedlist>

   <listitem>Monitoring Tools</listitem>
   
   <listitem>Error Recovery Capability</listitem>
   
   </itemizedlist>

  <section>
      <title>DAX</title>   </section>


      <para>The DAX is a description of an abstract workflow in XML format that
      is used as the primary input into Pegasus. The DAX schema is described
       in <ulink
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.xsd">dax-3.2.xsd</ulink>
      The documentation of the schema and its elements can be found in <ulink
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.html">dax-3.2.html</ulink>. </para>
      
      <para>A DAX can be created by all users with the DAX generating API in
      Java, Perl, or Python format</para>
      
      <note>We highly recommend using the DAX API. </note>
      
      <para>Advanced users who can read XML schema definitions can generate a
      DAX directly from a script</para>

      <para>The sample workflow below incorporates some of the elementary graph
      structures used in all abstract workflows.</para>
      
       <itemizedlist>
        <listitem>
          <para><emphasis>fan-out</emphasis>, <emphasis>scatter</emphasis>,
          and <emphasis>diverge</emphasis> all describe the fact that multiple
          siblings are dependent on fewer parents.</para>

          <para>The example shows how the <emphasis> Job 2 and 3</emphasis> nodes
          depend on <emphasis>Job 1</emphasis> node.</para>
        </listitem>

        <listitem>
          <para><emphasis>fan-in</emphasis>, <emphasis>gather</emphasis>,
          <emphasis>join</emphasis>, and <emphasis>converge</emphasis>
          describe how multiple siblings are merged into fewer dependent child
          nodes.</para>

          <para>The example shows how the <emphasis>Job 4</emphasis> node
          depends on both <emphasis>Job 2 and Job 3</emphasis> nodes.</para>
        </listitem>
      </itemizedlist>

      <itemizedlist>
        <listitem>
          <para><emphasis>serial execution</emphasis> implies that nodes are
          dependent on one another, like pearls on a string.</para>
        </listitem>

        <listitem>
          <para><emphasis>parallel execution</emphasis> implies that nodes can
          be executed in parallel</para>

        </listitem>
      </itemizedlist>
      
        <para><figure id="components_blackdiamond">
          <title>Sample Workflow</title>

          <mediaobject>
            <imageobject>
              <imagedata align="center" fileref="images/DiamondWorkflow.png"
                         valign="middle" />
            </imageobject>
          </mediaobject>
        </figure></para>
       <para>The example diamond workflow consits of four nodes representing
      jobs, and are linked by six files.</para>

      <itemizedlist>
        <listitem>

          <para>Required input files must be registered with the Replica catalog in order for Pegasus to find it and integrate it
          into the workflow.</para>
          </listitem>
          
        <listitem>
          <para>Leaf files are a product or output of a workflow. Output files can be collected at a
          location.</para>
        </listitem>

        <listitem>
        <para>The remaining files all have lines leading to them and
          originating from them. These files are products of some job steps
          (lines leading to them), and consumed by other job steps (lines
          leading out of them). Often, these files represent intermediary
          results that can be cleaned.</para>
        </listitem>
      </itemizedlist>

      <para>There are two main ways of generating DAX's</para>

      <orderedlist>
        <listitem>
          <para>Using a DAX generating API in <link
          linkend="api-java">Java</link>, <link linkend="api-perl">Perl</link>
          or <link linkend="api-python">Python</link>.</para>

          <para><emphasis>Note</emphasis> This option is what we recommend.</para>
        </listitem>

        <listitem>
          <para>Generating XML directly from your script.</para>

          <para>This option should only be considered by advanced users who
          can also read XML schema definitions.</para>
        </listitem>
      </orderedlist>

      <para>One example for a DAX representing the example workflow can look
      like the following:</para>

      <programlisting>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!-- generated: 2010-11-22T22:55:08Z --&gt;
&lt;adag xmlns="http://pegasus.isi.edu/schema/DAX"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xsi:schemaLocation="http://pegasus.isi.edu/schema/DAX http://pegasus.isi.edu/schema/dax-3.2.xsd"
      version="3.2" name="diamond" index="0" count="1"&gt;
  &lt;!-- part 2: definition of all jobs (at least one) --&gt;
  &lt;job namespace="diamond" name="preprocess" version="2.0" id="ID000001"&gt;
    &lt;argument&gt;-a preprocess -T60 -i &lt;file name="f.a" /&gt; -o &lt;file name="f.b1" /&gt; &lt;file name="f.b2" /&gt;&lt;/argument&gt;
    &lt;uses name="f.b2" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.b1" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.a" link="input" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="findrange" version="2.0" id="ID000002"&gt;
    &lt;argument&gt;-a findrange -T60 -i &lt;file name="f.b1" /&gt; -o &lt;file name="f.c1" /&gt;&lt;/argument&gt;
    &lt;uses name="f.b1" link="input" register="false" transfer="false" /&gt;
    &lt;uses name="f.c1" link="output" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="findrange" version="2.0" id="ID000003"&gt;
    &lt;argument&gt;-a findrange -T60 -i &lt;file name="f.b2" /&gt; -o &lt;file name="f.c2" /&gt;&lt;/argument&gt;
    &lt;uses name="f.c2" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.b2" link="input" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="analyze" version="2.0" id="ID000004"&gt;
    &lt;argument&gt;-a analyze -T60 -i &lt;file name="f.c1" /&gt; &lt;file name="f.c2" /&gt; -o &lt;file name="f.d" /&gt;&lt;/argument&gt;
    &lt;uses name="f.c2" link="input" register="false" transfer="false" /&gt;
    &lt;uses name="f.d" link="output" register="false" transfer="true" /&gt;
    &lt;uses name="f.c1" link="input" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;!-- part 3: list of control-flow dependencies --&gt;
  &lt;child ref="ID000002"&gt;
    &lt;parent ref="ID000001" /&gt;
  &lt;/child&gt;
  &lt;child ref="ID000003"&gt;
    &lt;parent ref="ID000001" /&gt;
  &lt;/child&gt;
  &lt;child ref="ID000004"&gt;
    &lt;parent ref="ID000002" /&gt;
    &lt;parent ref="ID000003" /&gt;
  &lt;/child&gt;
&lt;/adag&gt;</programlisting>

      <para>The example workflow representation in form of a DAX requires
      external catalogs, such as transformation catalog (TC) to resolve the
      logical job names (such as diamond::preprocess:2.0), and a replica catalog
      (RC) to resolve the input file <filename>f.a</filename>. The above
      workflow defines the four jobs just like the example picture, and the
      files that flow between the jobs. The intermediary files are neither
      registered nor staged out, and can be considered transient. Only the
      final result file <filename>f.d</filename> is staged out.</para>
      
      <section>
      <title>DAG </title>
      
      <para>The DAG an executable (concrete) workflow that can be executed over a variety of resources. When the workflow tasks are mapped to multiple resources that do not share a
  file system, explicit nodes are added to the workflow for orchestrating data.
  transfer between the tasks.</para>
  
      <para>When you take the workflow DAX above, and plan it for a single
    remote grid execution, here a site with handle <emphasis>hpcc</emphasis>,
    and plan the workflow without clean-up nodes, the following concrete
    workflow is built:</para>

    <para><figure id="concepts-fig-dag">
        <title>Black Diamond DAG</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/concepts-diamond-dag.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

    <para>Planning augments the original abstract workflow with ancillary
    tasks to facility the proper execution of the workflow. These tasks
    include:</para>

    <itemizedlist>
      <listitem>
        <para>the creation of remote working directories. These directories
        typically have name that seeks to avoid conflicts with other
        simultaneously running similar workflows. Such tasks use a job prefix
        of <code>create_dir</code>. </para>
      </listitem>

      <listitem>
        <para>the stage-in of input files before any task which requires these
        files. Any file consumed by a task needs to be staged to the task, if
        it does not already exist on that site. Such tasks use a job prefix of
        <code>stage_in</code>.If multiple files from various sources need to
        be transferred, multiple stage-in jobs will be created. Additional
        advanced options permit to control the size and number of these jobs,
        and whether multiple compute tasks can share stage-in jobs. </para>
      </listitem>

      <listitem>
        <para>the original DAX job is concretized into a compute task in the
        DAG. Compute jobs are a concatination of the job's
        <emphasis>name</emphasis> and <emphasis>id</emphasis> attribute from
        the DAX file. </para>
      </listitem>

      <listitem>
        <para>the stage-out of data products to a collecting site. Data
        products with their <emphasis>transfer</emphasis> flag set to
        <literal>false</literal> will not be staged to the output site.
        However, they may still be eligible for staging to other, dependent
        tasks. Stage-out tasks use a job prefix of <code>stage_out</code>.
        </para>
      </listitem>

      <listitem>
        <para>If compute jobs run at different sites, an intermediary staging
        task with prefix <code>stage_inter</code> is inserted between the
        compute jobs in the workflow, ensuring that the data products of the
        parent are available to the child job. </para>
      </listitem>

      <listitem>
        <para>the registration of data products in a replica catalog. Data
        products with their <emphasis>register</emphasis> flag set to
        <literal>false</literal> will not be registered.</para>
      </listitem>

      <listitem>
        <para>the clean-up of transient files and working directories. These
        steps can be omitted with the <command>--no-cleanup</command> option
        to the planner.</para>
      </listitem>
    </itemizedlist>

    <para><link linkend="advanced_concepts_transfers">Chapter "Advanced
    Concepts: Transfers"</link> will talk more about when and how staging
    nodes are inserted into the workflow. </para>

    <para>The DAG will be found in file <filename>diamond-0.dag</filename>,
    constructed from the <emphasis>name</emphasis> and
    <emphasis>index</emphasis> attributes found in the root element of the DAX
    file.</para>

    <programlisting>######################################################################
# PEGASUS WMS GENERATED DAG FILE
# DAG diamond
# Index = 0, Count = 1
######################################################################

JOB create_dir_diamond_0_hpcc create_dir_diamond_0_hpcc.sub
SCRIPT POST create_dir_diamond_0_hpcc /opt/pegasus/default/bin/pegasus-exitcode create_dir_diamond_0_hpcc.out

JOB stage_in_local_hpcc_0 stage_in_local_hpcc_0.sub
SCRIPT POST stage_in_local_hpcc_0 /opt/pegasus/default/bin/pegasus-exitcode stage_in_local_hpcc_0.out

JOB preprocess_ID000001 preprocess_ID000001.sub
SCRIPT POST preprocess_ID000001 /opt/pegasus/default/bin/pegasus-exitcode preprocess_ID000001.out

JOB findrange_ID000002 findrange_ID000002.sub
SCRIPT POST findrange_ID000002 /opt/pegasus/default/bin/pegasus-exitcode findrange_ID000002.out

JOB findrange_ID000003 findrange_ID000003.sub
SCRIPT POST findrange_ID000003 /opt/pegasus/default/bin/pegasus-exitcode findrange_ID000003.out

JOB analyze_ID000004 analyze_ID000004.sub
SCRIPT POST analyze_ID000004 /opt/pegasus/default/bin/pegasus-exitcode analyze_ID000004.out

JOB stage_out_local_hpcc_2_0 stage_out_local_hpcc_2_0.sub
SCRIPT POST stage_out_local_hpcc_2_0 /opt/pegasus/default/bin/pegasus-exitcode stage_out_local_hpcc_2_0.out

PARENT findrange_ID000002 CHILD analyze_ID000004
PARENT findrange_ID000003 CHILD analyze_ID000004
PARENT preprocess_ID000001 CHILD findrange_ID000002
PARENT preprocess_ID000001 CHILD findrange_ID000003
PARENT analyze_ID000004 CHILD stage_out_local_hpcc_2_0
PARENT stage_in_local_hpcc_0 CHILD preprocess_ID000001
PARENT create_dir_diamond_0_hpcc CHILD findrange_ID000002
PARENT create_dir_diamond_0_hpcc CHILD findrange_ID000003
PARENT create_dir_diamond_0_hpcc CHILD preprocess_ID000001
PARENT create_dir_diamond_0_hpcc CHILD analyze_ID000004
PARENT create_dir_diamond_0_hpcc CHILD stage_in_local_hpcc_0
######################################################################
# End of DAG
######################################################################
</programlisting>

    <para>The DAG file declares all jobs and links them to a Condor submit
    file that describes the planned, concrete job. In the same directory as
    the DAG file are all Condor submit files for the jobs from the picture
    plus a number of additional helper files.</para>

    <para>The various instructions that can be put into a DAG file are
    described in <ulink
    url="http://www.cs.wisc.edu/condor/manual/v7.5/2_10DAGMan_Applications.html">Condor's
    DAGMAN documentation</ulink>.The constituents of the submit directory are
    shown in <link linkend="submit_directory-layout">chapter "submit
    directory"</link>.</para>

      </section>
      
      
  <section>
      <title>Catalogs </title>
  </section>
      
      <para>Catalogs contain generated files that Pegasus uses to execute workflows.</para>
      
      <para> There are three catalogs in the Pegasus WMS:</para>
      
   <section>
         <title>Replica</title>
           <section id="replica">
           <title>Replica</title>

           <para>The Replica Catalog keeps mappings of logical file ids/names (LFN's)
    to physical file ids/names (PFN's). A single LFN can map to several PFN's.
    A PFN consists of a URL with protocol, host and port information and a
    path to a file. Along with the PFN one can also store additional key/value
    attributes to be associated with a PFN.</para>

               <para>Pegasus supports 4 different implemenations of the Replica
    Catalog.</para>

     <orderedlist>
      <listitem>
        <para>File <emphasis role="bold">(Default)</emphasis></para>
      </listitem>

      <listitem>
        <para>Database via JDBC</para>
      </listitem>

      <listitem>
        <para>Replica Location Service</para>

        <itemizedlist>
          <listitem>
            <para>RLS</para>
          </listitem>

          <listitem>
            <para>LRC</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>MRC</para>
      </listitem>
    </orderedlist>

       <section id="rc-FILE">
        <title>File</title>

        <para>In this mode, Pegasus queries a file based replica catalog. The
      file format is a simple multicolumn format. It is neither
      transactionally safe, nor advised to use for production purposes in any
      way. Multiple concurrent instances will clobber each other. The site
      attribute should be specified whenever possible. The attribute key for
      the site attribute is <emphasis role="bold">"pool".</emphasis></para>

      <programlisting>
LFN PFN
LFN PFN a=b [..]
LFN PFN a="b" [..]
"LFN w/LWS" "PFN w/LWS" [..]
      </programlisting>

      <para>The LFN may or may not be quoted. If it contains linear
      whitespace, quotes, backslash or an equality (equal?) sign, it must be quoted and
      escaped. The same conditions apply for the PFN. The attribute key-value pairs are separated
      by an equality sign without any whitespaces. The value may be in quoted.
      The LFN sentiments about quoting apply.</para>

      <para>The file mode is the Default mode. In order to use the File mode
      you have to set the following properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica=File</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica.file=<replaceable>&lt;path to
            the replica catalog file&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
       </section>

       <section id="rc-JDBCRC">
        <title>JDBCRC</title>

         <para>In this mode, Pegasus queries a SQL based replica catalog that is
      accessed via JDBC. The sql schema’s for this catalog can be found at
      <emphasis role="bold">$PEGASUS_HOME/sql</emphasis> directory. You will
      have to install the schema into either PostgreSQL or MySQL by running
      the appropriate commands to load the two scheams <emphasis
      role="bold">create-XX-init.sql</emphasis> and <emphasis
      role="bold">create-XX-rc.sql</emphasis> where XX is either <emphasis
      role="bold">my</emphasis> (for MySQL) or <emphasis
      role="bold">pg</emphasis> (for PostgreSQL)</para>

      <para>To use JDBCRC, the user additionally needs to set the following
      properties</para>

      <orderedlist>
        <listitem>
          <para><emphasis
          role="bold">pegasus.catalog.replica.db.url=<replaceable>&lt;jdbc url
          to the databse&gt;</replaceable></emphasis></para>
        </listitem>

        <listitem>
          <para><emphasis
          role="bold">pegasus.catalog.replica.db.user=<replaceable>&lt;database
          user&gt;</replaceable></emphasis></para>
        </listitem>

        <listitem>
          <para><emphasis
          role="bold">pegasus.catalog.replica.db.password=<replaceable>&lt;database
          password&gt;</replaceable></emphasis></para>
        </listitem>
      </orderedlist>
      </section>

       <section id="rc-RLS">
        <title>Replica Location Service</title>

         <para>RLS (Replica Location Service) is a distributed replica catalog,
      which ships with Globus. There is an index service called Replica
      Location Index (RLI) to which 1 or more Local Replica Catalog (LRC)
      report. Each LRC can contain all or a subset of mappings.</para>

      <para>Details about RLS can be found at <ulink
      url="http://www.globus.org/toolkit/data/rls/">http://www.globus.org/toolkit/data/rls/</ulink></para>

      <section>
        <title>RLS</title>

        <para>In this mode, Pegasus queries the central RLI to discover in
        which LRC’s the mappings for a LFN reside. It then queries the
        individual LRC’s for the PFN’s. To use this mode the following
        properties need to be set</para>

        <para><orderedlist>
            <listitem>
              <para><emphasis
              role="bold">pegasus.catalog.replica=RLS</emphasis></para>
            </listitem>

            <listitem>
              <para><emphasis
              role="bold">pegasus.catalog.replica.url=<replaceable>&lt;url to
              the globus LRC&gt;</replaceable></emphasis></para>
            </listitem>
          </orderedlist></para>
      </section>

      <section>
        <title>LRC</title>

        <para>This mode is availabe If the user does not want to query the RLI
        (Replica Location Index), but directly a single Local Replica Catalog.
        To use the LRC mode the follow properties need to be set</para>

        <para><orderedlist>
            <listitem>
              <para><emphasis
              role="bold">pegasus.catalog.replica=<replaceable>LRC</replaceable></emphasis></para>
            </listitem>

            <listitem>
              <para><emphasis
              role="bold">pegasus.catalog.replica.url=<replaceable>&lt;url to
              the globus LRC&gt;</replaceable></emphasis></para>
            </listitem>
          </orderedlist></para>

        <para>Details about Globus Replica Catalog and LRC can be found at
        <ulink
        url="http://www.globus.org/toolkit/data/rls/">http://www.globus.org/toolkit/data/rls/</ulink></para>
      </section>
    </section>

    <section id="rc-MRC">
      <title>MRC</title>

      <para>In this mode, Pegasus queries multiple replica catalogs to
      discover the file locations on the grid.</para>

      <para>To use it set</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica=<replaceable>MRC</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>

      <para>Each associated replica catalog can be configured via properties
      as follows.</para>

      <para>The user associates a variable name referred to as [value] for
      each of the catalogs, where [value] is any legal identifier (concretely
      [A-Za-z][_A-Za-z0-9]*) For each associated replica catalogs the user
      specifies the following properties</para>

      <itemizedlist>
        <listitem>
          <para><emphasis role="bold">pegasus.catalog.replica.mrc.[value]
          </emphasis>- specifies the type of replica catalog.</para>
        </listitem>

        <listitem>
          <para><emphasis role="bold">pegasus.catalog.replica.mrc.[value].key
          </emphasis>- specifies a property name key for a particular
          catalog</para>
        </listitem>
      </itemizedlist>

      <para>For example, if a user wants to query two lrc’s at the same time
      he/she can specify as follows</para>

      <para><itemizedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica.mrc.lrc1=LRC</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica.mrc.lrc1.url=<replaceable>&lt;url
            to the 1st globus LRC&gt;</replaceable></emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica.mrc.lrc2=LRC</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.replica.mrc.lrc2.url=</emphasis><emphasis
            role="bold">&lt;url to the 2nd globus LRC&gt;</emphasis></para>
          </listitem>
        </itemizedlist>In the above example, lrc1, lrc2 are any valid
      identifier names and url is the property key that needed to be
      specified.</para>
    </section>

    <section id="pegasus-rc-client">
      <title>Replica Catalog Client pegasus-rc-client</title>

      <para>The client used to interact with the Replica Catalogs is
      pegasus-rc-client. The implementation that the client talks to is
      configured using Pegasus properties.</para>

      <para>Lets assume we create a file f.a in your home directory as shown
      below.</para>

      <screen><command>$ date &gt; $HOME/f.a </command></screen>

      <para>We now need to register this file in the <emphasis
      role="bold">File</emphasis> replica catalog located in <emphasis
      role="bold">$HOME/rc</emphasis> using the pegasus-rc-client. Replace the
      <emphasis role="bold">gsiftp://url</emphasis> with the appropriate
      parameters for your grid site.</para>

      <screen><emphasis>$<command> rc-client -Dpegasus.catalog.replica=File -Dpegasus.catalog.replica.file=$HOME/rc insert \
 f.a</command> <replaceable>gsiftp://somehost:port/path/to/file/f.a pool=local</replaceable></emphasis></screen>

      <para>You may first want to check, if the file registeration made it
      into the replica catalog. Since we are using a File catalog we can just
      go look at the file $HOME/rc to see if there are any entries in
      there.</para>

      <screen><command>$ cat $HOME/rc</command><computeroutput>

# file-based replica catalog: 2010-11-10T17:52:53.405-07:00
f.a gsiftp://somehost:port/path/to/file/f.a pool=local</computeroutput></screen>

      <para>The above line shows that entry for file f.a was made
      correctly.</para>

      <para>You can also use the pegasus-rc-client to look for entries.</para>

      <screen><command>$ pegasus-rc-client -Dpegasus.catalog.replica=File -Dpegasus.catalog.replica.file=$HOME/rc lookup LFN f.a</command><computeroutput>

f.a gsiftp://somehost:port/path/to/file/f.a pool=local</computeroutput></screen>
    </section>
  </section>

  </section>
             

      <section id="site">
    <title>Site</title>

    <para>The Site Catalog describes the compute resources (which are often
    clusters) that we intend to run the workflow upon. A site is a homogeneous
    part of a cluster that has at least a single GRAM gatekeeper with a
    jobmanager-fork and jobmanager-&lt;scheduler&gt; interface and at least
    one gridftp server along with a shared file system. The GRAM gatekeeper
    can be either WS GRAM or Pre-WS GRAM. A site can also be a condor pool or
    glidein pool with a shared file system.</para>

    <para>Pegasus currently supports two implementation of the Site
    Catalog</para>

    <orderedlist>
      <listitem>
        <para>XML3 <emphasis role="bold">(Default)</emphasis></para>
      </listitem>

      <listitem>
        <para>XML <emphasis role="bold">(Deprecated)</emphasis></para>
      </listitem>

      <listitem>
        <para>File <emphasis role="bold">(Deprecated)</emphasis></para>
      </listitem>
    </orderedlist>

    <section id="sc-XML3">
      <title>XML3</title>

      <para>This is the default format for Pegasus 3.0. This format allows
      defining filesystem of shared as well as local type on the head node of
      the remote cluster as well as on the backend nodes</para>

      <figure>
        <title>Schema Image of the Site Catalog XML 3</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/sc-3.0_p2.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Below is an example of the XML3 site catalog</para>

      <programlisting>&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog
http://pegasus.isi.edu/schema/sc-3.0.xsd" version="3.0"&gt;
  &lt;site  handle="isi" arch="x86" os="LINUX" osrelease="" osversion="" glibc=""&gt;
      &lt;grid  type="gt2" contact="smarty.isi.edu/jobmanager-pbs" scheduler="PBS" jobtype="auxillary"/&gt;
      &lt;grid  type="gt2" contact="smarty.isi.edu/jobmanager-pbs" scheduler="PBS" jobtype="compute"/&gt;
          &lt;head-fs&gt;
               &lt;scratch&gt;
                  &lt;shared&gt;
                     &lt;file-server protocol="gsiftp" url="gsiftp://skynet-data.isi.edu"
                                  mount-point="/nfs/scratch01" /&gt;
                     &lt;internal-mount-point mount-point="/nfs/scratch01"/&gt;
                  &lt;/shared&gt;
               &lt;/scratch&gt;
               &lt;storage&gt;
                  &lt;shared&gt;
                     &lt;file-server protocol="gsiftp" url="gsiftp://skynet-data.isi.edu"
                                  mount-point="/exports/storage01"/&gt;
                     &lt;internal-mount-point mount-point="/exports/storage01"/&gt;
                  &lt;/shared&gt;
               &lt;/storage&gt;
          &lt;/head-fs&gt;
      &lt;replica-catalog  type="LRC" url="rlsn://smarty.isi.edu"/&gt;
      &lt;profile namespace="env" key="PEGASUS_HOME" &gt;/nfs/vdt/pegasus&lt;/profile&gt;
      &lt;profile namespace="env" key="GLOBUS_LOCATION" &gt;/vdt/globus&lt;/profile&gt;
  &lt;/site&gt;
&lt;/sitecatalog&gt;</programlisting>

      <para>Described below are some of the entries in the site
      catalog.</para>

      <para><orderedlist>
          <listitem>
            <para>site - A site identifier.</para>
          </listitem>

          <listitem>
            <para>replica-catalog - URL for a local replica catalog (LRC) to
            register your files in. Only used for RLS implementation of the
            RC. This is optional</para>
          </listitem>

          <listitem>
            <para>File Systems - Info about filesystems mounted on the remote
            clusters head node or worker nodes. It has several
            configurations</para>

            <itemizedlist>
              <listitem>
                <para>head-fs/scratch - This describe the scratch file systems
                (temporary for execution) available on the head node</para>
              </listitem>

              <listitem>
                <para>head-fs/storage - This describes the storage file
                systems (long term) available on the head node</para>
              </listitem>

              <listitem>
                <para>worker-fs/scratch - This describe the scratch file
                systems (temporary for execution) available on the worker
                node</para>
              </listitem>

              <listitem>
                <para>worker-fs/storage - This describes the storage file
                systems (long term) available on the worker node</para>
              </listitem>
            </itemizedlist>

            <para>Each scratch and storage entry can contain two sub
            entries,</para>

            <itemizedlist>
              <listitem>
                <para>SHARED for shared file systems like NFS, LUSTRE
                etc.</para>
              </listitem>

              <listitem>
                <para>LOCAL for local file systems (local to the
                node/machine)</para>
              </listitem>
            </itemizedlist>

            <para>Each of the filesystems are defined by used a file-server
            element. Protocol defines the protocol uses to access the files,
            URL defines the url prefix to obtain the files from and
            mount-point is the mount point exposed by the file server.</para>

            <para>Along with this an internal-mount-point needs to defined to
            access the files directly from the machine without any file
            servers.</para>
          </listitem>

          <listitem>
            <para>arch,os,osrelease,osversion, glibc - The
            arch/os/osrelease/osversion/glibc of the site. OSRELEASE,
            OSVERSION and GLIBC are optional</para>

            <para>ARCH can have one of the following values X86, X86_64,
            SPARCV7, SPARCV9, AIX, PPC.</para>

            <para>OS can have one of the following values LINUX,SUNOS,MACOSX.
            The default value for sysinfo if none specified is
            X86::LINUX</para>
          </listitem>

          <listitem>
            <para>Profiles - One or many profiles can be attached to a
            pool.</para>

            <para>One example is the environments to be set on a remote
            pool.</para>
          </listitem>
        </orderedlist></para>

      <para>To use this site catalog the follow properties need to be
      set</para>

      <orderedlist>
        <listitem>
          <para><emphasis
          role="bold">pegasus.catalog.site=XML3</emphasis></para>
        </listitem>

        <listitem>
          <para><emphasis
          role="bold">pegasus.catalog.site.file=<replaceable>&lt;path to the
          site catalog file&gt;</replaceable></emphasis></para>
        </listitem>
      </orderedlist>
    </section>

    <section id="sc-XML">
      <title>XML</title>

      <para><warning>
          <para>This format is now deprecated in favor of the XML3 format. If
          you are still using the XML or File format you should convert it to
          XML3 formation using the pegasus-sc-converter client</para>
        </warning></para>

      <para><programlisting>$ <emphasis>cat $HOME/sites.xml</emphasis>

&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
  xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog
  http://pegasus.isi.edu/schema/sc-2.0.xsd"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="2.0"&gt;
  &lt;site handle="local" gridlaunch="/nfs/vdt/pegasus/bin/kickstart"
   sysinfo="INTEL32::LINUX"&gt;
    &lt;profile namespace="env" key="PEGASUS_HOME" &gt;/nfs/vdt/pegasus&lt;/profile&gt;
    &lt;profile namespace="env" key="GLOBUS_LOCATION" &gt;/vdt/globus&lt;/profile&gt;
    &lt;profile namespace="env" key="LD_LIBRARY_PATH" &gt;/vdt/globus/lib&lt;/profile&gt;
    &lt;profile namespace="env" key="JAVA_HOME" &gt;/vdt/java&lt;/profile&gt;
    &lt;lrc url="rlsn://localhost" /&gt;
    &lt;gridftp  url="gsiftp://localhost" storage="/$HOME/storage" major="4" minor="0"
     patch="5"&gt;
    &lt;/gridftp&gt;
    &lt;jobmanager universe="transfer" url="localhost/jobmanager-fork" major="4" minor="0"
     patch="5" /&gt;
    &lt;jobmanager universe="vanilla" url="localhost/jobmanager-fork" major="4" minor="0"
     patch="5" /&gt;
    &lt;workdirectory &gt;$HOME/workdir&lt;/workdirectory&gt;
  &lt;/site&gt;
  &lt;site handle="clus1" gridlaunch="/opt/nfs/vdt/pegasus/bin/kickstart"
   sysinfo="INTEL32::LINUX"&gt;
    &lt;profile namespace="env" key="PEGASUS_HOME" &gt;/opt/nfs/vdt/pegasus&lt;/profile&gt;
    &lt;profile namespace="env" key="GLOBUS_LOCATION" &gt;/opt/vdt/globus&lt;/profile&gt;
    &lt;profile namespace="env" key="LD_LIBRARY_PATH" &gt;/opt/vdt/globus/lib&lt;/profile&gt;
    &lt;lrc url="rlsn://clus1.com" /&gt;
    &lt;gridftp  url="gsiftp://clus1.com" storage="/jobmanager-fork" major="4" minor="0"
     patch="3"&gt;
    &lt;/gridftp&gt;
    &lt;jobmanager universe="transfer" url="clus1.com/jobmanager-fork" major="4" minor="0"
     patch="3" /&gt;
    &lt;jobmanager universe="vanilla" url="clus1.com/jobmanager-pbs" major="4" minor="0"
     patch="3" /&gt;
    &lt;workdirectory &gt;$HOME/workdir-clus1&lt;/workdirectory&gt;
  &lt;/site&gt;
&lt;/sitecatalog&gt;</programlisting><orderedlist>
          <listitem>
            <para>site - A site identifier.</para>
          </listitem>

          <listitem>
            <para>lrc - URL for a local replica catalog (LRC) to register your
            files in. Only used for RLS implementation of the RC</para>
          </listitem>

          <listitem>
            <para>workdirectory - A remote working directory (Should be on a
            shared file system)</para>
          </listitem>

          <listitem>
            <para>gridftp - A URL prefix for a remote storage location. and a
            path to the storage location</para>
          </listitem>

          <listitem>
            <para>jobmanager - Url to the jobmanager entrypoints for the
            remote grid. Different universes are supported which map to
            different batch jobmanagers.</para>

            <para>"vanilla" for compute jobs and "transfer" for transfer jobs
            are mandatory. Generally a transfer universe should map to the
            fork jobmanager.</para>
          </listitem>

          <listitem>
            <para>gridlaunch - Path to the remote kickstart tool (provenance
            tracking)</para>
          </listitem>

          <listitem>
            <para>sysinfo - The arch/os/osversion/glibc of the site. The
            format is ARCH::OS:OSVER:GLIBC where OSVERSION and GLIBC are
            optional.</para>

            <para>ARCH can have one of the following values INTEL32, INTEL64,
            SPARCV7, SPARCV9, AIX, AMD64. OS can have one of the following
            values LINUX,SUNOS. The default value for sysinfo if none
            specified is INTEL32::LINUX</para>
          </listitem>

          <listitem>
            <para>Profiles - One or many profiles can be attached to a
            pool.</para>

            <para>One example is the environments to be set on a remote
            pool.</para>
          </listitem>
        </orderedlist></para>

      <para>To use this format you need to set the following properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.site=XML</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.site.file=<replaceable>&lt;path to the
            site catalog file&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
    </section>

    <section id="sc-Text">
      <title>Text</title>

      <para><warning>
          <para>This format is now deprecated in favor of the XML3 format. If
          you are still using the File format you should convert it to XML3
          format using the client pegasus-sc-converter</para>
        </warning></para>

      <para>The format for the File is as follows</para>

      <programlisting>site site_id {
  #required. Can be a dummy value if using Simple File RC
  lrc "rls://someurl"

  #required on a shared file system
  workdir "path/to/a/tmp/shared/file/sytem/"

  #required one or more entries
  gridftp "gsiftp://hostname/mountpoint” "GLOBUS VERSION"

  #required one or more entries
  universe transfer "hostname/jobmanager-&lt;scheduler&gt;" "GLOBUS VERSION"

  #reqired one or more entries
  universe vanilla "hostname/jobmanager-&lt;scheduler&gt;" "GLOBUS VERSION"

  #optional
  sysinfo  "ARCH::OS:OSVER:GLIBC"

  #optional
  gridlaunch "/path/to/gridlaunch/executable"

  #optional zero or more entries
  profile namespace "key" "value"
} </programlisting>

      <para>The gridlaunch and profile entries are optional. All the rest are
      required for each pool. Also the transfer and vanilla universe are
      mandatory. You can add multiple transfer and vanilla universe if you
      have more then one head node on the cluster. The entries in the Site
      Catalog have the following meaning:</para>

      <orderedlist>
        <listitem>
          <para>site - A site identifier.</para>
        </listitem>

        <listitem>
          <para>lrc - URL for a local replica catalog (LRC) to register your
          files in. Only used for RLS implementation of the RC</para>
        </listitem>

        <listitem>
          <para>workdir - A remote working directory (Should be on a shared
          file system)</para>
        </listitem>

        <listitem>
          <para>gridftp - A URL prefix for a remote storage location.</para>
        </listitem>

        <listitem>
          <para>universe - Different universes are supported which map to
          different batch jobmanagers.</para>

          <para>"vanilla" for compute jobs and "transfer" for transfer jobs
          are mandatory. Generally a transfer universe should map to the fork
          jobmanager.</para>
        </listitem>

        <listitem>
          <para>gridlaunch - Path to the remote kickstart tool (provenance
          tracking)</para>
        </listitem>

        <listitem>
          <para>sysinfo - The arch/os/osversion/glibc of the site. The format
          is ARCH::OS:OSVER:GLIBC where OSVERSION and GLIBC are
          optiona.</para>

          <para>ARCH can have one of the following values INTEL32, INTEL64,
          SPARCV7, SPARCV9, AIX, AMD64. OS can have one of the following
          values LINUX,SUNOS. The default value for sysinfo if none specified
          is INTEL32::LINUX</para>
        </listitem>

        <listitem>
          <para>Profiles - One or many profiles can be attached to a
          pool.</para>

          <para>One example is the environments to be set on a remote
          pool.</para>
        </listitem>
      </orderedlist>

      <para>To use this format you need to set the following properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.site=Text</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.site.file=<replaceable>&lt;path to the
            site catalog file&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
    </section>

    <section id="pegasus-sc-client">
      <title>Site Catalog Client pegasus-sc-client</title>

      <para>The pegasus-sc-client can be used to generate a site catalog for
      Open Science Grid (OSG) by querying their Monitoring Interface likes
      VORS or OSGMM. See pegasus-sc-client --help for more details</para>
    </section>

    <section>
      <title>Site Catalog Converter pegasus-sc-converter</title>

      <para>Pegasus 3.0 by default now parses Site Catalog format conforming
      to the SC schema 3.0 ( XML3 ) available <ulink role=""
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.xsd"
      userlevel="">here</ulink> and is explained in detail in the chapter on
      Catalogs.</para>

      <para>Pegasus 3.0 comes with a pegasus-sc-converter that will convert
      users old site catalog ( XML ) to the XML3 format. Sample usage is given
      below.</para>

      <programlisting><emphasis role="bold">$ pegasus-sc-converter -i sample.sites.xml -I XML -o sample.sites.xml3 -O XML3
</emphasis>
2010.11.22 12:55:14.169 PST:   Written out the converted file to sample.sites.xml3
</programlisting>

      <para>To use the converted site catalog, in the properties do the
      following</para>

      <orderedlist>
        <listitem>
          <para>unset pegasus.catalog.site or set pegasus.catalog.site to
          XML3</para>
        </listitem>

        <listitem>
          <para>point pegasus.catalog.site.file to the converted site
          catalog</para>
        </listitem>
      </orderedlist>
    </section>
  </section>

  <section id="transformation">
    <title>Transformation</title>

    <para>The Transformation Catalog maps logical transformations to physical
    executables on the system. It also provides additional information about
    the transformation as to what system they are compiled for, what profiles
    or environment variables need to be set when the transformation is invoked
    etc.</para>

    <para>Pegasus currently supports two implementations of the Transformation
    Catalog</para>

    <orderedlist>
      <listitem>
        <para><emphasis role="bold">Text: </emphasis>A multiline text based
        Transformation Catalog (DEFAULT)</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">File:</emphasis> A simple multi column
        text based Transformation Catalog</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Database:</emphasis> A database backend
        (MySQL or PostgreSQL) via JDB</para>
      </listitem>
    </orderedlist>

    <para>In this guide we will look at the format of the Multiline Text based
    TC.</para>

    <section id="tc-Text">
      <title>MultiLine Text based TC (Text)</title>

      <para>The multile line text based TC is the new default TC in Pegasus.
      This format allows you to define the transformations</para>

      <para>The file is read and cached in memory. Any modifications, as
      adding or deleting, causes an update of the memory and hence to the file
      underneath. All queries are done against the memory representation. The
      file sample.tc.text in the etc directory contains an example</para>

      <para><programlisting>tr example::keg:1.0 {

#specify profiles that apply for all the sites for the transformation
#in each site entry the profile can be overriden

  profile env "APP_HOME" "/tmp/myscratch"
  profile env "JAVA_HOME" "/opt/java/1.6"

  site isi {
    profile env "HELLo" "WORLD"
    profile condor "FOO" "bar"
    profile env "JAVA_HOME" "/bin/java.1.6"
    pfn "/path/to/keg"
    arch "x86"
    os "linux"
    osrelease "fc"
    osversion "4"
    type "INSTALLED"
  }

  site wind {
    profile env "CPATH" "/usr/cpath"
    profile condor "universe" "condor"
    pfn "file:///path/to/keg"
    arch "x86"
    os "linux"
    osrelease "fc"
    osversion "4"
    type "STAGEABLE"
  }
}</programlisting></para>

      <para>The entries in this catalog have the following meaning</para>

      <para><orderedlist>
          <listitem>
            <para>tr - A transformation identifier. (Normally a
            Namespace::Name:Version.. The Namespace and Version are
            optional.)</para>
          </listitem>

          <listitem>
            <para>pfn - URL or file path for the location of the executable.
            The pfn is a file path if the transformation is of type INSTALLED
            and generally a url (file:/// or http:// or gridftp://) if of type
            STAGEABLE</para>
          </listitem>

          <listitem>
            <para>site - The site identifier for the site where the
            transformation is available</para>
          </listitem>

          <listitem>
            <para>type - The type of transformation. Whether it is Iinstalled
            ("INSTALLED") on the remote site or is availabe to stage
            ("STAGEABLE").</para>
          </listitem>

          <listitem>
            <para>arch, os, osrelease, osversion - The
            arch/os/osrelease/osversion of the transformation. osrelease and
            osversion are optional.</para>

            <para>ARCH can have one of the following values x86, x86_64,
            sparcv7, sparcv9, ppc, aix. The default value for arch is
            x86</para>

            <para>OS can have one of the following values linux,sunos,macosx.
            The default value for OS if none specified is linux</para>
          </listitem>

          <listitem>
            <para>Profiles - One or many profiles can be attached to a
            transformation for all sites or to a transformation on a
            particular site.</para>
          </listitem>
        </orderedlist></para>

      <para>To use this format of the Transformation Catalog you need to set
      the following properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation=Text</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.file=<replaceable>&lt;path
            to the transformation catalog
            file&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
    </section>

    <section id="tc-File">
      <title>Singleline Text based TC (File)</title>

      <warning>
        <para>This format is now deprecated in favor of the multiline TC. If
        you are still using the single line TC you should convert it to
        multiline using the tc-converter client.</para>
      </warning>

      <para>The format of the this TC is as follows.</para>

      <programlisting>#site  logicaltr   physicaltr   type  system  profiles(NS::KEY="VALUE")

site1 sys::date:1.0 /usr/bin/date  INSTALLED INTEL32::LINUX:FC4.2:3.6 ENV::PATH="/usr/bin";PEGASUS_HOME="/usr/local/pegasus"</programlisting>

      <para>The system and profile entries are optional and will use default
      values if not specified. The entries in the file format have the
      following meaning:</para>

      <orderedlist>
        <listitem>
          <para>site - A site identifier.</para>
        </listitem>

        <listitem>
          <para>logicaltr - The logical transformation name. The format is
          NAMESPACE::NAME:VERSION where NAMESPACE and NAME are
          optional.</para>
        </listitem>

        <listitem>
          <para>physicaltr - The physical transformation path or URL.</para>

          <para>If the transformation type is INSTALLED then it needs to be an
          absolute path to the executable. If the type is STAGEABLE then the
          path needs to be a HTTP, FTP or gsiftp URL</para>
        </listitem>

        <listitem>
          <para>type - The type of transformation. Can have on of two
          values</para>

          <itemizedlist>
            <listitem>
              <para>INSTALLED: This means that the transformation is installed
              on the remote site</para>
            </listitem>

            <listitem>
              <para>STAGEABLE: This means that the transformation is available
              as a static binary and can be staged to a remote site.</para>
            </listitem>
          </itemizedlist>
        </listitem>

        <listitem>
          <para>system - The system for which the transformation is
          compiled.</para>

          <para>The formation of the sytem is ARCH::OS:OSVERSION:GLIBC where
          the GLIBC and OS VERSION are optional. ARCH can have one of the
          following values INTEL32, INTEL64, SPARCV7, SPARCV9, AIX, AMD64. OS
          can have one of the following values LINUX,SUNOS. The default value
          for system if none specified is INTEL32::LINUX</para>
        </listitem>

        <listitem>
          <para>Profiles - The profiles associated with the transformation.
          For indepth information about profiles and their priorities read the
          Profile Guide.</para>

          <para>The format for profiles is NS::KEY="VALUE" where NS is the
          namespace of the profile e.g. Pegasus,condor,DAGMan,env,globus. The
          key and value can be any strings. Remember to quote the value with
          double quotes. If you need to specify several profiles you can do it
          in several ways</para>

          <itemizedlist>
            <listitem>
              <para>NS1::KEY1="VALUE1",KEY2="VALUE2";NS2::KEY3="VALUE3",KEY4="VALUE4"</para>

              <para>This is the most optimized form. Multiple key values for
              the same namespace are separated by a comma "," and different
              namespaces are separated by a semicolon ";"</para>
            </listitem>

            <listitem>
              <para>NS1::KEY1="VALUE1";NS1::KEY2="VALUE2";NS2::KEY3="VALUE3";NS2::KEY4="VALUE4"</para>

              <para>You can also just repeat the triple of NS::KEY="VALUE"
              separated by semicolons for a simple format;</para>
            </listitem>
          </itemizedlist>
        </listitem>
      </orderedlist>

      <para>To use this format of the Transformation Catalog you need to set
      the following properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation=File</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.file=<replaceable>&lt;path
            to the transformation catalog
            file&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
    </section>

    <section id="tc-Database">
      <title>Database TC (Database)</title>

      <para>The database TC alows you to use a relational database. To use the
      database TC you need to have installed a MySQL or PostgreSQL server. The
      schema for the database is available in $PEGASUS_HOME/sql directory. You
      will have to install the schema into either PostgreSQL or MySQL by
      running the appropriate commands to load the two scheams <emphasis
      role="bold">create-XX-init.sql</emphasis> and <emphasis
      role="bold">create-XX-tc.sql</emphasis> where XX is either <emphasis
      role="bold">my</emphasis> (for MySQL) or <emphasis
      role="bold">pg</emphasis> (for PostgreSQL)</para>

      <para>To use the Database TC you need to set the following
      properties</para>

      <para><orderedlist>
          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.db.driver=MySQL |
            Postgres</emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.db.url=<replaceable>&lt;jdbc
            url to the databse&gt;</replaceable></emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.db.user=<replaceable>&lt;database
            user&gt;</replaceable></emphasis></para>
          </listitem>

          <listitem>
            <para><emphasis
            role="bold">pegasus.catalog.transformation.db.password=<replaceable>&lt;database
            password&gt;</replaceable></emphasis></para>
          </listitem>
        </orderedlist></para>
    </section>

    <section id="pegasus-tc-client">
      <title>TC Client pegasus-tc-client</title>

      <para>We need to map our declared transformations (preprocess,
      findranage, and analyze) from the example DAX above to a simple "mock
      application" name "keg" ("canonical example for the grid") which reads
      input files designated by arguments, writes them back onto output files,
      and produces on STDOUT a summary of where and when it was run. Keg ships
      with Pegasus in the bin directory. Run keg on the command line to see
      how it works.</para>

      <screen><command>$ keg -o /dev/fd/1</command>
<computeroutput>
Timestamp Today: 20040624T054607-05:00 (1088073967.418;0.022)
Applicationname: keg @ 10.10.0.11 (VPN)
Current Workdir: /home/unique-name
Systemenvironm.: i686-Linux 2.4.18-3
Processor Info.: 1 x Pentium III (Coppermine) @ 797.425
Output Filename: /dev/fd/1</computeroutput></screen>

      <para>Now we need to map all 3 transformations onto the "keg"
      executable. We place these mappings in our File transformation catalog
      for site clus1. In earlier version of Pegasus one had to define entries
      for Pegasus executables like transfer, replica client, dirmanager etc on
      each site as well as site "local". This is no longer required. Pegasus
      2.0 and later automatically picks up the paths for these binaries from
      the environment profile PEGASUS_HOME set in the site catalog for each
      site.</para>

      <para>Note: A single entry needs to be on one line. The above example is
      just formatted for convenience.</para>

      <para>Alternatively you can also use the pegasus-tc-client to add
      entries to any implementation of the transformation catalog. The
      following eg: shows us adding the last entry in the File based
      transformation catalog.</para>

      <screen><command>$ pegasus-tc-client -Dpegasus.catalog.transformation=Text \
-Dpegasus.catalog.transformation.file=$HOME/tc -a -r clus1 -l black::analyze:1.0 \
-p gsiftp://clus1.com/opt/nfs/vdt/pegasus/bin/keg  -t STAGEABLE -s INTEL32::LINUX \
-e ENV::KEY3="VALUE3"</command><computeroutput>

2007.07.11 16:12:03.712 PDT: [INFO] Added tc entry sucessfully</computeroutput></screen>

      <para>To verify if the entry was correctly added to the transformation
      catalog you can use the pegasus-tc-client to query.</para>

      <screen><command>$ pegasus-tc-client -Dpegasus.catalog.transformation=File \
-Dpegasus.catalog.transformation.file=$HOME/tc -q -P -l black::analyze:1.0</command>

<computeroutput>#RESID     LTX          PFN                  TYPE              SYSINFO

clus1    black::analyze:1.0    gsiftp://clus1.com/opt/nfs/vdt/pegasus/bin/keg
                STAGEABLE    INTEL32::LINUX</computeroutput></screen>

      <para/>
    </section>

    <section>
      <title>TC Converter Client pegasus-tc-converter</title>

      <para>Pegasus 3.0 by default now parses a file based multiline textual
      format of a Transformation Catalog. The new Text format is explained in
      detail in the chapter on Catalogs.</para>

      <para>Pegasus 3.0 comes with a pegasus-tc-converter that will convert
      users old transformation catalog ( File ) to the Text format. Sample
      usage is given below.</para>

      <programlisting><emphasis role="bold">$ pegasus-tc-converter -i sample.tc.data -I File -o sample.tc.text -O Text
</emphasis>
2010.11.22 12:53:16.661 PST:   Successfully converted Transformation Catalog from File to Text
2010.11.22 12:53:16.666 PST:   The output transfomation catalog is in file  /lfs1/software/install/pegasus/pegasus-3.0.0cvs/etc/sample.tc.text
</programlisting>

      <para>To use the converted transformation catalog, in the properties do
      the following</para>

      <orderedlist>
        <listitem>
          <para>unset pegasus.catalog.transformation or set
          pegasus.catalog.transformation to Text</para>
        </listitem>

        <listitem>
          <para>point pegasus.catalog.transformation.file to the converted
          transformation catalog</para>
        </listitem>
      </orderedlist>
    </section>
  </section>
             
  <section>
    <para><figure id="">
    <title>Catalog Diagram</title>
          <para>The diagram below shows a typical Pegasus network with Catalogs</para>

          <mediaobject>
            <imageobject>
              <imagedata align="center" fileref="images/"
                         valign="middle" />
            </imageobject>
          </mediaobject>
        </figure></para>

    </section>
      <section>
       <title>Pegasus Mapper</title>
      </section>

      <para>The mapping of tasks to the execution resources is done by the mapper based on
  information derived for static and/or dynamic sources. In some cases
  information systems already in place provide the information about the
  execution environment and the location of data. In other cases, users
  specify this information. </para>

      <section>

      <title> Condor Schedd </title>
      
      <para>Individual workflow tasks are managed by Condor Schedd which supervises their execution on local and remote resources.
      Condor schedd is a component in the Condor Project.</para>

      </section>
      
      <section>
      
      <title>Submit Directory</title>
             <para>The Submit Directory receives the executable workflow (DAG) and stores it until Pegasus Mapper runs to map the tasks of
      the DAG with the static or dynamic compute resources.</para>
      </section>
      
       <para>To see the contents of the directory and the details of the process of conversion from an Abstract to Executable workflow see the <link
       
       linkend="submit_directory"> Submit Directory Details </link> </para>



      <title>Monitoring Tools</title>
      
      <para>Pegasus comes with a set of tools that help monitor the progress of
  the workflow and collect statistics and performance profiles of the
  workflows. Pegasus WMS is a user-side application that can be deployed
  locally by a scientist with no support from a site administrator and has no
  impact on the target cyberinfrastructure sites. A collaboration can set up a
  submit host, which hosts the workflow management system. Jobs are sent from
  the submit host to the campus cluster, the Open Science Grid, the TeraGrid,
  the cloud, or other resources.</para>

      
  <section>

       <title>Error Recovery</title>
       
       <para>When errors occur, Pegasus tries to recover when possible by retrying
  tasks, by retrying the entire workflow, by providing workflow-level
  checkpointing, by re-mapping portions of the workflow, by trying alternative
  data sources for staging data, and, when all else fails, by providing a
  rescue workflow containing a description of only the work that remains to be
  done. It cleans up storage as the workflow is executed so that
  data-intensive workflows have enough space to execute on storage-constrained
  resource. Pegasus keeps track of what has been done (provenance) including
  the locations of data used and produced, and which software was used with
  which parameters.</para>
       </section>
       
</chapter>



















