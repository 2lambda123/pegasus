#!/bin/bash
#-----------------------------------------------------------------------------
# Modified for Intelligent Data performace testing with Policy Server
#-----------------------------------------------------------------------------
set -e

# note - this requires Montage 3.2beta6 or higher

#######################################################################
#
#  Settings
#

#DEGREES=2.0
# The script that is sequencing the tests sets this environment variable.
DEGREES=${PERFTEST_DEGREES:=1}
RUN_DIR=$1

#echo "Montage degrees = $DEGREES"
#echo "RUN_DIR=$RUN_DIR"
#exit 0

# Used to artificially inject staging files into each staging job
LARGE_FILE_HOSTNAME=vm-103.alamo.futuregrid.org
LARGE_FILE_BASE=/opt/stagein/stagein
#LARGE_FILE_HOSTNAME=

#LOCAL_PEGASUS_HOME="/ccg/software/pegasus/dev/trunk"
LOCAL_PEGASUS_HOME="/nfs/ccg3/scratch/smithd/pegasus"
LOCAL_GLOBUS_LOCATION="/ccg/software/globus/default"
#LOCAL_MONTAGE_LOCATION="/ccg/software/montage/Montage_v3.2_beta6_mats"
#LOCAL_MONTAGE_LOCATION="/ccg/software/montage/Montage_v3.3_mats"
LOCAL_MONTAGE_LOCATION="/nfs/ccg3/scratch/smithd/Montage_v3.3_patched_4"
LOCAL_GLOBUS_TCP_PORT_RANGE="40000,50000"

CLUSTER_NAME="CCG"
CLUSTER_HOSTNAME="obelix.isi.edu"
CLUSTER_GATEKEEPER_TYPE="gt5"
CLUSTER_GATEKEEPER_PORT="2119"
CLUSTER_SCHEDULER="condor"
#CLUSTER_WORK_DIR="/nfs/ccg1/90-day-scratch"
#CLUSTER_WORK_DIR="/nfs/ccg3/scratch/smithd/work"
CLUSTER_WORK_DIR="/nfs/ccg4/scratch-6-months-purge/smithd/work"
#CLUSTER_PEGASUS_HOME="/ccg/software/pegasus/dev/trunk"
CLUSTER_PEGASUS_HOME="/nfs/ccg3/scratch/smithd/pegasus"
CLUSTER_GLOBUS_LOCATION="/ccg/software/globus/default"
#CLUSTER_MONTAGE_LOCATION="/ccg/software/montage/Montage_v3.3_mats"
CLUSTER_MONTAGE_LOCATION="/nfs/ccg3/scratch/smithd/Montage_v3.3_patched_4"

# this will bundle N jobs togehter
JOB_CLUSTERS_SIZE="25"

# Intelligent Data settings for policy
#PEGASUS_POLICY_CHECKS="NO"
PEGASUS_POLICY_CHECKS="YES"
PEGASUS_POLICY_HOST="lonestar.isi.edu"
PEGASUS_POLICY_PORT="8080"
PEGASUS_POLICY_URL="/policy/"
#######################################################################

TOP_DIR=`pwd`
LOCAL_HOSTNAME=`hostname -f`

export PATH=$LOCAL_MONTAGE_LOCATION/bin:$LOCAL_PEGASUS_HOME/bin:$PATH

# unique directory for this run
if [ "x$RUN_DIR" = "x" ]; then
  echo "Generating workkflow run directory..."
  RUN_ID=`/bin/date +'%F_%H%M%S'`
  RUN_DIR=`pwd`/work/$RUN_ID
fi

echo "Work directory: $RUN_DIR"

mkdir -p $RUN_DIR
cd $RUN_DIR

cp $TOP_DIR/pegasusrc.0clusters .

# create the transformation catalogue (tc)
echo
echo "Creating the transformation catalog..."
for BINARY in `(cd $LOCAL_MONTAGE_LOCATION/bin && ls)`; do
    cat >>tc <<EOF
tr $BINARY:3.3 {
    site $CLUSTER_NAME {
        pfn "$CLUSTER_MONTAGE_LOCATION/bin/$BINARY"
        arch "x86"
        os "linux"
        type "INSTALLED"
        profile pegasus "clusters.size" "$JOB_CLUSTERS_SIZE" 
    }
}
EOF
done

# site catalog
echo
echo "Creating the site catalog..."
cat >sites.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-3.0.xsd" version="3.0">
    <site handle="local" arch="x86" os="LINUX">
        <grid  type="gt2" contact="localhost/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/>
        <head-fs>
            <scratch>
                <shared>
                    <file-server protocol="file" url="file://" mount-point="$RUN_DIR/work"/>
                    <internal-mount-point mount-point="$RUN_DIR/work"/>
                </shared>
            </scratch>
            <storage>
                <shared>
                    <file-server protocol="file" url="file://" mount-point="$RUN_DIR/outputs"/>
                    <internal-mount-point mount-point="$RUN_DIR/outputs"/>
                </shared>
            </storage>
        </head-fs>
        <replica-catalog  type="LRC" url="rlsn://dummyValue.url.edu" />
        <profile namespace="env" key="PEGASUS_HOME" >$LOCAL_PEGASUS_HOME</profile>
        <profile namespace="env" key="GLOBUS_LOCATION" >$LOCAL_GLOBUS_LOCATION</profile>
        <profile namespace="env" key="GLOBUS_TCP_PORT_RANGE" >$LOCAL_GLOBUS_TCP_PORT_RANGE</profile>
	<profile namespace="env" key="PEGASUS_POLICY_CHECKS" >$PEGASUS_POLICY_CHECKS</profile>
	<profile namespace="env" key="PEGASUS_POLICY_HOST" >$PEGASUS_POLICY_HOST</profile>
	<profile namespace="env" key="PEGASUS_POLICY_PORT" >$PEGASUS_POLICY_PORT</profile>
	<profile namespace="env" key="PEGASUS_POLICY_URL" >$PEGASUS_POLICY_URL</profile>

    </site>
    <site handle="$CLUSTER_NAME" arch="x86" os="LINUX">
        <grid  type="$CLUSTER_GATEKEEPER_TYPE" contact="$CLUSTER_HOSTNAME:$CLUSTER_GATEKEEPER_PORT/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/>
        <grid  type="$CLUSTER_GATEKEEPER_TYPE" contact="$CLUSTER_HOSTNAME:$CLUSTER_GATEKEEPER_PORT/jobmanager-$CLUSTER_SCHEDULER" scheduler="unknown" jobtype="compute"/>
        <head-fs>
            <scratch>
                <shared>
                    <file-server protocol="gsiftp" url="gsiftp://$CLUSTER_HOSTNAME" mount-point="$CLUSTER_WORK_DIR"/>
                    <internal-mount-point mount-point="$CLUSTER_WORK_DIR"/>
                </shared>
            </scratch>
            <storage>
            </storage>
        </head-fs>
        <replica-catalog  type="LRC" url="rlsn://dummyValue.url.edu" />
        <profile namespace="env" key="PEGASUS_HOME" >$CLUSTER_PEGASUS_HOME</profile>
        <profile namespace="env" key="GLOBUS_LOCATION" >$CLUSTER_GLOBUS_LOCATION</profile>
        <profile namespace="env" key="MONTAGE_HOME" >$CLUSTER_MONTAGE_LOCATION</profile>
	<profile namespace="env" key="PEGASUS_POLICY_CHECKS" >$PEGASUS_POLICY_CHECKS</profile>
        <profile namespace="env" key="PEGASUS_POLICY_HOST" >$PEGASUS_POLICY_HOST</profile>
        <profile namespace="env" key="PEGASUS_POLICY_PORT" >$PEGASUS_POLICY_PORT</profile>
        <profile namespace="env" key="PEGASUS_POLICY_URL" >$PEGASUS_POLICY_URL</profile> 
    </site>
</sitecatalog>
EOF

echo
echo "Running mDAG (finding input images, generating DAX, ...)..."
if [ "x$LARGE_FILE_HOSTNAME" != "x" ]; then
  mDAG 2mass j M17 $DEGREES $DEGREES 0.0002777778 . "gsiftp://$LOCAL_HOSTNAME$RUN_DIR" "gsiftp://$LOCAL_HOSTNAME$RUN_DIR/inputs" "gsiftp://$LARGE_FILE_HOSTNAME$LARGE_FILE_BASE"
else
  mDAG 2mass j M17 $DEGREES $DEGREES 0.0002777778 . "gsiftp://$LOCAL_HOSTNAME$RUN_DIR" "gsiftp://$LOCAL_HOSTNAME$RUN_DIR/inputs"
fi

echo
echo "Adding input images to the replica catalog..."
echo "  " `cat cache.list | wc -l` "images found"
cat cache.list | grep -v ".fits " >rc
cat url.list | sed 's/ http:.*ref=/ http:\/\/obelix.isi.edu\/irsa-cache/' >>rc

echo
echo "Planning and submitting the workflow..."
pegasus-plan \
    --conf pegasusrc.0clusters \
    --sites $CLUSTER_NAME \
    --dir work \
    --output local \
    --submit \
    --dax dag.xml \
    2>&1 | tee pegasus-plan.out


