kickstart(1)                                                      kickstart(1)



NNAAMMEE
       kickstart - run an executable in a more universal environment.

SSYYNNTTAAXX
       kkiicckkssttaarrtt [-n tr] [-N dv] [-H] [-R site] [-W | -w wd] [-L lbl -T iso]
        [-s [l=]p | @fn] [-S [l=]p | @fn] [-i asi] [-o aso] [-e ase] [-X]
        [-l log] [-B sz] (-I fn | app [appflags] )
       kkiicckkssttaarrtt -V

DDEESSCCRRIIPPTTIIOONN
       The  kkiicckkssttaarrtt  executable is a light-weight program which connects the
       _s_t_d_i_n, _s_t_d_o_u_t and _s_t_d_e_r_r filehandles for grid jobs on the remote  site.

       Sitting  in between the remote scheduler and the executable, it is pos-
       sible for kkiicckkssttaarrtt to gather additional  information  about  the  exe-
       cutable run-time behavior and resource usage, including the exit status
       of jobs. This information is important for the VDS invocation  tracking
       as well as to Condor DAGMan's awareness of Globus job failures.

       KKiicckkssttaarrtt  allows  the  optional execution of jobs before and after the
       main application job that run in chained execution with the main appli-
       cation job. See section SSUUBBJJOOBBSS for details about this feature.

       All  jobs with relative path specifications to the application are part
       of search relative to the  current  working  directory  (yes,  this  is
       unsafe),  and  by  prepending  each component from the _P_A_T_H environment
       variable. The first match is used. Jobs that  use  absolute  pathnames,
       starting  in  a  slash, are exempt. Using an absolute path to your exe-
       cutable is the safe and recommended option.

       KKiicckkssttaarrtt rewrites the commandline of any job (pre, post and main) with
       variable  substitutions  from  Unix  environment variables. See section
       VVAARRIIAABBLLEE RREEWWRRIITTIINNGG below for details on this feature.

       KKiicckkssttaarrtt provides a temporary named pipe (fifo) for applications  that
       are gridstart aware. Any data an application writes to the FIFO will be
       propagated back to the submit host, thus enabling progress  meters  and
       other  application  dependent  monitoring. See section FFEEEEDDBBAACCKK CCHHAANNNNEELL
       below for details on this feature.

AARRGGUUMMEENNTTSS
       --nn ttrr  In order to associate the minimal performance information of the
              job  with  the invocation records, the jobs needs to carry which
              transformation in the VDC was responsible for producing it.  The
              format  is  the  notion  of  VDLt for fully-qualified definition
              names, like namespace::name:version, with only the name  portion
              being mandatory.

              There  is  no  default.  If  no  value  is given, "null" will be
              reported.

       --NN ddvv  In order to associate the VDC invocation record of the job  with
              the invocation records, the jobs needs to carry which derivation
              in the VDC was responsible for producing it. The format  is  the
              notion of VDLt for fully-qualified definition names, like names-
              pace::name:version, with only the name portion being  mandatory.

              There  is  no  default.  If  no  value  is given, "null" will be
              reported.

       --HH     This option avoids kickstart writing the XML preamble  (entity),
              if  you  need  to  combine  multiple  kickstart records into one
              document.

              Additionally, if specified, the  environment  and  the  resource
              usage  segments  will  not be written, assuming that a in a con-
              catinated record version, the initial  run  will  have  captured
              those settings.

       --RR ssiittee
              In  order  to provide the greater picture, kickstart can reflect
              the site handle (resource identifier) into its output.

              There is no default. If no value is given,  the  attribute  will
              not be generated.

       --LL llbbll

       --TT iissoo These  optional  arguments  denote the workflow label (from DAX)
              and the workflow's last modification time (from DAX). The  label
              _l_b_l  can  be  any  sensible  string  of up to 32 characters, but
              should use C identifier characters. The timestamp _i_s_o must be an
              ISO 8601 compliant time-stamp.

       --SS ll==pp If stat information on any file is required _b_e_f_o_r_e any jobs were
              started, logical to physical file mappings to stat can be passed
              using  the  --SS  option.  The  LFN and PFN are concatenated by an
              equals (=) sign. The LFN is  optional:  If  no  equals  sign  is
              found,  the  argument is taken as sole PFN specification without
              LFN.

              This option may be specified multiple times. To reduce and over-
              come commandline length limits, if the argument is prefixed with
              an at (@) sign, the argument is taken to be a  textual  file  of
              LFN  to  PFN mappings.  The optionality mentioned above applies.
              Each line inside the file argument is the  name  of  a  file  to
              stat. Comments (#) and empty lines are permitted.

              Each  PFN  will incur a _s_t_a_t_c_a_l_l record (element) with attribute
              _i_d set to value _i_n_i_t_i_a_l.  The optional _l_f_n attribute is  set  to
              the  LFN  stat'ed.  The  filename is part of the _s_t_a_t_i_n_f_o record
              inside.

              There is no default.

       --ss ffnn  If stat information on any file is required _a_f_t_e_r all jobs  have
              finished,  logical  to  physical  file  mappings  to stat can be
              passed using the --ss option. The LFN and PFN are concatenated  by
              an  equals  (=)  sign. The LFN is optional: If no equals sign is
              found, the argument is taken as sole PFN  specification  without
              LFN.

              This option may be specified multiple times. To reduce and over-
              come commandline length limits, if the argument is prefixed with
              an  at  (@)  sign, the argument is taken to be a textual file of
              LFN to PFN mappings.  The optionality mentioned  above  applies.
              Each  line  inside  the  file  argument is the name of a file to
              stat. Comments (#) and empty lines are permitted.

              Each PFN will incur a _s_t_a_t_c_a_l_l record (element)  with  attribute
              _i_d set to value _f_i_n_a_l.  The optional _l_f_n attribute is set to the
              LFN stat'ed. The filename is part of the _s_t_a_t_i_n_f_o record inside.

              There is no default.

       --ii aassii This  option  allows  kkiicckkssttaarrtt  to  re-connect the stdin of the
              application that it starts. Use a single hyphen to  share  _s_t_d_i_n
              with the one provided to kkiicckkssttaarrtt.

              The default is to connect _s_t_d_i_n to _/_d_e_v_/_n_u_l_l.

       --oo aassoo This  option  allows  kkiicckkssttaarrtt  to re-connect the _s_t_d_o_u_t of the
              application that it starts. The mode is used whenever an  appli-
              cation produces meaningful results on its _s_t_d_o_u_t that need to be
              tracked by VDS. The real _s_t_d_o_u_t of Globus  jobs  is  staged  via
              GASS  (GT2)  or  RFT (GT4). The real _s_t_d_o_u_t is used to propagate
              the invocation record back to the submit site.  Use  the  single
              hyphen  to  share  the application's _s_t_d_o_u_t with the one that is
              provided to kkiicckkssttaarrtt.  In that case, the output from  kkiicckkssttaarrtt
              will interleave with application output. For this reason, such a
              mode is not recommended.

              In order to provide an uncaptured _s_t_d_o_u_t as part of the results,
              it  is the default to connect the _s_t_d_o_u_t of the application to a
              temporary file. The content  of  this  temporary  file  will  be
              transferred  as  payload data in the kkiicckkssttaarrtt results. The con-
              tent size is subject to payload limits, see the  --BB  option.  If
              the  content  grows  large,  only an initial portion will become
              part of the payload. If the temporary file grows too  large,  it
              may  flood the worker node's temporary space. The temporary file
              will be deleted after kkiicckkssttaarrtt finishes.

              If the filename is prefixed with an exclaimation point, the file
              will  be  opened  in append mode instead of overwrite mode. Note
              that you may need to escape  the  exclaimation  point  from  the
              shell.

              The default is to connect _s_t_d_o_u_t to a temporary file.

       --ee aassee This  option  allows  kkiicckkssttaarrtt  to re-connect the _s_t_d_e_r_r of the
              application that it starts. This  option  is  used  whenever  an
              application  produces  meaningful  results  on _s_t_d_e_r_r that needs
              tracking by VDS. The real _s_t_d_e_r_r of Globus jobs  is  staged  via
              GASS  (GT2)  or  RFT  (GT4).  It  is  used to propagate abnormal
              behaviour from both,  kkiicckkssttaarrtt  and  the  application  that  it
              starts,  though  its main use is to propagate application depen-
              dent data and heartbeats. Use a single hyphen  to  share  _s_t_d_e_r_r
              with  the  _s_t_d_e_r_r  that  is  provided to kkiicckkssttaarrtt.  This is the
              backward compatible behavior.

              In order to provide an uncaptured _s_t_d_e_r_r as part of the results,
              by  default the _s_t_d_e_r_r of the application will be connected to a
              temporary file. Its content is transferred as  payload  data  in
              the kkiicckkssttaarrtt results. If too large, only the an initial portion
              will become part of the payload. If the temporary file grows too
              large,  it may flood the worker node's temporary space. The tem-
              porary file will be deleted after kkiicckkssttaarrtt finishes.

              If the filename is prefixed with an exclaimation point, the file
              will  be  opened  in append mode instead of overwrite mode. Note
              that you may need to escape  the  exclaimation  point  from  the
              shell.

              The default is to connect _s_t_d_e_r_r to a temporary file.

       --ll llooggffnn
              allows  to  append  the  performance data to the specified file.
              Thus, multiple XML documents  may  end  up  in  the  same  file,
              including their XML preamble.  _s_t_d_o_u_t is normally used to stream
              back the results. Usually, this is a GASS-staged stream.  Use  a
              single hyphen to generate the output on the _s_t_d_o_u_t that was pro-
              vided to kkiicckkssttaarrtt, the default behavior.

              Default is to append the invocation  record  onto  the  provided
              _s_t_d_o_u_t.

       --ww ccwwdd permits  the  explicit  setting  of a new working directory once
              kickstart is started. This is  useful  in  a  remote  scheduling
              environment, when the chosen working directory is not visible on
              the job submitting host. If the directory does not exist,  kkiicckk--
              ssttaarrtt  will  fail. This option is mutually exclusive with the _-_W
              _c_w_d option.

              Default is to use the working directory that the application was
              started  in. This is usually set up by a remote scheduling envi-
              ronment.

       --WW ccwwdd permits the explicit creation  and  setting  of  a  new  working
              directory  once kickstart is started. This is useful in a remote
              scheduling environment, when the chosen working directory is not
              visible  on  the  job submitting host. If the directory does not
              exist, kkiicckkssttaarrtt will attempt to create it, and then change into
              it.  Both,  creation  and  directory change may still fail. This
              option is mutually exclusive with the _-_w _c_w_d option.

              Default is to use the working directory that the application was
              started  in. This is usually set up by a remote scheduling envi-
              ronment.

       --XX     make an application executable, no matter what. It  is  a  work-
              around  code  for  a  weakness of _g_l_o_b_u_s_-_u_r_l_-_c_o_p_y which does not
              copy the permissions of the source to the destination.  Thus, if
              an executable is staged-in using GridFTP, it will have the wrong
              permissions. Specifying the _-_X flag will attempt to  change  the
              mode  to include the necessary x (and r) bits to make the appli-
              cation executable.

              Default is not to change the mode of the application. Note  that
              this  feature  can  be misused by hackers, as it is attempted to
              call chmod on whatever path is specified.

       --BB sszz  varies the size of the debug output data section.  If  the  file
              descriptors _s_t_d_o_u_t and _s_t_d_e_r_r remain untracked, kkiicckkssttaarrtt tracks
              that output in temporary files. The first few  pages  from  this
              output  is copied into a data section in the output. In order to
              resize the length of the output  within  reasonable  boundaries,
              this  option permits a changes. Data beyond the size will not be
              copied, i.e. is truncated.

              Warning: This is not a cheap way to obtain the stdio file handle
              data.   Please  use tracked files for that. Due to output buffer
              pre-allocation, using arbitrary large arguments  may  result  in
              failures of kkiicckkssttaarrtt itself to allocate the necessary memory.

              The default maximum size of the data section is 262144 byte.

       --II ffnn  In  this  mode,  the  application  name and any arguments to the
              application are specified inside of file _f_n.  The file  contains
              one  argument  per line. Escapeing from Globus, Condor and shell
              meta characters is not required. This mode permits  to  use  the
              maximum possible commandline length of the underlying operationg
              system, e.g. 128k for Linux. Using the --II mode stops any further
              commandline processing of kkiicckkssttaarrtt command lines.

              Default  is  to use the _a_p_p _f_l_a_g_s mode, where the application is
              specified explicitely on the command-line.

       aapppp    The path to the application has to be completely specified.  The
              application is a mandatory option.

       aappppffllaaggss
              Application may or may not have additional flags.

RREETTUURRNN VVAALLUUEE
       kkiicckkssttaarrtt  will  return  the return value of the main job. In addition,
       the error code 127 signals that the call to exec failed, and  126  that
       reconnecting  the  stdio failed. A job failing with the same exit codes
       is indistinguishable from kkiicckkssttaarrtt failures.

SSEEEE AALLSSOO
       ccoonnddoorr__ssuubbmmiitt__ddaagg(1), ccoonnddoorr__ssuubbmmiitt(1), ggeettrruussaaggee(3c), ggeennccddaagg(1).

       hhttttpp::////vvddss..iissii..eedduu//ddoocc//sscchheemmaass//iivv--11..1100//iivv--11..1100..hhttmmll,
       hhttttpp::////vvddss..iissii..eedduu//linkDDooccuummeennttaattiioonn..

SSUUBBJJOOBBSS
       Subjobs are a new feature and may have a few wrinkles left.

       In order to allow specific setups  and  assertion  checks  for  compute
       nodes,  kkiicckkssttaarrtt allows the optional execution of a _p_r_e_j_o_b.  This _p_r_e_-
       _j_o_b is anything that the remote compute node is capable  of  executing.
       For  modern  Unix systems, this includes #! scripts interpreter invoca-
       tions, as long as the x bits on the executed file are set. The main job
       is  run  if and only if the prejob returned regularly with an exit code
       of zero.

       With similar restrictions, the  optional  execution  of  a  _p_o_s_t_j_o_b  is
       chained to the success of the main job. The postjob will be run, if the
       main job terminated normally with an exit code of zero.

       In addition, a user may specify a _s_e_t_u_p and a _c_l_e_a_n_u_p  job.  The  _s_e_t_u_p
       job  sets up the remote execution environment. The _c_l_e_a_n_u_p job may tear
       down and clean-up after any job ran. Failure to run the setup  job  has
       no  impact  on  subsequent jobs. The cleanup is a job that will even be
       attempted to run for all failed jobs. No job information is passed.  If
       you  need to invoke multiple setup or clean-up jobs, bundle them into a
       script, and invoke the clean-up script. Failure of the clean-up job  is
       not  meant to affect the progress of the remote workflow (DAGMan). This
       may change in the future.

       The setup-, pre-, and post- and cleanup-job run  on  the  same  compute
       node  as  the  main job to execute. However, since they run in separate
       processes as children of kkiicckkssttaarrtt, they are unable to  influence  each
       others nor the main jobs environment settings.

       All  jobs  and their arguments are subject to variable substitutions as
       explained in the next section.

       To specify the prejob, insert the the application  invocation  and  any
       optional  commandline  argument  into  the  environment  variable _G_R_I_D_-
       _S_T_A_R_T___P_R_E_J_O_B.  If you are invoking from a shell, you might want to  use
       single  quotes  to  protect against the shell. If you are invoking from
       Globus, you can append the RSL string feature. From Condor, you can use
       Condor's notion of environment settings. From VDS, use the _p_r_o_f_i_l_e com-
       mand to set generic scripts that will work on multiple  sites,  or  the
       transformation  catalog to set environment variables in a pool-specific
       fashion. Please remember that the execution of the main job is  chained
       to the success of the prejob.

       To  set  up the postjob, use the environment variable _G_R_I_D_S_T_A_R_T___P_O_S_T_J_O_B
       to point to an application with potential  arguments  to  execute.  The
       same  restrictions as for the prejob apply. Please note that the execu-
       tion of the post job is chained to the main job.

       To provide the independent setup  job,  use  the  environment  variable
       _G_R_I_D_S_T_A_R_T___S_E_T_U_P.   The  exit  code of the setup job has no influence on
       the remaining chain of jobs. To provide an independent cleanup job, use
       the  environment  variable _G_R_I_D_S_T_A_R_T___C_L_E_A_N_U_P to point to an application
       with possible arguments to execute. The same restrictions as for prejob
       and  postjob apply. The cleanup is run regardless of the exit status of
       any other jobs.

VVAARRIIAABBLLEE RREEWWRRIITTIINNGG
       Variable substitution is a new feature and  may  have  a  few  wrinkles
       left.

       The  variable  substitution  employs simple rules from the Bourne shell
       syntax. Simple quoting rules for backslashed characters, double  quotes
       and  single  quotes are obeyed. Thus, in order to pass a dollar sign to
       as argument to your job, it must be escaped with a backslash  from  the
       variable rewriting.

       For  pre- and postjobs, double quotes allow the preservation of whites-
       pace and the insertion  of  special  characters  like  \a  (alarm),  \b
       (backspace),  \n  (newline), \r (carriage return), \t (horizontal tab),
       and \v (vertical tab). Octal modes are _n_o_t allowed. Variables are still
       substituted  in  double quotes. Single quotes inside double quotes have
       no special meaning.

       Inside single quotes, no variables are  expanded.  The  backslash  only
       escapes a single quote or backslash.

       Backticks are not supported.

       Variables are only substituted once. You cannot have variables in vari-
       ables. If you need this feature, please request it.

       Outside quotes, arguments from the pre- and postjob are split on linear
       whitespace. The backslash makes the next character verbatim.

       Variables  that are rewritten must start with a dollar sign either out-
       side quotes or inside double quotes. The dollar may be  followed  by  a
       valid identifier. A valid identifier starts with a letter or the under-
       score. A valid identifier may contain further letters, digits or under-
       scores. The identifier is case sensitive.

       The  alternative  use is to enclose the identifier inside curly braces.
       In this case, almost any  character  is  allowed  for  the  identifier,
       including  whitespace. This is the _o_n_l_y curly brace expansion. No other
       Bourne magic involving curly braces is supported.

       One of the advantages of variable substitution  is,  for  example,  the
       ability to specify the application as _$_H_O_M_E_/_b_i_n_/_a_p_p_1 in the transforma-
       tion catalog, and thus to gridstart. As long as your home directory  on
       any compute node has a _b_i_n directory that contains the application, the
       transformation catalog does not need to care about the true location of
       the  application  path  on each pool. Even better, an administrator may
       decide to move your home directory to a different place. As long as the
       compute  node  is  set  up  correctly, you don't have to adjust any VDS
       data.

       Mind that variable substitution is an expert feature, as some degree of
       tricky  quoting  is  required  to  protect  substitutable variables and
       quotes from Globus, Condor and VDS in that order. Note that Condor uses
       the dollar sign for its own variables.

       The  variable substitution assumptions for the main job differ slightly
       from the prejob and  postjob  for  technical  reasions.  The  pre-  and
       postjob  commandlines  are passed as one string. However, the main jobs
       commandline is already split into pieces by the time it  reaches  kkiicckk--
       ssttaarrtt.  Thus, any whitespace on the main job's commandline must be pre-
       served, and further argument splitting avoided.

       It is highly recommended to experiment on the Unix commandline with the
       _e_c_h_o and _e_n_v applications to obtain a feeling for the different quoting
       mechanisms needed to achieve variable substitution.

FFEEEEDDBBAACCKK CCHHAANNNNEELL
       A long-running application may consider to stream back heart beats  and
       other  application-specific  monitoring  and  progress  data.  For this
       reason, _k_i_c_k_s_t_a_r_t provides a feedback channel. At start-up, a transient
       named  pipe,  also known as FIFO, is created. While waiting for started
       jobs to finish, _k_i_c_k_s_t_a_r_t will  attempt  to  read  from  the  FIFO.  By
       default,  any  information  read  will be encapsulated in XML tags, and
       written to _s_t_d_e_r_r _.  Please note that in a VDS, Globus, Condor-G  envi-
       ronment,  _s_t_d_e_r_r will be GASS streamed or staged to the submit host. At
       the submit host, an application specific monitor may  unpack  the  data
       chunks  and could for instance visually display them, or aggregate them
       with other data. Please note that _k_i_c_k_s_t_a_r_t only  provides  a  feedback
       channel.  The content and interpretation is up to, and specific for the
       application.

       In order to make an application gridstart aware, it needs to be able to
       write  to  a  FIFO.  The filename can be picked up from the environment
       variable GGRRIIDDSSTTAARRTT__CCHHAANNNNEELL which is provided to all jobs.  Please  note
       that  the  application  must be prepared to handle the PIPE signal when
       writing to a FIFO, and must be able to cope with failing  write  opera-
       tions.

EEXXAAMMPPLLEE
       You  can  run  the  kkiicckkssttaarrtt  executable locallly to verify that it is
       functioning well. In the initial phase, the format of  the  performance
       data may be slightly adjusted.

       $ env GRIDSTART_PREJOB='/bin/usleep 250000' \
         GRIDSTART_POSTJOB='/bin/date -u' \
         kickstart -l xx \$PEGASUS_HOME/bin/keg -T1 -o-
       $ cat xx
       <?xml version="1.0" encoding="ISO-8859-1"?>
         ...
         </statcall>
       </invocation>

       Please take note a few things in the above example:

       The  output  from the postjob is appended to the output of the main job
       on _s_t_d_o_u_t.  The output could potentially be  separated  into  different
       data  sections through different temporary files. If you truly need the
       separation, request that feature.

       The log file is reported with a size of zero, because the log file  did
       indeed  barely  exist at the time the data structure was (re-) initial-
       ized. With regular GASS output, it will report the status of the socket
       file descriptor, though.

       The file descriptors reported for the temporary files are from the per-
       spective of kkiicckkssttaarrtt.  Since the temporary files  have  the  close-on-
       exec  flag  set,  kkiicckkssttaarrtt's  filedescriptors are invisible to the job
       processes. Still, the _s_t_d_i_o of the job processes are connected  to  the
       temporary files.

       Even  this  output already appears large. The output may already be too
       large to guarantee that the append operation on networked pipes  (GASS,
       NFS) are atomically written.

       The current format of the performance data is as follows:

OOUUTTPPUUTT FFOORRMMAATT
       Refer to hhttttpp::////wwwwww..ggrriipphhyynn..oorrgg//wwoorrkkssppaaccee//VVDDSS//iivv--11..44//iivv--11..44..hhttmmll for an
       up-to-date description of elements and  their  attributes.  Check  with
       hhttttpp::////wwwwww..ggrriipphhyynn..oorrgg//wwoorrkkssppaaccee//VVDDSS// for IV schemas with a higher ver-
       sion number.

RREESSTTRRIICCTTIIOONNSS
       There is no version for the Condor _s_t_a_n_d_a_r_d universe. It is simply  not
       possible within the constraints of Condor.

       Due  to  its  very  nature, kkiicckkssttaarrtt will also prove difficult to port
       outside the Unix environment.

       Any of the pre-, main-, cleanup and postjob are unable to influence one
       anothers visible environment.

       Do not use a VDL definition with just the name _n_u_l_l and no namespace or
       version.

       First Condor, and then Unix, place a limit on the length of the comman-
       dline.   The additional space required for the gridstart invocation may
       silently overflow the maximum space, and cause applications to fail. If
       you  suspect  to  work  with  many argument, try an argument-file based
       approach.

       A job failing with exit code 126 or 127 is indistinguishable from kkiicckk--
       ssttaarrtt  failing with the same exit codes. Sometimes, careful examination
       of the returned data can help.

       If the logfile is collected into a shared file, due to the size of  the
       data,  simultaneous  appends  on  a  shared  filesystem  from different
       machines may still mangle data. Currently, file  locking  is  not  even
       attempted, although all data is written atomically from the perspective
       of kkiicckkssttaarrtt.

       The upper limit of characters of commandline  characters  is  currently
       not  checked  by  kkiicckkssttaarrtt.   Thus,  some variable substitutions could
       potentially result in a commandline that is larger than permissable.

       If the output or error file is opened in append mode, but the  applica-
       tion decides to truncate its output file, as in aboves example by open-
       ing _/_d_e_v_/_f_d_/_1 inside _k_e_g, the resulting file will still  be  truncated.
       This is correct behavior, but sometimes not obvious.

FFIILLEESS
       $$PPEEGGAASSUUSS__HHOOMMEE//eettcc//iivv--11..66..xxssdd
              is  the  suggested  location of the latest XML schema describing
              the data on the submit host.

EENNVVIIRROONNMMEENNTT VVAARRIIAABBLLEESS
       GGRRIIDDSSTTAARRTT__TTMMPP
              is the hightest priority to look for a temporary  directory,  if
              specified.  This rather special variable was introduced to over-
              come some peculiarities with the FNAL cluster.

       TTMMPP    is the next hightest priority to look for a temporary directory,
              if specified.

       TTEEMMPP   is the next priority for an environment variable denoting a tem-
              porary files directory.

       TTMMPPDDIIRR is next in the checklist. If none of these are found, either the
              _s_t_d_i_o definition _P___t_m_p_d_i_r is taken, or the fixed string _/_t_m_p _.

       GGRRIIDDSSTTAARRTT__SSEETTUUPP
              contains  a string that starts a job to be executed uncondition-
              ally before any other jobs, see above for a  detailled  descrip-
              tion.

       GGRRIIDDSSTTAARRTT__PPRREEJJOOBB
              contains  a  string  that starts a job to be executed before the
              main job, see above for a detailled description.

       GGRRIIDDSSTTAARRTT__PPOOSSTTJJOOBB
              contains a string that starts a job to be executed conditionally
              after the main job, see above for a detailled description.

       GGRRIIDDSSTTAARRTT__CCLLEEAANNUUPP
              contains  a string that starts a job to be executed uncondition-
              ally after any of the previous jobs, see above for  a  detailled
              description.

       GGRRIIDDSSTTAARRTT__CCHHAANNNNEELL
              is the name of a FIFO for an application-specific feedback-chan-
              nel, see above for a detailled description.

AAUUTTHHOORRSS
       Michael Milligan <mbmillig@uchicago.edu>,
       Jens-S. Vöckler <voeckler@cs.uchicago.edu>,
       Mike Wilde <wilde@mcs.anl.gov>,
       Yong Zhao <yongzh@cs.uchicago.edu>.

       Virtual Data System hhttttpp::////vvddss..iissii..eedduu// and hhttttpp::////vvddss..uucchhiiccaaggoo..eedduu//
       GriPhyN hhttttpp::////wwwwww..ggrriipphhyynn..oorrgg//



GriPhyN Virtual Data System          1.0.0                        kickstart(1)
