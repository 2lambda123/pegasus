<?xml version="1.0" encoding="UTF-8"?>
<chapter>
  <title id="grid">Conventions for Running Pegasus on the Grid</title>

  <para>This document describes the conventions for workflow execution and job
  management needed to run workflows across multiple Grid sites.</para>

  <section>
    <title>Data Files</title>

    <para>We first need to define how file names are referenced and processed.
    Pegasus is concerned with three kinds of file names:</para>

    <para><emphasis role="bold">LFN:</emphasis> the logical filenames used in
    the DAX. LFNs may be relative or absolute, and may or may not have multiple
    directory levels in them. When a LFN is looked up in a replica catalog (RC),
    it is looked up in its relative or absolute form, exactly as it is coded in
    the DAX file. Similarly, when an instance of an LFN is produced at a Grid
    site, it is stored in the RC exactly as it was coded in the DAX.</para>

    <para><emphasis role="bold">SFN:</emphasis> the physical “storage”
    filenames, as files are referenced by user jobs running at a grid
    site</para>

    <para><emphasis role="bold">TFN:</emphasis> the physical “transfer”
    filenames (i.e., complete URLs), as files are accessed by the GridFTP
    protocol, both inside and outside_ the site.</para>

    <para>LFNs and SFNs are issues that the user needs to be concerned about.
    For the most part, the formation and use of the TFN happens automatically in
    the code generated by Pegasus. The user does not need to be aware of this
    coding of file names, other than to make sure that the GridFTP server is
    properly configured and identified to the site catalog. The important
    concept to understand here is how these names are used as a workflow is
    planned and executed on the Grid. File names are translated to SFNs by the
    workflow executor, and used by the programs that are executed in the
    workflow.</para>

    <para>Input files are looked up in the Replica Catalog and copied to the
    site where the job will run, if they don’t already exist at that site. In
    Pegasus v 2.0 RLS <link linkend="grid">(</link><ulink
    url="http://www.globus.org/rls">http://www.globus.org/rls/ </ulink>), DB
    backend via JDBC and a Simple File are the available implementations of a
    replica catalog.</para>

    <para>Programs start in their working directory (i.e., their “current
    working directory” (CWD) is set to the working directory before the job is
    started). When jobs execute, they reference their input files using names
    that have been translated into physical “storage file names” or SFNs. They
    create new output files at or below this current working directory. When
    jobs complete, any files they create that were designated in the DAX as
    “output” files are cataloged as existing at the site. In some cases, these
    files may be moved within the site for persistence. We anticipate that some
    jobs will need to have a “bigger” workspace, and may create files above or
    below their CWD . It is possible, but rare, that jobs will exist that cannot
    be accommodated by this model. Sometimes it may be necessary to adjust a
    job’s parameters in order to get it to conform to this model. For programs
    that expect input files:</para>

    <orderedlist>
      <listitem>
        <para>files should be pre-cataloged in the Replica Catalog by the
        logical name (LFN) exactly as coded in the DAX</para>
      </listitem>

      <listitem>
        <para>the PFN in the Replica Catalog must be a TFN that can be used to
        retrieve the file.</para>
      </listitem>

      <listitem>
        <para>the file is copied by Pegasus-inserted code to the storage
        directory(sdir), under the name relative to the LFN (regardless of
        whether the LFN is relative or absolute)</para>
      </listitem>

      <listitem>
        <para>the SFN produced by Pegasus and placed in the command line is the
        file’s relative name within the sdir.</para>
      </listitem>
    </orderedlist>
  </section>

  <section>
    <title>Layout of a Grid Site</title>

    <section>
      <title>Grids Sites Properties</title>

      <para>A Grid site, typically represented in a site monitoring entity ,
      consists of the following storage areas:</para>

      <itemizedlist>
        <listitem>
          <para><emphasis><emphasis role="bold">$DATA</emphasis></emphasis>:
          where users can create and leave persistent files, typically under
          VO-specific directory hierarchies.</para>
        </listitem>

        <listitem>
          <para><emphasis role="bold">$APP</emphasis>: where users can create
          and leave application files and directories, typically under
          VO-specific directory hierarchies.</para>
        </listitem>

        <listitem>
          <para><emphasis role="bold">$TMP</emphasis>: place to create temporary
          directories for the duration of a job or workflow. Typically shared by
          all users of the Grid site, and reachable and sharable by all worker
          nodes.</para>
        </listitem>

        <listitem>
          <para><emphasis role="bold">$WN_TMP</emphasis>: place to create
          temporary directories on the local disk of the worker node. The local
          disk provides speed-up to IO intensive file operations, e.g. database
          searches.</para>
        </listitem>

        <listitem>
          <para><emphasis role="bold">$GRID:</emphasis> location of the OSG (or
          VDT) software stack, under which we can expect the base directory for
          the Globus and Pegasus worker tools installation.</para>
        </listitem>
      </itemizedlist>
    </section>

    <section>
      <title>Description of Grid Sites in Pegasus</title>

      <para>Pegasus defines the following concepts:</para>

      <para>Each site has a grid storage directory (“<emphasis
      role="bold">sdir</emphasis>”) that contains files that persist at the
      site:</para>

      <itemizedlist>
        <listitem>
          <para>all files in the <emphasis role="bold">sdir</emphasis> are
          tracked in the Replica Catalog. The files that are transferred as part
          of the workflow description to the <emphasis
          role="bold">sdir</emphasis> are automatically registered in the
          Replica Catalog. The user can however explicitly ask them not to be
          registered using the transience attribute (dontRegister) in the
          DAX.</para>
        </listitem>

        <listitem>
          <para>all files must be accessible via gridftp to the Pegasus submit
          hosts that run jobs at the site. Jobs are run at each site in (or
          below) a “working directory” (<emphasis
          role="bold">workdir</emphasis>)</para>
        </listitem>

        <listitem>
          <para>the <emphasis role="bold">workdir</emphasis> is created when the
          site is set up for the user</para>
        </listitem>

        <listitem>
          <para>a temporary “<emphasis role="bold">job directory</emphasis>” may
          be created within the workdir for the duration of the workflow or
          partition and destroyed when the workflow completes or partition
          completes.</para>
        </listitem>

        <listitem>
          <para>A job starts with its CWD set to the jobdir(or the workdir).
          Hence relative pathnames referenced by a job are relative to this
          CWD.</para>

          <note>
            <para>Pegasus currently does not create per job temporary directory.
            It expects the application to create unique files or create unique
            job directories itself if two or more jobs will produce output with
            the same file.</para>
          </note>
        </listitem>
      </itemizedlist>

      <para>Currently a submit host must be able to access any site's sdir,
      workdir, and jobdir via gridftp. These directories are specified in the
      site catalog as follows (using XML as the example here):</para>

      <programlisting>&lt;site handle="chalant" gridlaunch="/home/pegasu/bin/kickstart"
sysinfo="cpuarch"&gt;
&lt;lrc url="rls://pegasus.isi.edu"/&gt;
&lt;gridftp url="gsiftp://pegasus.isi.edu"
storage="/home/pegasus" …/&gt;
&lt;workdirectory &gt;/home/pegasus&lt;/workdirectory&gt;
&lt;jobmanager ..… /&gt;
&lt;/site&gt;</programlisting>

      <para>In XPath syntax we have the following fields of interest: <code>
      </code></para>

      <itemizedlist>
        <listitem>
          <para>sdir = site/gridftp@storage</para>
        </listitem>

        <listitem>
          <para>gftp = site/gridftp@url</para>
        </listitem>

        <listitem>
          <para>workdir = site/workdirectory</para>
        </listitem>
      </itemizedlist>

      <para>We also need to define how file names are referenced and processed:
      <code> </code></para>

      <itemizedlist>
        <listitem>
          <para>LFN <code>a/b/c</code></para>
        </listitem>

        <listitem>
          <para>SFN <code>&lt;workdir&gt;/a/b/c</code></para>
        </listitem>

        <listitem>
          <para>TFN <code>&lt;gftp&gt;&lt;workdir&gt;/a/b/c</code></para>
        </listitem>
      </itemizedlist>

      <para>Pegasus assumes that workdir is accessible, and that sdir is a
      separate storage location it can use to stage data to/from. Pegasus does
      not distinguish between internal and external paths to the same data. The
      external path to workdir is constructed as gftp + workdir.</para>
    </section>

    <section>
      <title>Pegasus File Management Conventions</title>

      <para>We describe what happens at run time in a Pegasus DAG:</para>

      <itemizedlist>
        <listitem>
          <para>for setup</para>
        </listitem>

        <listitem>
          <para>for stage-in</para>
        </listitem>

        <listitem>
          <para>for compute job filenames</para>
        </listitem>

        <listitem>
          <para>for stage-out</para>
        </listitem>

        <listitem>
          <para>for replicas</para>
        </listitem>

        <listitem>
          <para>for inter-pool transfers</para>
        </listitem>

        <listitem>
          <para>for cleanup</para>
        </listitem>
      </itemizedlist>

      <para>We also specify related aspects of the compute job (filename
      arguments - how are they created) and replica registration (what TFN is
      registered). Given the following site catalog excerpt:</para>

      <itemizedlist>
        <listitem>
          <para>site 1</para>

          <itemizedlist>
            <listitem>
              <para>wdir1</para>
            </listitem>

            <listitem>
              <para>sdir</para>
            </listitem>

            <listitem>
              <para>gridftp=gsiftp://HOST1</para>
            </listitem>
          </itemizedlist>
        </listitem>

        <listitem>
          <para>site 2</para>

          <itemizedlist>
            <listitem>
              <para>wdir2</para>
            </listitem>

            <listitem>
              <para>sdir2</para>
            </listitem>

            <listitem>
              <para>gridftp=gsiftp://HOST2</para>
            </listitem>
          </itemizedlist>
        </listitem>
      </itemizedlist>

      <para>In addition, Pegasus allows the users to specify a relative path or
      an absolute path in the properties file that applies to all the sites.
      Given the following properties excerpt:</para>

      <itemizedlist>
        <listitem>
          <para>vds.dir.exec <emphasis>pwdir</emphasis></para>
        </listitem>

        <listitem>
          <para>vds.dir.storage <emphasis>psdir</emphasis></para>
        </listitem>
      </itemizedlist>

      <para>Depending upon whether <emphasis>pwdir/psdir</emphasis> is relative
      or absolute the <emphasis>wdir/sdir</emphasis> are either appended or
      replaced.</para>

      <table frame="box" rules="all">
        <caption></caption>

        <col align="center" span="1" />

        <tbody>
          <tr>
            <th></th>

            <td>pwdir</td>

            <td>psdir</td>
          </tr>

          <tr>
            <th>XXdir is relative</th>

            <td>wdir1 = wdir1 + pwdir</td>

            <td>sdir1 = sdir + psdir</td>
          </tr>

          <tr>
            <th>XXdir is absolute</th>

            <td>wdir1 == pwdir</td>

            <td>sdir1 == psdir</td>
          </tr>
        </tbody>
      </table>

      <para>All subsequent filename resolutions below assume that the above
      transformations have taken place.</para>

      <section id="sec.231">
        <title id="sec.231.title">Setup Job</title>

        <para>Pegasus uses a setup job to create the remote<emphasis>
        jdir1</emphasis> from <emphasis>wdir1</emphasis> for a partition of a
        workflow. A partition can be as large as the full workflow, or as small
        as a single job. By default the full workflow constitutes one partition.
        The job directory is created by appending a random string to the wdir
        directory. Thus, the jdir is a function of</para>

        <itemizedlist>
          <listitem>
            <para>wdir:jdir1 := wdir1 + random</para>
          </listitem>
        </itemizedlist>

        <para>One setup job is created for each execution site, where the
        portions of a partition have been scheduled. All jobs of the same
        partition and scheduled for the same site share the same
        <emphasis>jdir1</emphasis>.</para>
      </section>

      <section>
        <title>Stage In</title>

        <para>Pegasus distinguishes between direct (peer to peer) transfers and
        3rd-party transfers (3pt). For the replica catalog look-ups, it uses the
        LFN to find entries. In direct transfer mode, one or more transfer jobs
        run on the gatekeeper to pull files:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := pfn_from_replica_catalog(LFN)</para>
          </listitem>

          <listitem>
            <para>dTFN := file:// + jdir1 + LFN</para>
          </listitem>
        </itemizedlist>

        <para>In 3rd party transfer mode (set by specifying the property
        pgs.transfer.thirdparty.sites), the transfers are initiated from the
        submit host between the remote source servers and destination
        server:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := pfn_from_replica_catalog(LFN)</para>
          </listitem>

          <listitem>
            <para>dTFN := gsiftp://HOST1 + jdir1 + LFN</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Compute Job</title>

        <para>All the compute jobs are run in the jdir directory. The
        <emphasis>jdir</emphasis> directory is determined as explained in
        <emphasis role="bold">‎ </emphasis><xref linkend="sec.231" /> . All
        references to filenames on the command-line are relative to the jdir1.
        Since filenames are flattened, the following translation into SFNs
        applies.</para>

        <itemizedlist>
          <listitem>
            <para>SFN := jdir1 + LFN</para>
          </listitem>
        </itemizedlist>

        <para>The filenames actually used are stripped of their <emphasis>jdir1
        </emphasis>prefix to generate relative paths to files. The command-line
        arguments that derive from filenames are resolved relative to the CWD,
        and contain only the LFN.</para>
      </section>

      <section>
        <title>Stage Out</title>

        <para>The stage-out distinguished between direct (peer to peer)
        transfers and 3rd party transfers (set by specifying the property
        pgs.transfer.thirdparty.sites). For direct transfers, files movement is
        initiated on the remote site between:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := file:// + jdir1 + LFN</para>
          </listitem>

          <listitem>
            <para>dTFN := gsiftp://HOST2 + sdir2 + LFN</para>
          </listitem>
        </itemizedlist>

        <para>In 3rd party transfer mode, file transfer is directed from the
        submit host between:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := gsiftp://HOST1 + jdir1 + LFN</para>
          </listitem>

          <listitem>
            <para>dTFN := gsiftp://HOST2 + sdir2 + LFN</para>
          </listitem>
        </itemizedlist>

        <para>In the above, the site2 stands in as the output pool where
        appropriately tagged result files are to be transferred to.</para>
      </section>

      <section>
        <title>Replica Registration</title>

        <para>Files marked for registration are registered with the replica
        catalog. The Replica Catalog where to register is picked up from the
        site catalog or the properties file and corresponds to the output site
        that the user specifies at runtime. The file to register for a given LFN
        uses the dTFN of the stage-out.</para>

        <itemizedlist>
          <listitem>
            <para>gsiftp://HOSTxxxx + sdirX + LFN</para>
          </listitem>
        </itemizedlist>

        <para>The replica that is registered in the replica catalog, is the one
        residing on the output site i.e the replica that was staged to the
        output site by the stageout job. The replica’s that are on the execution
        sites are not catalogued currently, as they are usually on scratch space
        that can be purged according to the site’s policy or by the cleanup
        mechanism in Pegasus.</para>
      </section>

      <section>
        <title>Inter-pool Transfer</title>

        <para>Inter-pool transfer jobs are a variant of stage-in jobs, and are
        created under the following conditions:</para>

        <itemizedlist>
          <listitem>
            <para>A job X is scheduled at site1.</para>
          </listitem>

          <listitem>
            <para>Its immediate parent P(X) is scheduled at site2 unequal
            site1</para>
          </listitem>

          <listitem>
            <para>Job X requires an input file that is generated by job
            P(X).</para>
          </listitem>
        </itemizedlist>

        <para>Again, in direct (peer to peer) transfers, the transfer job or
        jobs are executed on the destination site with the following filename
        translations:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := gsiftp://HOST1 +<code> jdir1 </code>+ LFN</para>
          </listitem>

          <listitem>
            <para>dTFN := file:// + <code>jdir2 </code>+ LFN</para>
          </listitem>
        </itemizedlist>

        <para>In 3rd party transfer mode, the following transfers are directed
        from the submit host:</para>

        <itemizedlist>
          <listitem>
            <para>sTFN := gsiftp://HOST1 + <code>jdir1</code> + LFN</para>
          </listitem>

          <listitem>
            <para>dTFN := gsiftp://HOST2 + <code>jdir2 </code>+ LFN</para>
          </listitem>
        </itemizedlist>

        <para>The jdir directory is determined as explained in <xref
        linkend="sec.231" /></para>
      </section>

      <section>
        <title>Clean-up Job</title>

        <para>When Pegasus setup jobs created partition-specific remote job
        directories, a clean-up DAG is generated. The submit files for the
        clean-up DAG are generated in a cleanup directory in the partition’s or
        workflow's submit directory. The clean-up DAG consists of clean-up jobs
        for each execution site, where the portions of the partition were
        scheduled and run. The clean-up DAG is not submitted automatically, and
        has to be submitted manually by the user.</para>

        <para>A new feature in Pegasus also allows cleanup of files from the
        remote jdir while the workflow is running. This feature is enabled by
        default and can be turned off by using the option --nocleanup on the
        command line to Pegasus. This cleanup features adds cleanup jobs at
        various positions to cleanup files which are no longer needed for
        further execution of the workflow. This results in effective usage of
        remote site disk space.</para>
      </section>

      <section>
        <title>Future Extensions to the Site Catalog</title>

        <para>We need the separate storage dir for staging and storing files,
        and a work directory to run jobs. We need to know, how to access these
        directories both, from the inside and from the outside. Thus, we need,
        in addition to what the site catalog provides today,</para>

        <itemizedlist>
          <listitem>
            <para>a storage dir element for the inside view.</para>
          </listitem>

          <listitem>
            <para>a workdir gridftp path for outside view of the workdir.</para>
          </listitem>
        </itemizedlist>

        <para>Some sites may not permit outside access to the workdir, or inside
        access to the storage dir, e.g. LCG2. Such a site requires 2nd-level
        staging. We will deal with these another time.</para>

        <para><programlisting>&lt;directory type="working" url="gsiftp://host1" internal="dir1"
 external="dir2"&gt;

&lt;directory type="storage" url="gsiftp://host2" internal="dir3"
 external="dir4"&gt;</programlisting></para>

        <para>Pegasus constructs the external view of the working directory by
        adding the site catalog's wdir1 to the gridftp base URI. Pegasus
        constructs transfer filenames (TFN) according to the XPath syntax from
        section 1.2.3 as per the following rule</para>

        <itemizedlist>
          <listitem>
            <para>TFN := pool/gridftp@url + pool/workdirectory+ LFN</para>
          </listitem>
        </itemizedlist>

        <para>The TFNs constructed according to the above rule are listed by
        transfer job type below:</para>

        <itemizedlist>
          <listitem>
            <para>Stagein jobs : dTFN</para>
          </listitem>

          <listitem>
            <para>Interpool jobs : both sTFN and dTFN</para>
          </listitem>

          <listitem>
            <para>Stageout jobs : sTFN</para>
          </listitem>
        </itemizedlist>

        <para>Bringing in a notion of explicitly defining a gridftp server with
        the storagedir and workdir will solve this problem: We do not have to
        use the gsiftp URI from the storagedir to get the outside view to the
        workdir. The external view of the <code>wdir1 </code>can now be
        correctly constructed from the correct knowledge. In XPath syntax from
        the above excerpt, the resulting filename becomes:</para>

        <itemizedlist>
          <listitem>
            <para>TFN := directory[@type="working"]@url +
            directory[@type="working"]@external + LFN</para>
          </listitem>
        </itemizedlist>

        <para>Since we know how to access each file system inside as well as
        from the outside, it will be a much better and more flexible
        design.</para>
      </section>
    </section>
  </section>
</chapter>