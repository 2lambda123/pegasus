<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="monitoring_debugging_stats">
  <title>Monitoring, Debugging and Statistics</title>

  <section>
    <title>Introduction</title>

    <para>Pegasus comes bundled with useful tools that help users debug
    workflows and generate useful statistics and plots about their workflow
    runs. These tools internally parse the Condor log files and have a similar
    interface. With the exception of pegasus-monitord (see below), all tools
    take in the submit directory as an argument. Users can invoke the tools
    listed in this chapter as follows</para>

    <programlisting>$ pegasus-[toolname]   &lt;path to the submit directory&gt;</programlisting>
  </section>

  <section>
    <title>Monitoring and Debugging</title>

    <para>As the number of jobs and tasks in workflows increase, the ability
    to track the progress and quickly debug a workflow becomes more and more
    important. Pegasus comes with a series of utilities that can be used to
    monitor and debug workflows both in real-time as well as after execution
    is already completed.</para>

    <section>
      <title>pegasus-monitord</title>

      <para>pegasus-monitord is used to follow a workflow, parsing the output
      of DAGMan's dagman.out file. In addition to generating the jobstate.log
      file, which contains the various states that a job goes through during
      the workflow execution, pegasus-monitord can also be used to mine
      information from jobs' submit and output files, and either populate a
      database, or write a file with NetLogger events containing this
      information.</para>

      <para>pegasus-monitord is automatically invoked by pegasus-run, and
      tracks workflows in real-time. By default, it produces the jobstate.log
      file, and a SQLite database, which contains all the information listed
      in the Stampede schema. When a workflow fails, and is re-submitted with
      a rescue DAG, pegasus-monitord will automatically pick up from where it
      left previously and continue to write the jobstate.log file and populate
      the database.</para>

      <para>If, after the workflow has already finished, users need to
      re-create the jobstate.log file, or re-populate the database from
      scratch, pegasus-monitord's --replay option should be used when running
      it manually. In addition to SQLite, pegasus-monitord supports other
      types of databases, such as MySQL and Postgres. Users will need to
      install the low-level database drivers, and should consult
      pegasus-monitord's man page for more detailed information.</para>

      <para>As an example:</para>

      <para><programlisting>$ pegasus-monitord -r diamond-0.dag.dagman.out</programlisting>will
      launch pegasus-monitord in replay mode. In this case, if a jobstate.log
      file already exists, it will be rotated and a new file will be created.
      It will also create/use a SQLite database in the workflow's run
      directory, with the name of diamond-0.stampede.db. If the database
      already exists, it will make sure to remove any references to the
      current workflow before it populates the database. In this case,
      pegasus-monitord will process the workflow information from start to
      finish, including any restarts that may have happened.</para>

      <para>One important detail is that while processing a workflow,
      pegasus-monitord will automatically detect if/when sub-workflows are
      initiated, and will automatically track those sub-workflows as well. In
      this case, although pegasus-monitord will create a separate jobstate.log
      file in each workflow directory, the database at the top-level workflow
      will contain the information from not only the main workflow, but also
      from all sub-workflows.</para>
    </section>

    <section>
      <title>pegasus-status</title>

      <para>To monitor the execution of the workflow lets run the
      pegasus-status command as suggested by the output of the pegasus-run
      command above.</para>

      <programlisting><emphasis role="bold">$ pegasus-status -l</emphasis> <replaceable>/Workflow/dags/directory</replaceable>

Workflow_1-0.dag succeeded
10/01/10 12:24:38  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/01/10 12:24:38   ===     ===      ===     ===     ===        ===      ===
10/01/10 12:24:38    48       0        5       0       5          0        0

WORKFLOW STATUS : RUNNING | 48/58 ( 83% ) | (workflow is running)</programlisting>

      <para>To see the jobs in the queue while the workflow is running you can
      run the pegasus-status without the -l option as shown below.</para>

      <programlisting>$ <emphasis>pegasus-status /nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0002</emphasis>


-- Submitter: smarty.isi.edu : &lt;128.9.72.26:53194&gt; : smarty.isi.edu
 ID      OWNER/NODENAME   SUBMITTED     RUN_TIME ST PRI SIZE CMD
22417.0   gmehta          7/11 18:13   0+00:03:58 R  0   9.8  condor_dagman -f -
22423.0    |-rc_tx_analy  7/11 18:16   0+00:00:54 R  2   0.0  kickstart -n pegas
22424.0    |-rc_tx_findr  7/11 18:16   0+00:00:00 I  2   0.0  kickstart -n pegas
22425.0    |-rc_tx_prepr  7/11 18:16   0+00:00:00 I  2   0.0  kickstart -n pegas</programlisting>

      <para>If you do not see any of your job in the output of pegasus status
      or if the the pegasus-status says FAILED or Completed 100% then the
      workflow has </para>

      <itemizedlist>
        <listitem>
          <para>successfully completed</para>
        </listitem>

        <listitem>
          <para>stopped midway due to non recoverable error.</para>
        </listitem>
      </itemizedlist>
    </section>

    <section>
      <title>pegasus-analyzer</title>

      <para>pegasus-analyzer is a command-line utility for parsing several
      files in the workflow directory and summarizing useful information to
      the user. It should be used after the workflow has already finished
      execution. pegasus-analyzer quickly goes through the jobstate.log file,
      and isolates jobs that did not complete successfully. It then parses
      their submit, and kickstart output files, printing to the user detailed
      information for helping the user debug what happened to his/her
      workflow.</para>

      <para>The simplest way to invoke pegasus-analyzer is to simply give it a
      workflow run directory, like in the example below:</para>

      <para><programlisting>$ pegasus-analyzer -d /home/user/run0004
pegasus-analyzer: initializing...

************************************Summary*************************************

 Total jobs         :     26 (100.00%)
 # jobs succeeded   :     25 (96.15%)
 # jobs failed      :      1 (3.84%)
 # jobs unsubmitted :      0 (0.00%)

******************************Failed jobs' details******************************

============================register_viz_glidein_7_0============================

 last state: POST_SCRIPT_FAILURE
       site: local
submit file: /home/user/run0004/register_viz_glidein_7_0.sub
output file: /home/user/run0004/register_viz_glidein_7_0.out.002
 error file: /home/user/run0004/register_viz_glidein_7_0.err.002

--------------pegasus::rc-client - pegasus::rc-client:1.0 - stdout--------------

2009-02-20 16:25:13.467 ERROR [root] You need to specify the pegasus.catalog.replica property
2009-02-20 16:25:13.468 WARN  [root] non-zero exit-code 1</programlisting>In
      the case above, pegasus-analyzer's output contains a brief summary
      section, showing how many jobs have succeeded and how many have failed.
      After that, pegasus-analyzer will print information about each job that
      failed, showing its last known state, along with the location of its
      submit, output, and error files. pegasus-analyzer will also display any
      stdout and stderr from the job, as recorded in its kickstart record.
      Please consult pegasus-analyzer's man page for more examples and a
      detailed description of its various command-line options.</para>
    </section>

    <section>
      <title>pegasus-remove</title>

      <para>If you want to abort your workflow for any reason you can use the
      pegasus-remove command listed in the output of pegasus-run invocation or
      by specifiying the Dag directory for the workflow you want to
      terminate.</para>

      <programlisting><emphasis role="bold">$ <emphasis role="bold">pegasus-remove </emphasis></emphasis><replaceable>/PATH/To/WORKFLOW DIRECTORY</replaceable></programlisting>
    </section>

    <section>
      <title>Resubmitting failed workflows</title>

      <para>Pegasus will remove the DAGMan and all the jobs related to the
      DAGMan from the condor queue. A rescue DAG will be generated in case you
      want to resubmit the same workflow and continue execution from where it
      last stopped. A rescue DAG only skips jobs that have completely
      finished. It does not continue a partially running job unless the
      executable supports checkpointing.</para>

      <para>To resubmit an aborted or failed workflow with the same submit
      files and rescue Dag just rerun the pegasus-run command</para>

      <programlisting>$ <emphasis>pegasus-run -Dpegasus.user.properties=/nfs/asd2/gmehta/PEGASUS/dags\
/gmehta/pegasus/black-diamond/run0001/pegasus.61698.properties \
--nodatabase /nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0001
</emphasis></programlisting>
    </section>
  </section>

  <section>
    <title>Plotting and Statistics</title>

    <para></para>

    <section>
      <title>pegasus-statistics</title>

      <para>pegasus-statistics generates workflow execution statistics. To
      generate statistics run the command as shown below.</para>

      <programlisting>$ <emphasis>pegasus-statistics /scratch/grid-setup/run0001/</emphasis>


...

******************************************** SUMMARY ********************************************
Total workflow execution time      :         1741 
Total workflow execution wall time :      276.963 
Total jobs                         :           17 
Total tasks                        :           17 
# jobs succeeded                   :           17 
# jobs failed                      :            0 
# jobs unsubmitted                 :            0 
# jobs unknown                     :            0 

Workflow execution statistics created at :
/scratch/grid-setup/run0001/statistics/workflow

Workflow events with time starting with zero is created at :
/scratch/grid-setup/run0001/statistics/out

Job statistics is created at : 
/scratch/grid-setup/run0001/statistics/jobs

Logical transformation statistics is created at :
/scratch/grid-setup/run0001/statistics/breakdown.txt
**************************************************************************************************</programlisting>

      <para>By default the output gets generated to statistics folder inside
      the submit directory. pegasus-statistics generates the following
      statistics list and tables.</para>

      <para><emphasis role="bold">Workflow statistics table</emphasis></para>

      <para>Workflow statistics table contains information about the workflow
      run like total execution time, job's failed etc. A sample table is shown
      below.</para>

      <para><link linkend="???">/scratch/grid-setup/run0001</link></para>

      <table>
        <title>Table 3.1</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry>Total workflow execution time</entry>

              <entry>1741</entry>
            </row>

            <row>
              <entry>Total workflow execution wall time</entry>

              <entry>276.963</entry>
            </row>

            <row>
              <entry>Total jobs</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry>Total tasks</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs succeeded</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs failed</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unsubmitted</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unknown</entry>

              <entry>0</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><link linkend="???">All</link></para>

      <table>
        <title>Table 3.2</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry>Total workflow execution time</entry>

              <entry>1741</entry>
            </row>

            <row>
              <entry>Total workflow execution wall time</entry>

              <entry>276.963</entry>
            </row>

            <row>
              <entry>Total jobs</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry>Total tasks</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs succeeded</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs failed</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unsubmitted</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unknown</entry>

              <entry>0</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><emphasis role="bold">Job statistics table</emphasis></para>

      <para>Job statistics table contains the following details about the jobs
      in the workflow. A sample table is shown below.</para>

      <itemizedlist>
        <listitem>
          <para>Job - the name of the job</para>
        </listitem>

        <listitem>
          <para>Site - the site where the job ran</para>
        </listitem>

        <listitem>
          <para>Kickstart - the actual duration of the job in seconds on the
          remote compute node</para>
        </listitem>

        <listitem>
          <para>Post - the postscript time as reported by DAGMan</para>
        </listitem>

        <listitem>
          <para>DAGMan - the time between the last parent job of a job
          completes and the job gets submitted</para>
        </listitem>

        <listitem>
          <para>CondorQTime - the time between submission by DAGMan and the
          remote Grid submission. It is an estimate of the time spent in the
          condor q on the submit node</para>
        </listitem>

        <listitem>
          <para>Resource - the time between the remote Grid submission and
          start of remote execution . It is an estimate of the time job spent
          in the remote queue</para>
        </listitem>

        <listitem>
          <para>Runtime - the time spent on the resource as seen by Condor
          DAGMan . Is always &gt;=kickstart</para>
        </listitem>

        <listitem>
          <para>CondorQLen - the number of outstanding jobs in the queue when
          this job was released</para>
        </listitem>

        <listitem>
          <para>Seqexec - the time taken for the completion of a clustered
          job</para>
        </listitem>

        <listitem>
          <para>Seqexec-Delay- the time difference between the time for the
          completion of a clustered job and sum of all the individual tasks
          kickstart time</para>
        </listitem>
      </itemizedlist>

      <table>
        <title>Table 3.3</title>

        <tgroup align="center" cols="11">
          <thead>
            <row>
              <entry align="center">Job</entry>

              <entry align="center">Site</entry>

              <entry align="center">Kickstart</entry>

              <entry align="center">Post</entry>

              <entry align="center">DAGMan</entry>

              <entry align="center">CondorQTime</entry>

              <entry align="center">Resource</entry>

              <entry align="center">Runtime</entry>

              <entry align="center">CondorQLen</entry>

              <entry align="center">Seqexec</entry>

              <entry align="center">Seqexec-Delay</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>analyze_ID0000004</entry>

              <entry>ISIViz</entry>

              <entry>60.16</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>23.00</entry>

              <entry>145.00</entry>

              <entry>160.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_analyze_ID0000004</entry>

              <entry>ISIViz</entry>

              <entry>8.05</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>15.00</entry>

              <entry>20.00</entry>

              <entry>101.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_findrange_ID0000003</entry>

              <entry>ISIViz</entry>

              <entry>0.97</entry>

              <entry>5.00</entry>

              <entry>8.00</entry>

              <entry>10.00</entry>

              <entry>5.00</entry>

              <entry>110.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_preprocess_ID0000001</entry>

              <entry>ISIViz</entry>

              <entry>1.00</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>20.00</entry>

              <entry>0.00</entry>

              <entry>20.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_stage_out_local_ISIViz_0_0</entry>

              <entry>ISIViz</entry>

              <entry>0.99</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>20.00</entry>

              <entry>0.00</entry>

              <entry>150.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_stage_out_local_ISIViz_1_0</entry>

              <entry>ISIViz</entry>

              <entry>1.16</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>17.00</entry>

              <entry>5.00</entry>

              <entry>15.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>clean_up_stage_out_local_ISIViz_2_0</entry>

              <entry>ISIViz</entry>

              <entry>10.28</entry>

              <entry>6.00</entry>

              <entry>7.00</entry>

              <entry>15.00</entry>

              <entry>20.00</entry>

              <entry>100.00</entry>

              <entry>2</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>create_dir_diamond_0_ISIViz</entry>

              <entry>ISIViz</entry>

              <entry>0.33</entry>

              <entry>5.00</entry>

              <entry>14.00</entry>

              <entry>15.00</entry>

              <entry>0.00</entry>

              <entry>20.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>findrange_ID0000002</entry>

              <entry>ISIViz</entry>

              <entry>60.25</entry>

              <entry>6.00</entry>

              <entry>7.00</entry>

              <entry>21.00</entry>

              <entry>20.00</entry>

              <entry>290.00</entry>

              <entry>3</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>findrange_ID0000003</entry>

              <entry>ISIViz</entry>

              <entry>60.37</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>26.00</entry>

              <entry>25.00</entry>

              <entry>822.00</entry>

              <entry>2</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>preprocess_ID0000001</entry>

              <entry>ISIViz</entry>

              <entry>60.48</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>15.00</entry>

              <entry>20.00</entry>

              <entry>235.00</entry>

              <entry>1</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>register_ISIViz_2_0</entry>

              <entry>local</entry>

              <entry>3.58</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>5.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>stage_in_local_ISIViz_0</entry>

              <entry>local</entry>

              <entry>1.88</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>stage_out_local_ISIViz_0_0</entry>

              <entry>local</entry>

              <entry>1.82</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>5.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>stage_out_local_ISIViz_1_0</entry>

              <entry>local</entry>

              <entry>1.72</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>5.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>stage_out_local_ISIViz_1_1</entry>

              <entry>local</entry>

              <entry>2.15</entry>

              <entry>5.00</entry>

              <entry>6.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>

            <row>
              <entry>stage_out_local_ISIViz_2_0</entry>

              <entry>local</entry>

              <entry>1.76</entry>

              <entry>5.00</entry>

              <entry>7.00</entry>

              <entry>0.00</entry>

              <entry>0.00</entry>

              <entry>5.00</entry>

              <entry>0</entry>

              <entry>-</entry>

              <entry>-</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><emphasis role="bold">Logical transformation statistics
      table</emphasis></para>

      <para>Logical transformation statistics table contains information about
      each type of transformation in the workflow. A sample table is shown
      below.</para>

      <para><link linkend="???">/scratch/grid-setup/run0001</link></para>

      <table>
        <title>Table 3.4</title>

        <tgroup align="center" cols="7">
          <thead>
            <row>
              <entry align="center">Transformation</entry>

              <entry align="center">Count</entry>

              <entry align="center">Mean</entry>

              <entry align="center">Variance</entry>

              <entry align="center">Min</entry>

              <entry align="center">Max</entry>

              <entry align="center">Total</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>pegasus::dirmanager</entry>

              <entry>1</entry>

              <entry>0.33</entry>

              <entry>0.00</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>
            </row>

            <row>
              <entry>diamond::analyze:2.0</entry>

              <entry>1</entry>

              <entry>60.16</entry>

              <entry>0.00</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>
            </row>

            <row>
              <entry>diamond::findrange:2.0</entry>

              <entry>2</entry>

              <entry>60.31</entry>

              <entry>0.01</entry>

              <entry>60.25</entry>

              <entry>60.37</entry>

              <entry>120.62</entry>
            </row>

            <row>
              <entry>diamond::preprocess:2.0</entry>

              <entry>1</entry>

              <entry>60.48</entry>

              <entry>0.00</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>
            </row>

            <row>
              <entry>pegasus::cleanup</entry>

              <entry>6</entry>

              <entry>3.74</entry>

              <entry>18.15</entry>

              <entry>0.97</entry>

              <entry>10.28</entry>

              <entry>22.46</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><link linkend="???">All</link></para>

      <table>
        <title>Table 3.5</title>

        <tgroup align="center" cols="7">
          <thead>
            <row>
              <entry align="center">Transformation</entry>

              <entry align="center">Count</entry>

              <entry align="center">Mean</entry>

              <entry align="center">Variance</entry>

              <entry align="center">Min</entry>

              <entry align="center">Max</entry>

              <entry align="center">Total</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>pegasus::dirmanager</entry>

              <entry>1</entry>

              <entry>0.33</entry>

              <entry>0.00</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>
            </row>

            <row>
              <entry>diamond::analyze:2.0</entry>

              <entry>1</entry>

              <entry>60.16</entry>

              <entry>0.00</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>
            </row>

            <row>
              <entry>diamond::findrange:2.0</entry>

              <entry>2</entry>

              <entry>60.31</entry>

              <entry>0.01</entry>

              <entry>60.25</entry>

              <entry>60.37</entry>

              <entry>120.62</entry>
            </row>

            <row>
              <entry>diamond::preprocess:2.0</entry>

              <entry>1</entry>

              <entry>60.48</entry>

              <entry>0.00</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>
            </row>

            <row>
              <entry>pegasus::cleanup</entry>

              <entry>6</entry>

              <entry>3.74</entry>

              <entry>18.15</entry>

              <entry>0.97</entry>

              <entry>10.28</entry>

              <entry>22.46</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><emphasis role="bold">Workflow events list</emphasis></para>

      <para>Workflow events list contains the events listed with time starting
      with zero. A sample list is shown below.</para>

      <programlisting>1287528335 INTERNAL *** MONITORD_STARTED ***
0 INTERNAL *** DAGMAN_STARTED 517.0 ***
14 create_dir_diamond_0_ISIViz SUBMIT 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz EXECUTE 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz GLOBUS_SUBMIT 518.0 ISIViz - 1
29 create_dir_diamond_0_ISIViz GRID_SUBMIT 518.0 ISIViz - 1
49 create_dir_diamond_0_ISIViz JOB_TERMINATED 518.0 ISIViz - 1
....
1741 clean_up_stage_out_local_ISIViz_2_0 POST_SCRIPT_SUCCESS 0 ISIViz - 16
1741 clean_up_analyze_ID0000004 POST_SCRIPT_TERMINATED 534.0 ISIViz - 17
1741 clean_up_analyze_ID0000004 POST_SCRIPT_SUCCESS 0 ISIViz - 17
1741 INTERNAL *** DAGMAN_FINISHED 0 ***
1287530077 INTERNAL *** MONITORD_FINISHED 0 ***</programlisting>
    </section>

    <section>
      <title>pegasus-plot</title>

      <para>pegasus-plot generates graphs and charts to visualize workflow
      execution. To generate graphs and charts run the command as shown
      below.</para>

      <programlisting>$ <emphasis>pegasus-plot /scratch/grid-setup/run0001/</emphasis>


...

******************************************** SUMMARY ********************************************
The workflow execution Gantt chart is created at -
png format :- /scratch/grid-setup/run0001/graph/diamond-2.png 
eps format :- /scratch/grid-setup/run0001/graph/diamond-2.eps 

The host over time chart is created at -
png format :-/scratch/grid-setup/run0001/graph/diamond-host.png 
eps format :-/scratch/grid-setup/run0001/graph/diamond-host.eps

JPEG file corresponding to the dag is created at: 
/scratch/grid-setup/run0001/graph/diamond-dag.jpg 

JPEG file corresponding to the dax is created at: 
/scratch/grid-setup/run0001/graph/blackdiamond-dax.jpg 
**************************************************************************************************</programlisting>

      <para>By default the output gets generated to graph folder inside the
      submit directory. pegasus-plot generates the following graphs and
      charts.</para>

      <para><emphasis role="bold">Gantt workflow execution
      chart</emphasis></para>

      <para>Gantt chart of the workflow execution run. A sample chart is shown
      below.</para>

      <figure>
        <title>Figure 4.1</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/diamond-2.png" />
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold">Host over time chart</emphasis></para>

      <para>Host over time chart of the workflow execution run. A sample chart
      is shown below.</para>

      <figure>
        <title>Figure 4.2</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/diamond-host.png" />
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold">Dag Graph</emphasis></para>

      <para>Graph representation of the DAG file. A sample graph is shown
      below.</para>

      <figure>
        <title>Figure 4.3</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/diamond-dag.jpg" />
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold">Dax Graph</emphasis></para>

      <para>Graph representation of the DAX file. A sample graph is shown
      below.</para>

      <figure>
        <title>Figure 4.4</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/blackdiamond-dax.jpg" />
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </section>
</chapter>
