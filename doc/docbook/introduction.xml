<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="introduction">
  <title>Introduction to Pegasus</title>

  <para><ulink url="http://pegasus.isi.edu">Pegasus</ulink> is a configurable
  system for mapping and executing abstract application workflows over a wide
  range of execution environment including a laptop, a campus cluster, a Grid,
  or a commercial or academic cloud. Today, Pegasus runs workflows on Amazon
  EC2, Nimbus, Open Science Grid, the TeraGrid, and many campus clusters. One
  workflow can run on a single system or across a heterogeneous set of
  resources. Pegasus can run workflows ranging from just a few computational
  tasks up to 1 million. </para>

  <para>An abstract application workflow is represented as a directed acyclic
  graph where the vertices are the compute tasks and the edges represent the
  data dependencies between the tasks. The input to Pegasus is a description
  of the abstract workflow in XML format.</para>

  <para>The Pegasus Workflow Management System consists of three main
  components: the Pegasus mapper, Condor DAGMan, and the Condor schedd. The
  mapping of tasks to the execution resources is done by the mapper based on
  information derived for static and/or dynamic sources. In some cases
  information systems already in place provide the information about the
  execution environment and the location of data. In other cases, users
  specify this information. The output is an executable workflow (also called
  the concrete workflow) that can be executed over a variety of resources. In
  case the workflow tasks are mapped to multiple resources that do not share a
  file system, explicit nodes are added to the workflow for orchestrating data
  transfer between the tasks.</para>

  <para>DAGMan relies on the resources (compute, storage and network) defined
  in the executable workflow to perform the necessary actions. Individual
  workflow tasks are managed by a task scheduler, which supervises their
  execution on local and remote resources. In our work scheduling is performed
  by the schedd a component in the Condor Project.</para>

  <para>When errors occur, Pegasus tries to recover when possible by retrying
  tasks, by retrying the entire workflow, by providing workflow-level
  checkpointing, by re-mapping portions of the workflow, by trying alternative
  data sources for staging data, and, when all else fails, by providing a
  rescue workflow containing a description of only the work that remains to be
  done. It cleans up storage as the workflow is executed so that
  data-intensive workflows have enough space to execute on storage-constrained
  resource. Pegasus keeps track of what has been done (provenance) including
  the locations of data used and produced, and which software was used with
  which parameters.</para>

  <para>Pegasus comes with a set of tools that help monitor the progress of
  the workflow and collect statistics and performance profiles of the
  workflows. Pegasus WMS is a user-side application that can be deployed
  locally by a scientist with no support from a site administrator and has no
  impact on the target cyberinfrastructure sites. A collaboration can set up a
  submit host, which hosts the workflow management system. Jobs are sent from
  the submit host to the campus cluster, the Open Science Grid, the TeraGrid,
  the cloud, or other resources.</para>

  <para>Pegasus is currently supports applications in a <ulink
  url="http://pegasus.isi.edu/applications.php">number of scientific
  domains</ulink> including astronomy, bioinformatics, earthquake science,
  gravitational wave physics, ocean science, limnology, and others</para>

  <para>Pegasus related publications are available <ulink
  url="http://pegasus.isi.edu/publications.php">here</ulink> .</para>
</chapter>
