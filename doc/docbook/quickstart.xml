<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="quickstart">
  <title>Pegasus Quick Start Guide</title>

  <section>
    <title>Getting Started</title>

    <para>This document is structured to get you and up running with the
    Pegasus planner with minimal effort.</para>

    <para>Download the latest release of Pegasus WMS 3.0 from <ulink
    url="http://pegasus.isi.edu/wms/download.php">http://pegasus.isi.edu/wms/download.php</ulink></para>

    <para>For convenience, there are Pegasus WMS tarballs which has Condor
    included. This way you can instlal Pegasus and Condor at the same time,
    with just minor configuration to get up and running.</para>

    <para>To run Pegasus you will need</para>

    <itemizedlist>
      <listitem>
        <para>JAVA 1.6</para>
      </listitem>

      <listitem>
        <para>Python 2.6</para>
      </listitem>

      <listitem>
        <para>Perl</para>
      </listitem>
    </itemizedlist>

    <para>Check Java version and ensure it is JAVA 1.6.x</para>

    <screen><command>$ java -version</command><computeroutput>

java version "1.5.0_07"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-164)
Java HotSpot(TM) Client VM (build 1.5.0_07-87, mixed mode, sharing)</computeroutput></screen>

    <para>To install Pegsus</para>

    <itemizedlist>
      <listitem>
        <para>Untar the tarball. The code will be untarred in a directory
        pegasus-&lt;version&gt;. Lets call this PEGASUS_HOME. Change
        PEGASUS_HOME on the command line to the directory where you untarred
        the code.</para>

        <para><screen><code><command>$ tar zxf pegasus-wms-*.tar.gz</command></code></screen></para>
      </listitem>

      <listitem>
        <para>Edit the Condor Configuration file located at
        PEGASUS_HOME/etc/condor_config (Additional configuration may be
        required for Production Environment).</para>

        <orderedlist>
          <listitem>
            <para>Change !!PEGASUS_HOME!! to the actual path where PEGASUS_WMS
            is installed</para>
          </listitem>

          <listitem>
            <para>CHANGE !!USER!! to the user who will receive email in case
            of error. (This can generally be just your username )</para>
          </listitem>
        </orderedlist>

        <para><screen><command>$ vim $PEGASUS_HOME/etc/condor_config</command><computeroutput>

RELEASE_DIR = !!PEGASUS_HOME!!    # CHANGE THIS TO PATH OF PEGASUS_WMS INSTALLATION

CONDOR_ADMIN = !!USER!! # CHANGE THIS To THE USER WHO wILL GET EMAIL INCASE OF ERROR.</computeroutput></screen></para>
      </listitem>

      <listitem>
        <para>Set up the environment:</para>

        <para><screen><command>$ export PATH=PEGASUS_HOME/bin:PEGASUS_HOME/condor/bin:$PATH
$ export CONDOR_CONFIG=PEGASUS_HOME/etc/condor_config</command></screen></para>
      </listitem>

      <listitem>
        <para>Start Condor by running ./sbin/condor_master</para>

        <para><screen><command>$ PEGASUS_HOME/sbin/condor_master</command></screen></para>
      </listitem>

      <listitem>
        <para>Check if condor is up by running the condor_q command</para>

        <para><screen><command>$ condor_q</command>

<computeroutput>-- Submitter: gmehta@smarty.isi.edu : &lt;128.9.72.26:60126&gt; : smarty.isi.edu
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               

0 jobs; 0 idle, 0 running, 0 held</computeroutput></screen></para>
      </listitem>
    </itemizedlist>

    <para>This guide assumes you are using a Bourne Shell derived shell. e.g.
    /bin/sh or /bin/bash.</para>
  </section>

  <section>
    <title>Abstract Workflow (DAX)</title>

    <para>Pegasus uses an XML format to describe the input abstract workflow
    (DAX). The DAX is divided into 5 sections.</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">Replica Catalog Section:</emphasis> This
        section lists all the files used in the workflow. They can be of type
        input, output, inout or executable. You can define the physical paths
        to the file. These files can also be describe in a separate Replica
        Catalog. See the Chapter on <link linkend="catalogs">Catalogs</link> .
        This Section is optional.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Transformation Catalog Section:</emphasis>
        This section lists all the executables used in the workflow. You can
        define the physical paths to the executable either here or in a
        separate Transformation Catalog. See the Chapter on <link
        linkend="catalogs">Catalogs</link> . This Section is optional</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Complex Transformation:</emphasis> This
        section lists any complex transformation (Transformation requiring
        additional transformations/executables). This section is
        optional.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Tasks:</emphasis> This section lists all
        the tasks of type jobs, dax or dags in the workflow. Along with the
        tasks are arguments required to invoke the tasks, any profiles that
        may be associated with the tasks and any files used as input or output
        by the task.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Dependencies:</emphasis> This section
        lists all the dependencies betweeen the tasks in the workflow.</para>
      </listitem>
    </itemizedlist>
  </section>

  <section>
    <title>Catalogs</title>

    <para>Pegasus uses several catalogs to help in its planning. These
    catalogs need to be setup or defined inside the DAX before Pegasus can
    plan a workflow. The catalogs used by Pegasus are :</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">Replica Catalog</emphasis><emphasis
        role="bold">:</emphasis> This catalog is used to lookup the location
        of input data as well as any existing output data referenced in the
        abstract workflow.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Site Catalog</emphasis><emphasis
        role="bold">:</emphasis> This catalog is used to track information
        about the various sites and their layout on the grid.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Transformation Catalog</emphasis><emphasis
        role="bold">:</emphasis> This catalog is used to lookup information
        about the location of executables (transformation) installed or
        available for staging on the Grid.</para>
      </listitem>
    </itemizedlist>

    <para>You can ignore this for now as we will setup everything that you
    require to run locally on your system. If you want to learn about the
    various catalogs and implementations in detail you can refer to the <link
    linkend="catalogs">Catalogs</link> guide.</para>
  </section>

  <section>
    <title>Running Pegasus</title>

    <para>Pegasus plans an abstract workflow (DAX) into a concrete/executable
    workflow by querying various catalogs listed above and performing several
    refinement steps. We have already setup all the catalogs required by
    Pegasus in the previous sections and also configured properties that will
    affect how Pegasus plans the workflow.</para>

    <para>Pegasus planner is invoked on the command line by running the
    pegasus-plan command. The client takes several parameters including one or
    more sites where to compute the workflow, an optional single site if the
    output data needs to be staged and stored and the input DAX file.</para>

    <section id="example_black_diamond" xreflabel="Black Diamond">
      <title>Running a Diamond Workflow</title>

      <para>Pegasus is shipped with a Diamond example. The example we are
      going to run is found at PEGASUS_HOME/examples/condor-blackdiamond. Lets
      change into the example directory</para>

      <screen><command>$ cd</command> <computeroutput>PEGASUS_HOME/examples/condor-blackdiamond</computeroutput></screen>

      <para>The workflow has 4 nodes, layed out in a diamond shape, with files
      being passed between them (f.*):</para>

      <mediaobject>
        <imageobject>
          <imagedata align="center" fileref="images/examples-diamond.jpg"
                     valign="middle" />
        </imageobject>
      </mediaobject>

      <para>The binary for the nodes is a simple "mock application" name
      <command>keg</command> ("canonical example for the grid") which reads
      input files designated by arguments, writes them back onto output files,
      and produces on STDOUT a summary of where and when it was run. Keg ships
      with Pegasus in the bin directory.</para>

      <para>This example ships with a "submit" script which will build the
      replica catalog, the transformation catalog, and the site catalog. When
      you create your own workflows, such a submit script is not needed if you
      want to maintain those catalogs manually.</para>

      <note>
        <para>The use of <filename>./submit</filename> scripts in this example
        are just to make it more easy to run the examples out of the
        box.</para>
      </note>

      <para>To test the examples, edit the <command>submit</command> script
      and change the cluster config to the setup and install locations for
      your cluster. Then run:</para>

      <para><screen><command>$ ./submit condor</command></screen></para>

      <para>The workflow should now be submitted in the local condor and in
      the output you should see a work dir location for the instance. With
      that directory you can monitor the workflow as mentioned </para>

      <para>Now lets see what happened at the backend.</para>

      <para>The submit script generates a DAX representation of the workflow
      by compiling and running the BlackDiamondDAX.java code. Pegasus provides
      several ways to generate your abstract workflow (DAX). </para>

      <itemizedlist>
        <listitem>
          <para>JAVA API</para>
        </listitem>

        <listitem>
          <para>PERL API</para>
        </listitem>

        <listitem>
          <para>PYTHON API</para>
        </listitem>
      </itemizedlist>

      <para>You can read the <link linkend="api">API chapter</link> on the
      details about writing your own workflow generator using our API's</para>

      <para>After generating the blackdiamond.dax file the script creates the
      site catalog required to run the workflow on the local node and writes
      out the required pegasus properties file "pegasurc"</para>

      <para></para>

      <para>Two directories are created work and output. The workflow gets
      generated and execute </para>
    </section>
  </section>

  <section>
    <title>Monitoring, Debugging and Statistics</title>

    <section>
      <title>pegasus-status</title>

      <para>To monitor the execution of the workflow lets run the
      pegasus-status command as suggested by the output of the pegasus-run
      command above.</para>

      <screen><emphasis role="bold">$ pegasus-status -l</emphasis> <replaceable>/Workflow/dags/directory</replaceable>

<computeroutput>blackdiamond-0.dag is running.
11/24/10 16:06:48  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
11/24/10 16:06:48   ===     ===      ===     ===     ===        ===      ===
11/24/10 16:06:48     2       0        1       0       0         12        0
</computeroutput></screen>

      <para>After the workflow finishes the status will change to COMPLETED or
      FAILED..</para>

      <screen><emphasis role="bold">$ pegasus-status -l</emphasis> <replaceable>/Workflow/dags/directory</replaceable>

<computeroutput>blackdiamond-0.dag succeeded
11/24/10 16:11:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
11/24/10 16:11:09   ===     ===      ===     ===     ===        ===      ===
11/24/10 16:11:09    15       0        0       0       0          0        0

WORKFLOW STATUS : COMPLETED | 15/15 ( 100% ) | (all jobs finished successfully)</computeroutput></screen>

      <para></para>
    </section>

    <section>
      <title>pegasus-analyzer</title>

      <para>If the workflow fails the you can anlyze the run using the tool
      pegasus-analyzer.</para>

      <para>The simplest way to invoke pegasus-analyzer is to simply give it a
      workflow run directory, like in the example below:</para>

      <para><screen><command>$ pegasus-analyzer -d </command><replaceable>/PATH/To/WORKFLOW DIRECTORY</replaceable>

<computeroutput>pegasus-analyzer: initializing...

************************************Summary*************************************

 Total jobs         :     26 (100.00%)
 # jobs succeeded   :     25 (96.15%)
 # jobs failed      :      1 (3.84%)
 # jobs unsubmitted :      0 (0.00%)

******************************Failed jobs' details******************************

============================register_viz_glidein_7_0============================

 last state: POST_SCRIPT_FAILURE
       site: local
submit file: /home/user/run0004/register_viz_glidein_7_0.sub
output file: /home/user/run0004/register_viz_glidein_7_0.out.002
 error file: /home/user/run0004/register_viz_glidein_7_0.err.002

-------------------------------Task #1 - Summary--------------------------------

site        : local
executable  : /lfs1/software/install/pegasus/default/bin/rc-client
arguments   : -Dpegasus.user.properties=/lfs1/work/pegasus/run0004/pegasus.15181.properties \
-Dpegasus.catalog.replica.url=rlsn://smarty.isi.edu --insert register_viz_glidein_7_0.in
exitcode    : 1
working dir : /lfs1/work/pegasus/run0004

---------Task #1 - pegasus::rc-client - pegasus::rc-client:1.0 - stdout---------

2009-02-20 16:25:13.467 ERROR [root] You need to specify the pegasus.catalog.replica property
2009-02-20 16:25:13.468 WARN  [root] non-zero exit-code 1</computeroutput></screen>In
      the case above, pegasus-analyzer's output contains a brief summary
      section, showing how many jobs have succeeded and how many have failed.
      After that, pegasus-analyzer will print information about each job that
      failed, showing its last known state, along with the location of its
      submit, output, and error files. pegasus-analyzer will also display any
      stdout and stderr from the job. </para>
    </section>

    <section>
      <title>pegasus-remove</title>

      <para>If you want to abort your workflow for any reason you can use the
      pegasus-remove command listed in the output of pegasus-run invocation or
      by specifiying the Dag directory for the workflow you want to
      terminate.</para>

      <screen><emphasis role="bold">$ <emphasis role="bold">pegasus-remove </emphasis></emphasis><replaceable>/PATH/To/WORKFLOW DIRECTORY</replaceable></screen>

      <para>Pegasus will remove the workflow from the condor queue. A rescue
      DAG will be generated in case you want to resubmit the same workflow and
      continue execution from where it last stopped. A rescue DAG only skips
      jobs that have completely finished. It does not continue a partially
      running job unless the executable supports checkpointing.</para>
    </section>

    <section>
      <title>Resubmitting failed workflows</title>

      <para>To resubmit an aborted or failed workflow with the same submit
      files and rescue Dag just rerun the pegasus-run command</para>

      <screen><command>$ pegasus-run -Dpegasus.user.properties=/nfs/asd2/gmehta/PEGASUS/dags\
/gmehta/pegasus/black-diamond/run0001/pegasus.61698.properties \
--nodatabase</command> <replaceable>/nfs/asd2/gmehta/PEGASUS/dags/gmehta/pegasus/black-diamond/run0001</replaceable>
</screen>
    </section>
  </section>

  <section>
    <title>Plotting and Statistics</title>

    <section>
      <title>pegasus-statistics</title>

      <para>pegasus-statistics generates workflow execution statistics. To
      generate statistics run the command as shown below.</para>

      <screen><command>$ pegasus-statistics</command> <replaceable>/scratch/grid-setup/run0001/</replaceable>


...

******************************************** SUMMARY ********************************************
Total workflow execution time      :         1741 
Total workflow execution wall time :      276.963 
Total jobs                         :           17 
Total tasks                        :           17 
# jobs succeeded                   :           17 
# jobs failed                      :            0 
# jobs unsubmitted                 :            0 
# jobs unknown                     :            0 

Workflow execution statistics created at :
/scratch/grid-setup/run0001/statistics/workflow

Workflow events with time starting with zero is created at :
/scratch/grid-setup/run0001/statistics/out

Job statistics is created at : 
/scratch/grid-setup/run0001/statistics/jobs

Logical transformation statistics is created at :
/scratch/grid-setup/run0001/statistics/breakdown.txt
**************************************************************************************************</screen>

      <para>By default the output gets generated to statistics folder inside
      the submit directory. pegasus-statistics generates the following
      statistics list and tables.</para>

      <para><emphasis role="bold">Workflow statistics table</emphasis></para>

      <para>Workflow statistics table contains information about the workflow
      run like total execution time, job's failed etc. A sample table is shown
      below.<link linkend="???"></link></para>

      <table>
        <title>Table 3.1</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry>Total workflow execution time</entry>

              <entry>1741</entry>
            </row>

            <row>
              <entry>Total workflow execution wall time</entry>

              <entry>276.963</entry>
            </row>

            <row>
              <entry>Total jobs</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry>Total tasks</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs succeeded</entry>

              <entry>17</entry>
            </row>

            <row>
              <entry># jobs failed</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unsubmitted</entry>

              <entry>0</entry>
            </row>

            <row>
              <entry># jobs unknown</entry>

              <entry>0</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para><emphasis role="bold">Logical transformation statistics
      table</emphasis></para>

      <para>Logical transformation statistics table contains information about
      each type of transformation in the workflow. A sample table is shown
      below.</para>

      <table>
        <title>Table 3.5</title>

        <tgroup align="center" cols="7">
          <thead>
            <row>
              <entry align="center">Transformation</entry>

              <entry align="center">Count</entry>

              <entry align="center">Mean</entry>

              <entry align="center">Variance</entry>

              <entry align="center">Min</entry>

              <entry align="center">Max</entry>

              <entry align="center">Total</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>pegasus::dirmanager</entry>

              <entry>1</entry>

              <entry>0.33</entry>

              <entry>0.00</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>

              <entry>0.33</entry>
            </row>

            <row>
              <entry>diamond::analyze:2.0</entry>

              <entry>1</entry>

              <entry>60.16</entry>

              <entry>0.00</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>

              <entry>60.16</entry>
            </row>

            <row>
              <entry>diamond::findrange:2.0</entry>

              <entry>2</entry>

              <entry>60.31</entry>

              <entry>0.01</entry>

              <entry>60.25</entry>

              <entry>60.37</entry>

              <entry>120.62</entry>
            </row>

            <row>
              <entry>diamond::preprocess:2.0</entry>

              <entry>1</entry>

              <entry>60.48</entry>

              <entry>0.00</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>

              <entry>60.48</entry>
            </row>

            <row>
              <entry>pegasus::cleanup</entry>

              <entry>6</entry>

              <entry>3.74</entry>

              <entry>18.15</entry>

              <entry>0.97</entry>

              <entry>10.28</entry>

              <entry>22.46</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section>
      <title>pegasus-plots</title>

      <para>pegasus-plots generates graphs and charts to visualize workflow
      execution. To generate graphs and charts run the command as shown
      below.</para>

      <screen><command>$ pegasus-plots</command> &lt;submit dag directory&gt;


<computeroutput>******************************************** SUMMARY ********************************************
The workflow execution Gantt chart is created at -
png format :- /scratch/grid-setup/run0001/graph/diamond-2.png 
eps format :- /scratch/grid-setup/run0001/graph/diamond-2.eps 

The host over time chart is created at -
png format :-/scratch/grid-setup/run0001/graph/diamond-host.png 
eps format :-/scratch/grid-setup/run0001/graph/diamond-host.eps

JPEG file corresponding to the dag is created at: 
/scratch/grid-setup/run0001/graph/diamond-dag.jpg 

JPEG file corresponding to the dax is created at: 
/scratch/grid-setup/run0001/graph/blackdiamond-dax.jpg 
**************************************************************************************************</computeroutput></screen>

      <para>By default the output gets generated to graph folder inside the
      submit directory. pegasus-plots generates the following graphs and
      charts.</para>

      <para><emphasis role="bold">Gantt workflow execution
      chart</emphasis></para>

      <para>Gantt chart of the workflow execution run. A sample chart is shown
      below.</para>

      <figure>
        <title>Figure 4.1</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/diamond-2.png" scalefit="true" />
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold"></emphasis></para>

      <para><emphasis role="bold">Dag Graph</emphasis></para>

      <para>Graph representation of the DAG file. A sample graph is shown
      below.</para>

      <figure>
        <title>Figure 4.3</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/diamond-dag.jpg" scale="50%" />
          </imageobject>
        </mediaobject>
      </figure>

      <para><emphasis role="bold">Dax Graph</emphasis></para>

      <para>Graph representation of the DAX file. A sample graph is shown
      below.</para>

      <figure>
        <title>Figure 4.4</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/blackdiamond-dax.jpg" scale="50%" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>For more options see the man page for pegasus-plots or the <xref
      linkend="monitoring_debugging_stats" /> section</para>
    </section>
  </section>
</chapter>
