<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="useful_tips" lang="">
    <title>Useful Tips</title>
  <section>
     <title>Running the VM with Virtual Box</title>



      <para>Follow these steps to add the vmdk file to Virtual Box and create a virtual machine inside the Virtual
      Box</para>

           <para>1. Launch Virtual Box on your machine.</para>


        <para><figure id="virtualboxhome">
        <title>Virtualbox Home</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/VirtualBoxHome.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

          <para>2. In the Icon Menu, select <emphasis role="bold">New</emphasis></para>


          <para>The Create New Virtual Machine Wizard Welcome window opens up.</para>

        <para><figure id="welcome">
        <title>Welcome Window</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard1.png"  width="5in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

          <para>3. Select <emphasis role="bold">Next</emphasis></para>
         <para><figure id="selectvm">
        <title>VM Name and OS Type</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard3.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

          <para>4. Enter a name for the virtual machine.</para>
          <para>5. Select <emphasis role="bold">Linux</emphasis> as the <emphasis role="bold">Operating System</emphasis> and
          <emphasis role="bold">Debian</emphasis>as the <emphasis role="bold">Version</emphasis>
          from the pull down menus. Select <emphasis role="bold">Next</emphasis></para>
           <para><figure id="namevm">
        <title>Base Memory</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard4.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>


          <para>6. Select the base recommended <emphasis role="bold">Base Memory Size</emphasis>
          then select <emphasis role="bold">Next</emphasis></para>

           <para><figure id="selectvmfile">
        <title>VM Name and OS Type</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard5.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>


         <para>7. Select <emphasis role="bold">Use existing hard disk</emphasis>.</para>

        <para>8. Open the file icon and navigate to the location of the <emphasis role="bold">Debian-6-86</emphasis> file
         downloaded earlier. Once a file has been selected, it is available in the pull down menu.</para>

        <para><figure id="selectfile">
        <title>Document Library</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard6.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>


         <para>9. Double click the <emphasis role="bold">Debian-6-86 </emphasis> file to launch the Create New Virtual Disk Wizard.</para>
          <para><figure id="doclib">
        <title/>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard7.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>
          <para>10. Select <emphasis role="bold">Next</emphasis></para>

          <para><figure id="virtdisk1">
        <title>Storage Type</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard8.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>



        <para>11. Select the desired storage type then select <emphasis role="bold">Next</emphasis></para>
          <para><figure id="virtdisklocation">
        <title>Virtual Disk Location and Size</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard9.png"  width="5in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

         <para>12. Select the desired location and virtual disk size, then select <emphasis role="bold">Next</emphasis></para>
          <para><figure id="summary">
        <title>Summary</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/Wizard10.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

         <para>13. Review the settings and select <emphasis role="bold">Finish</emphasis> to create
         the virtual disk or <emphasis role="bold">Cancel</emphasis> to cancel creation</para>

         <para>The VM is created and will appear in the VirtualBox Manager window in a powered off state</para>

         <para><figure id="virtboxpopulated">
        <title>Storage Type</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/VirtualBoxPopulated.png" width="4in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

      <para>14. Double click the VM to launch the First Run Wizard</para>

      <para><figure id="firstrunwizard">
        <title>First Run</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/FirstRun1.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>
      <para>15. Select <emphasis role="bold">Next</emphasis></para>


        <para>The Starting VM progress window opens and tracks the creation process</para>

        <para><figure id="progressbar">
        <title>Start Run 2</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/FirstRun2.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>
        <para>When completed the virtual home page page is displayed</para>

       <para><figure id="virthome">
        <title>Virtual Machine Home Page</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/VirtualHomePageLogged in.png" width="6in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>
         <para>16. Select <emphasis role="bold">Accessories - LX Terminal</emphasis> to open a terminal window.</para>
         <para><figure id="virtdisk2">
        <title>Select Terminal</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/SelectTerminal.png"  width="6in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>
      <para> When the virtual machine starts , it automatically logs you in
    as user <emphasis role="bold">tutorial</emphasis>.

     The Terminal Window opens:</para>

      <para><figure id="virtdisk3">
        <title>Storage Type</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/VMCommandWindow.png"  width="6in"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>



         <para>Note: The terminal window is the main interface for the walkthrough process.</para>

         <para>To continue with the walkthrough see <link linkend="walkthrough">Walkthrough Workflow </link></para>




  </section>


  <section>
  <title>Migrating From Pegasus 2.X to Pegasus 3.0</title>

    <para>With Pegasus 3.0 effort has been made to simplify configuration.
    This chapter is for existing users of Pegasus who use Pegasus 2.x to run
    their workflows and walks through the steps to move to using Pegasus
    3.0</para>

  <section>
    <title>PEGASUS_HOME and Setup Scripts</title>

    <para>Earlier versions of Pegasus required users to have the environment
    variable PEGASUS_HOME set and to source a setup file
    $PEGASUS_HOME/setup.sh | $PEGASUS_HOME/setup.csh before running Pegasus to
    setup CLASSPATH and other variables.</para>

    <para>Starting with Pegasus 3.0 this is no longer required. The above
    paths are automaticallly determined by the Pegasus tools when they are
    invoked.</para>

    <para>All the users need to do is to set the PATH variable to pick up the
    pegasus executables from the bin directory.</para>

    <programlisting>$ <emphasis role="bold">export PATH=/some/install/pegasus-3.0.0/bin:$PATH</emphasis></programlisting>
  </section>

  <section>
    <title>Changes to Schemas and Catalog Formats</title>

    <section>
      <title>DAX Schema</title>

      <para>Pegasus 3.0 by default now parses DAX documents conforming to the
      DAX Schema 3.2 available <ulink role=""
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.xsd"
      userlevel="">here</ulink> and is explained in detail in the chapter on
      API references.</para>

      <para>Starting Pegasus 3.0 , DAX generation API's are provided in
      Java/Python and Perl for users to use in their DAX Generators. The use
      of API's is highly encouraged. Support for the old DAX schema's has been
      deprecated and will be removed in a future version.</para>

      <para>For users, who still want to run using the old DAX formats i.e 3.0
      or earlier, can for the time being set the following property in the
      properties and point it to dax-3.0 xsd of the installation.</para>

      <programlisting><emphasis role="bold">pegasus.schema.dax  /some/install/pegasus-3.0/etc/dax-3.0.xsd</emphasis></programlisting>
    </section>

    <section>
      <title>Site Catalog Format</title>

      <para>Pegasus 3.0 by default now parses Site Catalog format conforming
      to the SC schema 3.0 ( XML3 ) available <ulink role=""
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.xsd"
      userlevel="">here</ulink> and is explained in detail in the chapter on
      Catalogs.</para>

      <para>Pegasus 3.0 comes with a pegasus-sc-converter that will convert
      users old site catalog ( XML ) to the XML3 format. Sample usage is given
      below.</para>

      <programlisting><emphasis role="bold">$ pegasus-sc-converter -i sample.sites.xml -I XML -o sample.sites.xml3 -O XML3
</emphasis>
2010.11.22 12:55:14.169 PST:   Written out the converted file to sample.sites.xml3 
</programlisting>

      <para>To use the converted site catalog, in the properties do the
      following</para>

      <orderedlist>
        <listitem>
          <para>unset pegasus.catalog.site or set pegasus.catalog.site to
          XML3</para>
        </listitem>

        <listitem>
          <para>point pegasus.catalog.site.file to the converted site
          catalog</para>
        </listitem>
      </orderedlist>
    </section>

    <section>
      <title>Transformation Catalog Format</title>

      <para>Pegasus 3.0 by default now parses a file based multiline textual
      format of a Transformation Catalog. The new Text format is explained in
      detail in the chapter on Catalogs.</para>

      <para>Pegasus 3.0 comes with a pegasus-tc-converter that will convert
      users old transformation catalog ( File ) to the Text format. Sample
      usage is given below.</para>

      <programlisting><emphasis role="bold">$ pegasus-tc-converter -i sample.tc.data -I File -o sample.tc.text -O Text
</emphasis>
2010.11.22 12:53:16.661 PST:   Successfully converted Transformation Catalog from File to Text 
2010.11.22 12:53:16.666 PST:   The output transfomation catalog is in file  /lfs1/software/install/pegasus/pegasus-3.0.0cvs/etc/sample.tc.text 
</programlisting>

      <para>To use the converted transformation catalog, in the properties do
      the following</para>

      <orderedlist>
        <listitem>
          <para>unset pegasus.catalog.transformation or set
          pegasus.catalog.transformation to Text</para>
        </listitem>

        <listitem>
          <para>point pegasus.catalog.transformation.file to the converted
          transformation catalog</para>
        </listitem>
      </orderedlist>
    </section>
</section>

  <section>
    <title>Properties and Profiles Simplification</title>

    <para>Starting with Pegasus 3.0 all profiles can be specified in the
    properties file. Profiles specified in the properties file have the lowest
    priority. Profiles are explained in the detail in the<link
    linkend="profiles"> Profiles</link>chapter. As a
    result of this a lot of existing Pegasus Properties were replaced by
    profiles. The table below lists the properties removed and the new profile
    based names.</para>

    <table>
      <title>Table 1: Property Keys removed and their Profile based
      replacement</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry><emphasis role="bold">Old Property Key</emphasis></entry>

            <entry><emphasis role="bold">New Property Key</emphasis></entry>
          </row>

          <row>
            <entry>pegasus.local.env</entry>

            <entry>no replacement. Specify env profiles for local site in the
            site catalog</entry>
          </row>

          <row>
            <entry>pegasus.condor.release</entry>

            <entry>condor.periodic_release</entry>
          </row>

          <row>
            <entry>pegasus.condor.remove</entry>

            <entry>condor.periodic_remove</entry>
          </row>

          <row>
            <entry>pegasus.job.priority</entry>

            <entry>condor.priority</entry>
          </row>

          <row>
            <entry>pegasus.condor.output.stream</entry>

            <entry>pegasus.condor.output.stream</entry>
          </row>

          <row>
            <entry>pegasus.condor.error.stream</entry>

            <entry>condor.stream_error</entry>
          </row>

          <row>
            <entry>pegasus.dagman.retry</entry>

            <entry>dagman.retry</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.impl</entry>

            <entry>dagman.post</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.scope</entry>

            <entry>dagman.post.scope</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.arguments</entry>

            <entry>dagman.post.arguments</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.path.*</entry>

            <entry>dagman.post.path.*</entry>
          </row>

          <row>
            <entry>pegasus.dagman.maxpre</entry>

            <entry>dagman.maxpre</entry>
          </row>

          <row>
            <entry>pegasus.dagman.maxpost</entry>

            <entry>dagman.maxpost</entry>
          </row>

          <row>
            <entry>pegasus.dagman.maxidle</entry>

            <entry>dagman.maxidle</entry>
          </row>

          <row>
            <entry>pegasus.dagman.maxjobs</entry>

            <entry>dagman.maxjobs</entry>
          </row>

          <row>
            <entry>pegasus.remote.scheduler.min.maxwalltime</entry>

            <entry>globus.maxwalltime</entry>
          </row>

          <row>
            <entry>pegasus.remote.scheduler.min.maxtime</entry>

            <entry>globus.maxtime</entry>
          </row>

          <row>
            <entry>pegasus.remote.scheduler.min.maxcputime</entry>

            <entry>globus.maxcputime</entry>
          </row>

          <row>
            <entry>pegasus.remote.scheduler.queues</entry>

            <entry>globus.queue</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <section>
      <title>Profile Keys for Clustering</title>

      <para>The pegasus profile keys for job clustering were <emphasis
      role="bold">renamed</emphasis>. The following table lists the old and
      the new names for the profile keys.</para>

      <table>
        <title>Table 2: Old and New Names For Job Clustering Profile
        Keys</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Old Pegasus Profile
              Key</emphasis></entry>

              <entry><emphasis role="bold">New Pegasus Profile
              Key</emphasis></entry>
            </row>

            <row>
              <entry>collapse</entry>

              <entry>clusters.size</entry>
            </row>

            <row>
              <entry>bundle</entry>

              <entry>clusters.num</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </section>

  <section>
    <title>Transfers Simplification</title>

    <para>Pegasus 3.0 has a new default transfer client pegasus-transfer that
    is invoked by default for first level and second level staging. The
    pegasus-transfer client is a python based wrapper around various transfer
    clients like globus-url-copy, lcg-copy, wget, cp, ln . pegasus-transfer
    looks at source and destination url and figures out automatically which
    underlying client to use. pegasus-transfer is distributed with the PEGASUS
    and can be found in the bin subdirectory .</para>

    <para>Also, the Bundle Transfer refiner has been made the default for
    pegasus 3.0. Most of the users no longer need to set any transfer related
    properties. The names of the profiles keys that control the Bundle
    Transfers have been changed . The following table lists the old and the
    new names for the Pegasus Profile Keys and are explained in details in the
    Profiles Chapter.</para>

    <table>
      <title>Table 3: Old and New Names For Transfer Bundling Profile
      Keys</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry><emphasis role="bold">Old Pegasus Profile
            Key</emphasis></entry>

            <entry><emphasis role="bold">New Pegasus Profile
            Keys</emphasis></entry>
          </row>

          <row>
            <entry>bundle.stagein</entry>

            <entry>stagein.clusters | stagein.local.clusters |
            stagein.remote.clusters</entry>
          </row>

          <row>
            <entry>bundle.stageout</entry>

            <entry>stageout.clusters | stageout.local.clusters |
            stageout.remote.clusters</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <section>
      <title>Worker Package Staging</title>

      <para>Starting Pegasus 3.0 there is a separate boolean property
      <emphasis role="bold">pegasus.transfer.worker.package</emphasis> to
      enable worker package staging to the remote compute sites. Earlier it
      was bundled with user executables staging i.e if <emphasis
      role="bold">pegasus.catalog.transformation.mapper</emphasis> property
      was set to Staged .</para>
    </section>
  </section>

  <section>
    <title>Clients in bin directory</title>

    <para>Starting with Pegasus 3.0 the pegasus clients in the bin directory
    have a pegasus prefix. The table below lists the old client names and new
    names for the clients that replaced them</para>

    <table>
      <title>Table 1: Old Client Names and their New Names</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry><emphasis role="bold">Old Client</emphasis></entry>

            <entry><emphasis role="bold">New Client</emphasis></entry>
          </row>

          <row>
            <entry>rc-client</entry>

            <entry>pegasus-rc-client</entry>
          </row>

          <row>
            <entry>tc-client</entry>

            <entry>pegasus-tc-client</entry>
          </row>

          <row>
            <entry>pegasus-get-sites</entry>

            <entry>pegasus-sc-client</entry>
          </row>

          <row>
            <entry>sc-client</entry>

            <entry>pegasus-sc-converter</entry>
          </row>

          <row>
            <entry>tailstatd</entry>

            <entry>pegasus-monitord</entry>
          </row>

          <row>
            <entry>genstats and genstats-breakdown</entry>

            <entry>pegasus-statistics</entry>
          </row>

          <row>
            <entry>show-job</entry>

            <entry>pegasus-plots</entry>
          </row>

          <row>
            <entry>cleanup</entry>

            <entry>pegasus-cleanup</entry>
          </row>

          <row>
            <entry>dirmanager</entry>

            <entry>pegasus-dirmanager</entry>
          </row>

          <row>
            <entry>exitcode</entry>

            <entry>pegasus-exitcode</entry>
          </row>

          <row>
            <entry>rank-dax</entry>

            <entry>pegasus-rank-dax</entry>
          </row>

          <row>
            <entry>transfer</entry>

            <entry>pegasus-transfer</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>
</section>

  <section>
    <title>Best Practices For Developing Portable Code</title>

    <para>This document lists out issues for the algorithm developers to keep
    in mind while developing the respective codes. Keeping these in mind will
    alleviate a lot of problems while trying to run the codes on the Grid
    through workflows.</para>

    <section>
      <title>Supported Platforms</title>

      <para>Most of the hosts making a Grid run variants of Linux or in some
      case Solaris. The Grid middleware mostly supports UNIX and it's
      variants.</para>

      <section>
        <title>Running on Windows</title>

        <para>The majority of the machines making up the various Grid sites
        run Linux. In fact, there is no widespread deployment of a
        Windows-based Grid. Currently, the server side software of Globus does
        not run on Windows. Only the client tools can run on Windows. The
        algorithm developers should not code exclusively for the Windows
        platforms. They must make sure that their codes run on Linux or
        Solaris platforms. If the code is written in a portable language like
        Java, then porting should not be an issue.</para>

        <para>If for some reason the code can only be executed on windows
        platform, please contact the pegasus team at pegasus aT isi dot edu .
        In certain cases it is possible to stand up a linux headnode in front
        of a windows cluster running Condor as it's scheduler.</para>
      </section>
    </section>

    <section>
      <title>Packaging of Software</title>

      <para>As far as possible, binary packages (preferably statically linked)
      of the codes should be provided. If for some reason the codes, need to
      be built from the source then they should have an associated makefile (
      for C/C++ based tools) or an ant file ( for Java tools). The building
      process should refer to the standard libraries that are part of a normal
      Linux installation. If the codes require non-standard libraries, clear
      documentation needs to be provided, as to how to install those
      libraries, and make the build process refer to those libraries.</para>

      <para>Further, installing software as root is not a possibility. Hence,
      all the external libraries that need to be installed can only be
      installed as non-root in non-standard locations.</para>
    </section>

    <section>
      <title>MPI Codes</title>

      <para>If any of the algorithm codes are MPI based, they should contact
      the Grid group. MPI can be run on the Grid but the codes need to be
      compiled against the installed MPI libraries on the various Grid sites.
      The pegasus group has some experience running MPI code through
      PBS.</para>
    </section>

    <section>
      <title>Maximum Running Time of Codes</title>

      <para>Each of the Grid sites has a policy on the maximum time for which
      they will allow a job to run. The algorithms catalog should have the
      maximum time (in minutes) that the job can run for. This information is
      passed to the Grid sites while submitting a job, so that Grid site does
      not kill a job before that published time expires. It is OK, if the job
      runs only a fraction of the max time.</para>
    </section>

    <section>
      <title>Codes cannot specify the directory in which they should be
      run</title>

      <para>Codes are installed in some standard location on the Grid Sites or
      staged on demand. However, they are not invoked from directories where
      they are installed. The codes should be able to be invoked from any
      directory, as long as one can access the directory where the codes are
      installed.</para>

      <para>This is especially relevant, while writing scripts around the
      algorithm codes. At that point specifying the relative paths do not
      work. This is because the relative path is constructed from the
      directory where the script is being invoked. A suggested workaround is
      to pick up the base directory where the software is installed from the
      environment or by using the <command>dirname</command> cmd or api. The
      workflow system can set appropriate environment variables while
      launching jobs on the Grid.</para>
    </section>

    <section>
      <title>No hard-coded paths</title>

      <para>The algorithms should not hard-code any directory paths in the
      code. All directories paths should be picked up explicitly either from
      the environment (specifying environment variables) or from command line
      options passed to the algorithm code.</para>
    </section>

    <section>
      <title>Wrapping legacy codes with a shell wrapper</title>

      <para>When wrapping a legacy code in a script (or another program), it
      is necessary that the wrapper knows where the executable lives. This is
      accomplished using an environmental variable. Be sure to include this
      detail in the component description when submitting a component for use
      on the Grid -- include a brief descriptive name like GDA_BIN.</para>
    </section>

    <section>
      <title>Propogating back the right exitcode</title>

      <para>A job in the workflow is only released for execution if its
      parents have executed successfully. Hence, it is very important that the
      algorithm codes exit with the correct error code in case of success and
      failure. The algorithms should exit with a status of 0 in case of
      success, and a non zero status in case of error. Failure to do so will
      result in erroneous workflow execution where jobs might be released for
      execution even though their parents had exited with an error.</para>

      <para>The algorithm codes should catch all errors and exit with a non
      zero exitcode. The successful execution of the algorithm code can only
      be determined by an exitcode of 0. The algorithm code should not rely
      upon something being written to the stdout to designate success for e.g.
      if the algorithm code writes out to the stdout SUCCESS and exits with a
      non zero status the job would be marked as failed.</para>

      <para>In *nix, a quick way to see if a code is exiting with the correct
      code is to execute the code and then execute echo $?.</para>

      <programlisting>$ component-x input-file.lisp
... some output ...
$ echo $?
0</programlisting>

      <para>If the code is not exiting correctly, it is necessary to wrap the
      code in a script that tests some final condition (such as the presence
      or format of a result file) and uses exit to return correctly.</para>
    </section>

    <section>
      <title>Static vs. Dynamically Linked Libraries</title>

      <para>Since there is no way to know the profile of the machine that will
      be executing the code, it is important that dynamically linked libraries
      are avoided or that reliance on them is kept to a minimum. For example,
      a component that requires libc 2.5 may or may not run on a machine that
      uses libc 2.3. On *nix, you can use the <command>ldd</command> command
      to see what libraries a binary depends on.</para>

      <para>If for some reason you install an algorithm specific library in a
      non standard location make sure to set the
      <envar>LD_LIBRARY_PATH</envar> for the algorithm in the transformation
      catalog for each site.</para>
    </section>

    <section>
      <title>Temporary Files</title>

      <para>If the algorithm codes create temporary files during execution,
      they should be cleared by the codes in case of errors and success
      terminations. The algorithm codes will run on scratch file systems that
      will also be used by others. The scratch directories get filled up very
      easily, and jobs will fail in case of directories running out of free
      space. The temporary files are the files that are not being tracked
      explicitly through the workflow generation process.</para>
    </section>

    <section>
      <title>Handling of stdio</title>

      <para>When writing a new application, it often appears feasible to use
      <emphasis>stdin</emphasis> for a single file data, and
      <emphasis>stdout</emphasis> for a single file output data. The
      <emphasis>stderr</emphasis> descriptor should be used for logging and
      debugging purposes only, never to put data on it. In the *nix world,
      this will work well, but may hiccup in the Windows world. </para>

      <para>We are suggesting that you avoid using stdio for data files,
      because there is the implied expectation that stdio data gets magically
      handled. There is no magic! If you produce data on
      <emphasis>stdout</emphasis>, you need to declare to Pegasus that your
      <emphasis>stdout</emphasis> has your data, and what LFN Pegasus can
      track it by. After the application is done, the data product will be a
      remote file just like all other data products. If you have an input file
      on <emphasis>stdin</emphasis>, you must track it in a similar manner. If
      you produce logs on <emphasis>stderr</emphasis> that you care about, you
      must track it in a similar manner. Think about it this way: Whenever you
      are redirecting stdio in a *nix shell, you will also have to specify a
      file name. </para>

      <para>Most execution environments permit to connect
      <emphasis>stdin</emphasis>, <emphasis>stdout</emphasis> or
      <emphasis>stderr</emphasis> to any file, and Pegasus supports this case.
      However, there are certain very specific corner cases where this is not
      possible. For this reason, we recommend that in new code, you avoid
      using stdio for data, and provide alternative means on the commandline,
      i.e. via <command>--input <replaceable>fn</replaceable></command> and
      <command>--output <replaceable>fn</replaceable></command> commandline
      arguments instead relying on <emphasis>stdin</emphasis> and
      <emphasis>stdout</emphasis>.</para>
    </section>

    <section>
      <title>Configuration Files</title>

      <para>If your code requires a configuration file to run and the
      configuration changes from one run to another, then this file needs to
      be tracked explicitly via the Pegasus WMS. The configuration file should
      not contain any absolute paths to any data or libraries used by the
      code. If any libraries, scripts etc need to be referenced they should
      refer to relative paths starting with a <filename>./xyz</filename> where
      <filename>xyz</filename> is a tracked file (defined in the workflow) or
      as $ENV-VAR/xyz where <envar>$ENV-VAR</envar> is set during execution
      time and evaluated by your application code internally.</para>
    </section>

    <section>
      <title>Code Invocation and input data staging by Pegasus</title>

      <para>Pegasus will create one temporary directory per workflow on each
      site where the workflow is planned. Pegasus will stage all the files
      required for the execution of the workflow in these temporary
      directories. This directory is shared by all the workflow components
      that executed on the site. You will have no control over where this
      directory is placed and as such you should have no expectations about
      where the code will be run. The directories are created per workflow and
      not per job/alogrithm/task. Suppose there is a component component-x
      that takes one argument: input-file.lisp (a file containing the data to
      be operated on). The staging step will bring input-file.lisp to the
      temporary directory. In *nix the call would look like this:</para>

      <programlisting>$ /nfs/software/component-x input-file.lisp</programlisting>

      <para>Note that Pegasus will call the component using the full path to
      the component. If inside your code/script you invoke some other code you
      cannot assume a path for this code to be relative or absolute. You have
      to resovle it either using a dirname $0 trick in shell assuming the
      child code is in the same directory as the parent or construct the path
      by expecting an enviornment variable to be set by the workflow system.
      These env variables need to be explicitly published so that they can be
      stored in the transformation catalog.</para>

      <para>Now suppose that internally, component-x writes its results to
      /tmp/component-x-results.lisp. This is not good. Components should not
      expect that a /tmp directory exists or that it will have permission to
      write there. Instead, component-x should do one of two things: 1. write
      component-x-results.lisp to the directory where it is run from or 2.
      component-x should take a second argument output-file.lisp that
      specifies the name and path of where the results should be
      written.</para>
    </section>

    <section>
      <title>Logical File naming in DAX</title>

      <para>The logical file names used by your code can be of two
      types.</para>

      <itemizedlist>
        <listitem>
          <para>Without a directory path e.g. <filename>f.a</filename>,
          <filename>f.b</filename> etc</para>
        </listitem>

        <listitem>
          <para>With a directory path e.g. <filename>a/1/f.a</filename>,
          <filename>b/2/f.b</filename></para>
        </listitem>
      </itemizedlist>

      <para>Both types of files are supported. We will create any directory
      structure mentioned in your logical files on the remote execution site
      when we stage in data as well as when we store the output data to a
      permanent location. An example invocation of a code that consumes and
      produces files will be</para>

      <programlisting>$/bin/test --input f.a --output f.b</programlisting>

      <para>OR</para>

      <programlisting>$/bin/test --input a/1/f.a --output b/1/f.b</programlisting>

      <note>
        <para>A logical file name should never be an absolute file path, e.g.
        /a/1/f.a In other words, there should not be a starting slash (/) in a
        logical filename. </para>
      </note>
    </section>
  </section>
</chapter>


