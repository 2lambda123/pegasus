<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="execution_environments">
  <title>Execution Environments</title>

  <para>Pegasus supports a number of execution environments. An execution
  environment is a setup where jobs from a workflow are running.</para>

  <section id="localhost">
    <title>Localhost</title>

    <para>In this configuration, Pegasus schedules the jobs to run locally on
    the submit host. Running locally is a good approach for smaller workflows,
    testing workflows, and for demonstations such as the <link
    linkend="tutorial">Pegasus tutorial</link>. Pegasus supports two methods
    of local execution: local HTCondor pool, and shell planner. The former is
    preferred as the latter does not support all Pegasus' features (such as
    notifications).</para>

    <para>Running on a local HTCondor pool is achieved by executing the
    workflow on site local (<emphasis role="bold">--sites local</emphasis>
    option to pegasus-plan). The site "local" is a reserved site in Pegasus
    and results in the jobs to run on the submit host in HTCondor universe
    local. The site catalog can be left very simple in this case:</para>

    <programlisting>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;

    &lt;site  handle="local" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/tmp/wf/work"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/work"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/tmp/wf/storage"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/storage"/&gt;
        &lt;/directory&gt;
    &lt;/site&gt;

&lt;/sitecatalog&gt;
</programlisting>

    <para>The simplest execution environment does not involve HTCondor.
    Pegasus is capable of planning small workflows for local execution using a
    shell planner. Please refer to the <filename
    class="directory">share/pegasus/examples</filename> directory in your
    Pegasus installation, the shell planner's <link
    linkend="local_shell_examples">documentation section</link>, or the
    tutorials, for details.</para>
  </section>

  <section id="condor_pool">
    <title>Condor Pool</title>

    <para>A HTCondor pool is a set of machines that use HTCondor for resource
    management. A HTCondor pool can be a cluster of dedicated machines or a
    set of distributively owned machines. Pegasus can generate concrete
    workflows that can be executed on a HTCondor pool.</para>

    <figure>
      <title>The distributed resources appear to be part of a HTCondor
      pool.</title>

      <mediaobject>
        <imageobject>
          <imagedata contentdepth="100%" fileref="images/condor_layout.png"
                     scalefit="1" width="100%"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The workflow is submitted using DAGMan from one of the job
    submission machines in the HTCondor pool. It is the responsibility of the
    Central Manager of the pool to match the task in the workflow submitted by
    DAGMan to the execution machines in the pool. This matching process can be
    guided by including HTCondor specific attributes in the submit files of
    the tasks. If the user wants to execute the workflow on the execution
    machines (worker nodes) in a HTCondor pool, there should be a resource
    defined in the site catalog which represents these execution machines. The
    universe attribute of the resource should be vanilla. There can be
    multiple resources associated with a single HTCondor pool, where each
    resource identifies a subset of machine (worker nodes) in the pool.</para>

    <para>When running on a HTCondor pool, the user has to decide how Pegasus
    should transfer data. Please see the <link
    linkend="data_staging_configuration">Data Staging Configuration</link> for
    the options. The easiest is to use <emphasis
    role="bold">condorio</emphasis> as that mode does not require any extra
    setup - HTCondor will do the transfers using the existing HTCondor
    daemons. For an example of this mode see the example workflow in
    <filename> share/pegasus/examples/condor-blackdiamond-condorio/</filename>
    . In HTCondorio mode, the site catalog for the execution site is very
    simple as storage is provided by HTCondor:</para>

    <programlisting>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;

    &lt;site  handle="local" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/tmp/wf/work"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/work"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/tmp/wf/storage"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/storage"/&gt;
        &lt;/directory&gt;
    &lt;/site&gt;

    &lt;site  handle="condorpool" arch="x86_64" os="LINUX"&gt;
        &lt;profile namespace="pegasus" key="style" &gt;condor&lt;/profile&gt;
        &lt;profile namespace="condor" key="universe" &gt;vanilla&lt;/profile&gt;
    &lt;/site&gt;

&lt;/sitecatalog&gt;
</programlisting>

    <para>There is a set of HTCondor profiles which are used commonly when
    running Pegasus workflows. You may have to set some or all of these
    depending on the setup of the HTCondor pool:</para>

    <programlisting>  &lt;!-- Change the style to HTCondor for jobs to be executed in the HTCondor Pool.
       By default, Pegasus creates jobs suitable for grid execution. --&gt;
  &lt;profile namespace="pegasus" key="style"&gt;condor&lt;/profile&gt;

  &lt;!-- Change the universe to vanilla to make the jobs go to remote compute
       nodes. The default is local which will only run jobs on the submit host --&gt;
  &lt;profile namespace="condor" key="universe" &gt;vanilla&lt;/profhile&gt;

  &lt;!-- The requirements expression allows you to limit where your jobs go --&gt;
  &lt;profile namespace="condor" key="requirements"&gt;(Target.FileSystemDomain != &amp;quot;yggdrasil.isi.edu&amp;quot;)&lt;/profile&gt;

  &lt;!-- The following two profiles forces HTCondor to always transfer files. This
       has to be used if the pool does not have a shared filesystem --&gt;
  &lt;profile namespace="condor" key="should_transfer_files"&gt;True&lt;/profile&gt;
  &lt;profile namespace="condor" key="when_to_transfer_output"&gt;ON_EXIT&lt;/profile&gt;</programlisting>

    <section id="glideins">
      <title>Glideins</title>

      <para>In this section we describe how machines from different
      administrative domains and supercomputing centers can be dynamically
      added to a HTCondor pool for certain timeframe. These machines join the
      HTCondor pool temporarily and can be used to execute jobs in a non
      preemptive manner. This functionality is achieved using a HTCondor
      feature called <emphasis role="bold">glideins</emphasis> (see <ulink
      url="http://cs.wisc.edu/condor/glidein">
      http://cs.wisc.edu/condor/glidein</ulink>) . The startd daemon is the
      HTCondor daemon which provides the compute slots and runs the jobs. In
      the glidein case, the submit machine is usually a static machine and the
      glideins are told configued to report to that submit machine. The
      glideins can be submitted to any type of resource: a GRAM enabled
      cluster, a campus cluster, a cloud environment such as Amazon AWS, or
      even another HTCondor cluster.</para>

      <tip>
        <para>As glideins are usually coming from different compute resource,
        and/or the glideins are running in an administrative domain different
        from the submit node, there is usually no shared filesystem available.
        Thus the most common <link linkend="data_staging_configuration">data
        staging modes</link> are <emphasis role="bold">condorio</emphasis> and
        <emphasis role="bold">nonsharedfs</emphasis> .</para>
      </tip>

      <para>There are many useful tools which submits and manages glideins for
      you:</para>

      <itemizedlist>
        <listitem>
          <para><ulink
          url="http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/">
          GlideinWMS</ulink> is a tool and host environment used mostly on the
          <ulink url="http://www.opensciencegrid.org/">Open Science
          Grid</ulink>.</para>
        </listitem>

        <listitem>
          <para><ulink url="http://pegasus.isi.edu/projects/corralwms">
          CorralWMS</ulink> is a personal frontend for GlideinWMS. CorralWMS
          was developed by the Pegasus team and works very well for high
          throughput workflows.</para>
        </listitem>

        <listitem>
          <para><ulink
          url="http://research.cs.wisc.edu/condor/manual/v7.6/condor_glidein.html">
          condor_glidein</ulink> is a simple glidein tool for Globus GRAM
          clusters. condor_glidein is shipped with HTCondor.</para>
        </listitem>

        <listitem>
          <para>Glideins can also be created by hand or scripts. This is a
          useful solution for example for cluster which have no external job
          submit mechanisms or do not allow outside networking.</para>
        </listitem>
      </itemizedlist>
    </section>

    <section>
      <title>CondorC</title>

      <para>Using HTCondorC users can submit workflows to remote HTCondor
      pools. HTCondorC is a HTCondor specific solution for remote submission
      that does not involve the setting up a GRAM on the headnode. To enable
      HTCondorC submission to a site, user needs to associate pegasus profile
      key named style with value as HTCondorc. In case, the remote HTCondor
      pool does not have a shared filesytem between the nodes making up the
      pool, users should use pegasus in the HTCondorio data configuration. In
      this mode, all the data is staged to the remote node in the HTCondor
      pool using HTCondor File transfers and is executed using
      PegasusLite.</para>

      <para>A sample site catalog for submission to a HTCondorC enabled site
      is listed below</para>

      <programlisting>
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;
      
    &lt;site  handle="local" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/tmp/wf/work"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/work"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/tmp/wf/storage"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/storage"/&gt;
        &lt;/directory&gt;
    &lt;/site&gt;

    &lt;site  handle="condorcpool" arch="x86_86" os="LINUX"&gt;
         &lt;!-- the grid gateway entries are used to designate
              the remote schedd for the HTCondorC pool --&gt;
         &lt;grid type="condor" contact="ccg-condorctest.isi.edu" scheduler="Condor" jobtype="compute" /&gt;
         &lt;grid type="condor" contact="ccg-condorctest.isi.edu" scheduler="Condor" jobtype="auxillary" /&gt;
        
        &lt;!-- enable submission using HTCondorc --&gt;
        &lt;profile namespace="pegasus" key="style"&gt;condorc&lt;/profile&gt;

        &lt;!-- specify which HTCondor collector to use. 
             If not specified defaults to remote schedd specified in grid gateway --&gt;
        &lt;profile namespace="condor" key="condor_collector"&gt;condorc-collector.isi.edu&lt;/profile&gt;
        
        &lt;profile namespace="condor" key="should_transfer_files"&gt;Yes&lt;/profile&gt;
        &lt;profile namespace="condor" key="when_to_transfer_output"&gt;ON_EXIT&lt;/profile&gt;
        &lt;profile namespace="env" key="PEGASUS_HOME" &gt;/usr&lt;/profile&gt;
        &lt;profile namespace="condor" key="universe"&gt;vanilla&lt;/profile&gt;

    &lt;/site&gt;

&lt;/sitecatalog&gt;
</programlisting>

      <para>To enable PegasusLite in HTCondorIO mode, users should set the
      following in their properties</para>

      <programlisting># pegasus properties
pegasus.data.configuration    condorio</programlisting>
    </section>
  </section>

  <section id="cloud">
    <title>Cloud (Amazon EC2/S3, Google Cloud, ...)</title>

    <para><figure id="concepts-fig-cloud-layout">
        <title>Cloud Sample Site Layout</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center" contentdepth="100%"
                       fileref="images/fg-pwms-prefio.3.png" scalefit="1"
                       valign="middle" width="100%"/>
          </imageobject>
        </mediaobject>
      </figure></para>

    <para>This figure shows a sample environment for executing Pegasus across
    multiple clouds. At this point, it is up to the user to provision the
    remote resources with a proper VM image that includes a HTCondor worker
    that is configured to report back to a HTCondor master, which can be
    located inside one of the clouds, or outside the cloud.</para>

    <para>The submit host is the point where a user submits Pegasus workflows
    for execution. This site typically runs a HTCondor collector to gather
    resource announcements, or is part of a larger HTCondor pool that collects
    these announcements. HTCondor makes the remote resources available to the
    submit host's HTCondor installation.</para>

    <para>The <link linkend="concepts-fig-cloud-layout">figure above</link>
    shows the way Pegasus WMS is deployed in cloud computing resources,
    ignoring how these resources were provisioned. The provisioning request
    shows multiple resources per provisioning request.</para>

    <para>The initial stage-in and final stage-out of application data into
    and out of the node set is part of any Pegasus-planned workflow. Several
    configuration options exist in Pegasus to deal with the dynamics of push
    and pull of data, and when to stage data. In many use-cases, some form of
    external access to or from the shared file system that is visible to the
    application workflow is required to facilitate successful data staging.
    However, Pegasus is prepared to deal with a set of boundary cases.</para>

    <para>The data server in the figure is shown at the submit host. This is
    not a strict requirement. The data server for consumed data and data
    products may both be different and external to the submit host, or one of
    the object storage solution offered by the cloud providers</para>

    <para>Once resources begin appearing in the pool managed by the submit
    machine's HTCondor collector, the application workflow can be submitted to
    HTCondor. A HTCondor DAGMan will manage the application workflow
    execution. Pegasus run-time tools obtain timing-, performance and
    provenance information as the application workflow is executed. At this
    point, it is the user's responsibility to de-provision the allocated
    resources.</para>

    <para>In the figure, the cloud resources on the right side are assumed to
    have uninhibited outside connectivity. This enables the HTCondor I/O to
    communicate with the resources. The right side includes a setup where the
    worker nodes use all private IP, but have out-going connectivity and a NAT
    router to talk to the internet. The <emphasis>Condor connection
    broker</emphasis> (CCB) facilitates this setup almost effortlessly.</para>

    <para>The left side shows a more difficult setup where the connectivity is
    fully firewalled without any connectivity except to in-site nodes. In this
    case, a proxy server process, the <emphasis> generic connection
    broker</emphasis> (GCB), needs to be set up in the DMZ of the cloud site
    to facilitate HTCondor I/O between the submit host and worker
    nodes.</para>

    <para>If the cloud supports data storage servers, Pegasus is starting to
    support workflows that require staging in two steps: Consumed data is
    first staged to a data server in the remote site's DMZ, and then a second
    staging task moves the data from the data server to the worker node where
    the job runs. For staging out, data needs to be first staged from the
    job's worker node to the site's data server, and possibly from there to
    another data server external to the site. Pegasus is capable to plan both
    steps: Normal staging to the site's data server, and the worker-node
    staging from and to the site's data server as part of the job.</para>

    <section id="amazon_aws">
      <title>Amazon EC2</title>

      <para>There are many different ways to set up an execution environment
      in Amazon EC2. The easiest way is to use a submit machine outside the
      cloud, and to provision several worker nodes and a file server node in
      the cloud as shown here:</para>

      <para><figure id="ec2">
          <title>Amazon EC2</title>

          <mediaobject>
            <imageobject>
              <imagedata align="center" contentdepth="100%"
                         fileref="images/ec2.png" scalefit="1" valign="middle"
                         width="100%"/>
            </imageobject>
          </mediaobject>
        </figure></para>

      <para>The submit machine runs Pegasus and a HTCondor master (collector,
      schedd, negotiator). The workers run a HTCondor startd. And the file
      server node exports an NFS file system. The startd on the workers is
      configured to connect to the master running outside the cloud, and the
      workers also mount the NFS file system. More information on setting up
      HTCondor for this environment can be found at <ulink
      url="http://www.isi.edu/~gideon/condor-ec2/">
      http://www.isi.edu/~gideon/condor-ec2</ulink>.</para>

      <para>The site catalog entry for this configuration is similar to what
      you would create for running on a local <link
      linkend="condor_pool">Condor pool</link> with a shared file
      system.</para>
    </section>

    <section id="google_cloud">
      <title>Google Cloud Platform</title>

      <para>Using the Google Cloud Platform is just like any other cloud
      platform. You can choose to host the central manager / submit host
      inside the cloud or outside. The compute VMs will have HTCondor
      installed and configured to join the pool managed by the central
      manager.</para>

      <para>Google Storage is supported using gsutil. First, create a .boto
      file by running:</para>

      <programlisting>gsutil config
</programlisting>

      <para>Then, use a site catalog which specifies which .boto file to use.
      You can then use gs:// URLs in your workflow. Example:</para>

      <programlisting>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog
                 http://pegasus.isi.edu/schema/sc-4.0.xsd" version="4.0"&gt;

    &lt;site  handle="local" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/tmp"&gt;
            &lt;file-server operation="all" url="file:///tmp"/&gt;
        &lt;/directory&gt;
        &lt;profile namespace="env" key="PATH"&gt;/opt/gsutil:/usr/bin:/bin&lt;/profile&gt;                                    
    &lt;/site&gt;                                                                                                                                                                                                                                                                                                                                                                                                             
    &lt;!-- compute site --&gt;
    &lt;site  handle="condorpool" arch="x86_86" os="LINUX"&gt;
        &lt;profile namespace="pegasus" key="style" &gt;condor&lt;/profile&gt;
        &lt;profile namespace="condor" key="universe" &gt;vanilla&lt;/profile&gt;
    &lt;/site&gt;

    &lt;!-- storage sites have to be in the site catalog, just liek a compute site --&gt;
    &lt;site  handle="google_storage" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/my-bucket/scratch"&gt;
            &lt;file-server operation="all" url="gs://my-bucket/scratch"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/my-bucket/outputs"&gt;
            &lt;file-server operation="all" url="gs://my-bucket/outputs"/&gt;
        &lt;/directory&gt;
        &lt;profile namespace="pegasus" key="BOTO_CONFIG"&gt;/home/myuser/.boto&lt;/profile&gt;
    &lt;/site&gt;

&lt;/sitecatalog&gt;
</programlisting>
    </section>
  </section>

  <section id="pyglidein">
    <title>Remote Cluster using PyGlidein</title>

    <para>Glideins (HTCondor pilot jobs) provide an efficient solution for
    high-throughput workflows. The glideins are submitted to the remote
    cluster scheduler, and once started up, makes it appear like your HTCondor
    pool extends into the remote cluster. HTCondor can then schedule the jobs
    to the remote compute node in the same way it would schedule jobs to local
    compute nodes.</para>

    <para>Some infrastructures, such as <link linkend="open_science_grid">Open
    Science Grid</link>, provide infrastructure level glidein solutions, such
    as GlideinWMS. Another solution is <link linkend="bosco">BOSCO</link>. For
    some more custom setups, <ulink
    url="https://github.com/WIPACrepo/pyglidein">pyglidein</ulink> from the
    <ulink url="http://icecube.wisc.edu/">IceCube</ulink> project provides a
    nice framework. The architecture consists on a server on the submit host,
    which job it is to determining the demand. On the remote resource, the
    client can be invoked for example via cron, and submits directly to
    HTCondor, SLURM and PBS schedulers. This makes pyglidein very flexible and
    works well for example if the resource requires two-factor
    authentication.</para>

    <para><figure id="fig-pyglidein">
        <title>pyglidein overview</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center" contentdepth="100%"
                       fileref="images/pyglidein.png" scalefit="1"
                       valign="middle" width="100%"/>
          </imageobject>
        </mediaobject>
      </figure></para>

    <para>To get started with pyglidein, check out a copy of the Git
    repository on both your submit host as well as the cluster you want to
    glidein to. Starting with the submit host, first make sure you have
    HTCondor configured for <ulink
    url="http://research.cs.wisc.edu/htcondor/manual/current/3_8Security.html#SECTION00483400000000000000">PASSWORD</ulink>
    authentication. Make a copy of the HTCondor pool password file. You will
    need it on the cluster, and it is a binary file, so make sure you cp
    instead of a copy-and-paste of the file contents. To get the server
    started:</para>

    <programlisting>
./server.py --port 11001  
    </programlisting>

    <para>By default, the pyglidein server will use all jobs in the system to
    determine if glideins are needed. If you want user jobs to explicitly let
    us know they want glideins, you can pass a constraint for the server to
    use. For example, jobs could have the <emphasis>+WantStampede2 =
    True</emphasis> attribute, and then we could start the server with:</para>

    <programlisting>
./server.py --port 11001 --constraint "'WantStampede2 == True'"  
    </programlisting>

    <para>One the server is running, you can check status by pointing a web
    browser to it.</para>

    <para>Next step is to create a <emphasis>glidein.tar.gz</emphasis> file
    containing the HTCondor binaries, our pool password file, and a modified
    job wrapper script. This can be accomplished by building HTCondor with the
    <emphasis>create_glidein_tarball.py</emphasis> script, but first we need
    to modify <emphasis>glidein_template/</emphasis>. Start by copying your
    pool password file over the existing <emphasis>passwdfile</emphasis>
    file.</para>

    <para>Edit <emphasis>user_job_wrapper.sh</emphasis>. We don't need most of
    it, so edit it to read:</para>

    <programlisting>
#!/bin/bash

# This script is started just before the user job
# It is referenced by the USER_JOB_WRAPPER

export HOME=$PWD

# fix PATH and LD_LIBRARY_PATH
export PATH=$PATH:/usr/bin:/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib64:/usr/local/lib:/usr/lib64:/usr/lib:/usr/lib/x86_64-linux-gnu:/lib64:/lib:/lib/x86_64-linux-gnu

GLIDEIN_DIR=$GLIDEIN_LOCAL_TMP_DIR
if [ ! -d $GLIDEIN_DIR ]; then
    GLIDEIN_DIR=$PWD
fi
JOB_WRAPPER="${GLIDEIN_DIR}/job_wrapper.sh"

# fall through to next/default job wrapper
if [ ! -e $JOB_WRAPPER ]; then
    exec "$@"
else
    exec ${JOB_WRAPPER} "$@"
fi   
    </programlisting>

    <para>Create the glidein.tar.gz by running:</para>

    <programlisting>
python create_glidein_tarball.py
    </programlisting>

    <para>Once you have the glidein.tar.gz file, copy it to the Git checkout
    you have on the remote cluster. Then move over there for the remaining
    steps. Create a configuration file for your glidein under
    <emphasis>configs/</emphasis>. Here is an example for TACC
    Stampede2:</para>

    <programlisting>
[Mode]
debug = True

[Glidein]
address = http://workflow.isi.edu:11001/jsonrpc
site = TACC-Stampede2
tarball = /home1/00384/rynge/git/pyglidein/glidein.tar.gz

[Cluster]
user = rynge
os = RHEL7
scheduler = slurm
submit_command = sbatch
walltime_hrs = 48
max_total_jobs = 10
max_idle_jobs = 1
limit_per_submit = 1

gpu_only = False
whole_node = True
whole_node_cpus = 1
whole_node_memory = 96000
whole_node_disk = 30000
whole_node_gpus = 0
group_jobs = False
partition = normal
running_cmd = squeue -u $USER -t RUNNING -p normal -h | wc -l
idle_cmd = squeue -u $USER -t PENDING -p normal -h | wc -l

[SubmitFile]
filename = submit.slurm
local_dir = /tmp/$SLURM_JOB_ID
custom_header = #SBATCH -A TG-ABC00001
cvmfs_job_wrapper = False

[CustomEnv]
CLUSTER = workflow.isi.edu
    </programlisting>

    <para>This configuration will obviously look different for different
    clusters. <emphasis>configs/</emphasis> has a bunch of example configs,
    but a few things to note:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">address</emphasis> is the location of the
        server we started earlier</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">tarball</emphasis> is the full path to our
        custom glidein.tar.gz file we created above.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">CLUSTER</emphasis> is the location of your
        HTCondor central manager. In many cases this is the same host you
        started the server on. Please note that if you do not set this
        variable, the glideins will try to register into the IceCube
        infrastructure.</para>
      </listitem>
    </itemizedlist>

    <para>At this point we can try our first glidein:</para>

    <programlisting>
./client.py --config=$HOME/git/pyglidein/configs/stampede2.config
    </programlisting>

    <para>Once we have a seen a successful glidein, we can add the client to
    the crontab:</para>

    <programlisting>
# m  h  dom mon dow   command
*/10 *   *   *   *    (cd ~/git/pyglidein/ &amp;&amp; ./client.py --config=$HOME/git/pyglidein/configs/stampede2.config) &gt;~/cron-pyglidein.log 2&gt;&amp;1
    </programlisting>

    <para>With this setup, glideins will now appear automatically based on the
    demand in the local HTCondor queue.</para>
  </section>

  <section id="globus_gram">
    <title>Remote Cluster using Globus GRAM</title>

    <para><figure id="concepts-fig-site-layout">
        <title>Grid Sample Site Layout</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center" contentdepth="100%"
                       fileref="images/concepts-site-layout.jpg" scalefit="1"
                       valign="middle" width="100%"/>
          </imageobject>
        </mediaobject>
      </figure></para>

    <para>A generic grid environment shown in the figure <link
    linkend="concepts-fig-site-layout">above</link>. We will work from the
    left to the right top, then the right bottom.</para>

    <para>On the left side, you have a submit machine where Pegasus runs,
    HTCondor schedules jobs, and workflows are executed. We call it the
    <emphasis>submit host</emphasis> (SH), though its functionality can be
    assumed by a virtual machine image. In order to properly communicate over
    secured channels, it is important that the submit machine has a proper
    notion of time, i.e. runs an NTP daemon to keep accurate time. To be able
    to connect to remote clusters and receive connections from the remote
    clusters, the submit host has a public IP address to facilitate this
    communication.</para>

    <para>In order to send a job request to the remote cluster, HTCondor wraps
    the job into Globus calls via HTCondor-G. Globus uses GRAM to manage jobs
    on remote sites. In terms of a software stack, Pegasus wraps the job into
    HTCondor. HTCondor wraps the job into Globus. Globus transports the job to
    the remote site, and unwraps the Globus component, sending it to the
    remote site's <emphasis>resource manager</emphasis> (RM).</para>

    <para>To be able to communicate using the Globus security infrastructure
    (GSI), the submit machine needs to have the certificate authority (CA)
    certificates configured, requires a host certificate in certain
    circumstances, and the user a user certificate that is enabled on the
    remote site. On the remote end, the remote gatekeeper node requires a host
    certificate, all signing CA certificate chains and policy files, and a
    goot time source.</para>

    <para>In a grid environment, there are one or more clusters accessible via
    grid middleware like the <ulink url="http://www.globus.org/">Globus
    Toolkit</ulink>. In case of Globus, there is the Globus gatekeeper
    listening on TCP port 2119 of the remote cluster. The port is opened to a
    single machine called <emphasis>head node</emphasis> (HN).The head-node is
    typically located in a de-militarized zone (DMZ) of the firewall setup, as
    it requires limited outside connectivity and a public IP address so that
    it can be contacted. Additionally, once the gatekeeper accepted a job, it
    passes it on to a jobmanager. Often, these jobmanagers require a limited
    port range, in the example TCP ports 40000-41000, to call back to the
    submit machine.</para>

    <para>For the user to be able to run jobs on the remote site, the user
    must have some form of an account on the remtoe site. The user's grid
    identity is passed from the submit host. An entity called <emphasis>grid
    mapfile</emphasis> on the gatekeeper maps the user's grid identity into a
    remote account. While most sites do not permit account sharing, it is
    possible to map multiple user certificates to the same account.</para>

    <para>The gatekeeper is the interface through which jobs are submitted to
    the remote cluster's resource manager. A resource manager is a scheduling
    system like PBS, Maui, LSF, FBSNG or HTCondor that queues tasks and
    allocates worker nodes. The <emphasis>worker nodes</emphasis> (WN) in the
    remote cluster might not have outside connectivity and often use all
    private IP addresses. The Globus toolkit requires a shared filesystem to
    properly stage files between the head node and worker nodes.</para>

    <note>
      <para>The shared filesystem requirement is imposed by Globus. Pegasus is
      capable of supporting advanced site layouts that do not require a shared
      filesystem. Please contact us for details, should you require such a
      setup.</para>
    </note>

    <para>To stage data between external sites for the job, it is recommended
    to enable a GridFTP server. If a shared networked filesystem is involved,
    the GridFTP server should be located as close to the file-server as
    possible. The GridFTP server requires TCP port 2811 for the control
    channel, and a limited port range for data channels, here as an example
    the TPC ports from 40000 to 41000. The GridFTP server requires a host
    certificate, the signing CA chain and policy files, a stable time source,
    and a gridmap file that maps between a user's grid identify and the user's
    account on the remote site.</para>

    <para>The GridFTP server is often installed on the head node, the same as
    the gatekeeper, so that they can share the grid mapfile, CA certificate
    chains and other setups. However, for performance purposes it is
    recommended that the GridFTP server has its own machine.</para>

    <para>An example site catalog entry for a GRAM enabled site looks as
    follow in the site catalog</para>

    <programlisting>&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;
      
     &lt;site handle="Trestles" arch="x86_64" os="LINUX"&gt;
        &lt;grid type="gt5" contact="trestles.sdsc.edu/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/&gt;
        &lt;grid type="gt5" contact="trestles.sdsc.edu/jobmanager-pbs" scheduler="unknown" jobtype="compute"/&gt;

        &lt;directory type="shared-scratch" path="/oasis/projects/nsf/USERNAME"&gt;
            &lt;file-server operation="all" url="gsiftp://trestles-dm1.sdsc.edu/oasis/projects/nsf/USERNAME"/&gt;
        &lt;/directory&gt;

        &lt;!-- specify the path to a PEGASUS WORKER INSTALL on the site --&gt;
        &lt;profile namespace="env" key="PEGASUS_HOME" &gt;/path/to/PEGASUS/INSTALL&lt;/profile&gt;
    &lt;/site&gt;


 &lt;/sitecatalog&gt;</programlisting>
  </section>

  <section id="creamce_submission">
    <title>Remote Cluster using CREAMCE</title>

    <para><ulink
    url="https://wiki.italiangrid.it/twiki/bin/view/CREAM/FunctionalDescription">
    CREAM</ulink> is a webservices based job submission front end for remote
    compute clusters. It can be viewed as a replaced for Globus GRAM and is
    mainly popular in Europe. It widely used in the Italian Grid.</para>

    <para>In order to submit a workflow to compute site using the CREAMCE
    front end, the user needs to specify the following for the site in their
    site catalog</para>

    <orderedlist>
      <listitem>
        <para><emphasis role="bold">pegasus</emphasis> profile <emphasis
        role="bold">style</emphasis> with value set to <emphasis
        role="bold">cream</emphasis></para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">grid gateway</emphasis>defined for the
        site with <emphasis role="bold">contact</emphasis> attribute set to
        CREAMCE frontend and <emphasis role="bold">scheduler</emphasis>
        attribute to remote scheduler.</para>
      </listitem>

      <listitem>
        <para>a remote queue can be optionally specified using <emphasis
        role="bold">globus</emphasis> profile <emphasis
        role="bold">queue</emphasis> with value set to <emphasis
        role="bold">queue-name</emphasis></para>
      </listitem>
    </orderedlist>

    <para>An example site catalog entry for a creamce site looks as follow in
    the site catalog</para>

    <programlisting>&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;
      
    &lt;site  handle="creamce" arch="x86" os="LINUX"&gt;
        &lt;grid type="cream" contact="https://ce01-lcg.cr.cnaf.infn.it:8443/ce-cream/services/CREAM2" scheduler="LSF" jobtype="compute" /&gt;
        &lt;grid type="cream" contact="https://ce01-lcg.cr.cnaf.infn.it:8443/ce-cream/services/CREAM2" scheduler="LSF" jobtype="auxillary" /&gt;

         &lt;!-- Scratch directory on the cluster --&gt;
        &lt;directory type="shared-scratch" path="/home/virgo034"&gt;
            &lt;file-server operation="all" url="gsiftp://ce01-lcg.cr.cnaf.infn.it/home/virgo034"/&gt;
        &lt;/directory&gt;

        &lt;!-- cream is the style to use for CREAMCE submits --&gt;                                                                                                                                                                                                                               
        &lt;profile namespace="pegasus" key="style"&gt;cream&lt;/profile&gt;

        &lt;!-- the remote queue is picked up from globus profile --&gt; 
        &lt;profile namespace="globus" key="queue"&gt;virgo&lt;/profile&gt;

        &lt;!-- Staring HTCondor 8.0 additional cream attributes 
             can be passed by setting cream_attributes --&gt;
        &lt;profile namespace="condor" key="cream_attributes"&gt;key1=value1;key2=value2&lt;/profile&gt;
    &lt;/site&gt;

 &lt;/sitecatalog&gt;</programlisting>

    <para>The pegasus distribution comes with creamce examples in the examples
    directory. They can be used as a starting point to configure your
    setup.</para>

    <tip>
      <para>Usually , the CREAMCE frontends accept VOMS generated user proxies
      using the command voms-proxy-init . Steps on generating a VOMS proxy are
      listed in the CREAM User Guide <ulink type=""
      url="https://wiki.italiangrid.it/twiki/bin/view/CREAM/UserGuide#1_1_Before_starting_get_your_use">
      here</ulink> .</para>
    </tip>
  </section>

  <section id="glite">
    <title>Local Campus Cluster Using Glite</title>

    <para>This section describes the configuration required for Pegasus to
    generate an executable workflow that uses glite to submit to a Slurm, PBS, or
    SGE batch system on a local cluster. This environment is referred to
    as the local campus cluster, as the workflow submit node (Pegasus
    +HTCondor) need to be installed on a login node (or a node where the local
    batch scheduler commands can be executed) of the cluster. </para>

    <note>
      <para>Glite is the old name for BLAH (or BLAHP). BLAH binaries are
      distributed with HTCondor as the "batch_gahp". For historical reasons,
      we often use the term "glite", and you will see "glite" and "batch_gahp"
      references in HTCondor, but all of them refer to the same thing, which
      has been renamed BLAH.</para>
    </note>

    <tip>
      <para>This guide covers Slurm, PBS, Moab, and SGE, but glite also works with
      other PBS-like batch systems, including LSF, Cobalt and others.
      If you need help configuring Pegasus and HTCondor to work with one of
      these systems, please contact pegasus-support@isi.edu. For the sake of
      brevity, the text below will say "PBS", but you should read that as "PBS
      or PBS-like system such as SGE, Moab, LSF, and others".</para>
    </tip>

    <para>This is because the glite layer communicates with the batch system
    running on the cluster using <literal>squeue</literal>/<literal>qsub</literal>/...
    or equivalent commands. If you can submit jobs to the local scheduler from
    the workflow submit host, then the
    local HTCondor can be used to submit jobs via glite (with some
    modifications described below). If you need to SSH to a different cluster
    head node in order to submit jobs to the scheduler, then you can use
    BOSCO, which is <link linkend="bosco"> documented in another
    section</link>.</para>

    <tip>
      <para>There is also a way to do remote job submission via glite even if
      you cannot SSH to the head node. This might be the case, for
      example, if the head node requires 2-factor authentication (e.g. RSA
      tokens). This approach is called the "Reverse GAHP" and you can find out
      more information on the <ulink
      url="https://github.com/juve/rvgahp">GitHub page</ulink>. All it
      requires is SSH from the cluster head node back to the workflow submit
      host.</para>
    </tip>

    <para>In either case, you need to modifiy the HTCondor glite installation
    that will be used to submit jobs to the local scheduler. To do this, run the
    <literal>pegasus-configure-glite</literal> command. This command will
    install all the required scripts to map Pegasus profiles to batch-system
    specific job attributes, and add support for Moab. You may need to run it
    as root depending on how you installed HTCondor.</para>

    <para>In order to configure a workflow to use glite you need to create an
    entry in your site catalog for the cluster and set the following
    profiles:</para>

    <orderedlist>
      <listitem>
        <para><emphasis role="bold">pegasus</emphasis> profile <emphasis
        role="bold">style</emphasis> with value set to <emphasis
        role="bold">glite</emphasis>.</para>
      </listitem>

      <listitem>
          <para><emphasis role="bold">condor</emphasis> profile
              <emphasis role="bold">grid_resource</emphasis> with value set to
              <emphasis role="bold">batch slurm</emphasis>,
              <emphasis role="bold">batch pbs</emphasis>,
              <emphasis role="bold">batch sge</emphasis> or
              <emphasis role="bold">batch moab</emphasis>.</para>
      </listitem>
    </orderedlist>

    <para>An example site catalog entry for a local glite PBS site looks like
    this:</para>

    <programlisting>
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;

    &lt;site  handle="local" arch="x86" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/lfs/shared-scratch/glite-sharedfs-example/work"&gt;
            &lt;file-server operation="all" url="file:///lfs/local-scratch/glite-sharedfs-example/work"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/shared-scratch//glite-sharedfs-example/outputs"&gt;
            &lt;file-server operation="all" url="file:///lfs/local-scratch/glite-sharedfs-example/outputs"/&gt;
        &lt;/directory&gt;
    &lt;/site&gt;

    &lt;site  handle="local-slurm" arch="x86" os="LINUX"&gt;

        &lt;!-- the following is a shared directory shared amongst all the nodes in the cluster --&gt;
        &lt;directory type="shared-scratch" path="/lfs/glite-sharedfs-example/local-slurm/shared-scratch"&gt;
            &lt;file-server operation="all" url="file:///lfs/glite-sharedfs-example/local-slurm/shared-scratch"/&gt;
        &lt;/directory&gt;

        &lt;profile namespace="env" key="PEGASUS_HOME"&gt;/lfs/software/pegasus&lt;/profile&gt;

        &lt;profile namespace="pegasus" key="style" &gt;glite&lt;/profile&gt;

        &lt;profile namespace="condor" key="grid_resource"&gt;batch slurm&lt;/profile&gt;
        &lt;profile namespace="pegasus" key="queue"&gt;batch&lt;/profile&gt;
        &lt;profile namespace="pegasus" key="runtime"&gt;30000&lt;/profile&gt;
    &lt;/site&gt;

&lt;/sitecatalog&gt;
    </programlisting>

    <tip>
      <para>Starting 4.2.1, in the examples directory you can find a glite
      shared filesystem example that you can use to test out this
      configuration.</para>
    </tip>

    <para>You probably don't need to know this, but Pegasus generates a
    <literal>+remote_cerequirements</literal> expression for an HTCondor glite
    job based on the Pegasus profiles associated with the job. This expression
    is passed to glite and used by the
    <literal>*_local_submit_attributes.sh</literal> scripts installed by
    <literal>pegasus-configure-glite</literal> to generate the correct batch
    submit script. An example <literal>+remote_cerequirements</literal>
    classad expression in the HTCondor submit file looks like this:</para>

    <programlisting><emphasis role="bold">+remote_cerequirements = JOBNAME=="preprocessj1" &amp;&amp; PASSENV==1 &amp;&amp; WALLTIME=="01:00:00" &amp;&amp; \
 EXTRA_ARGUMENTS=="-N testjob -l walltime=01:23:45 -l nodes=2" &amp;&amp; \
 MYENV=="CONDOR_JOBID=$(cluster).$(process),PEGASUS_DAG_JOB_ID=preprocess_j1,PEGASUS_HOME=/usr,PEGASUS_WF_UUID=aae14bc4-b2d1-4189-89ca-ccd99e30464f"</emphasis></programlisting>

    <para>The job name and environment variables are automatically passed
    through to the remote job.</para>

    <para>The following sections document the mapping of Pegasus profiles to
    batch system job requirements as implemented by Pegasus, HTCondor, and
    glite.</para>

    <section id="glite_mappings">
      <title>Setting job requirements</title>

      <para>The job requirements are constructed based on the following
      profiles:</para>

      <table>
        <title>Mapping of Pegasus Profiles to Job Requirements</title>

        <tgroup cols="8">
          <thead>
            <row>
              <entry align="center">Profile Key</entry>

              <entry align="center">Key in +remote_cerequirements</entry>

              <entry>PBS Parameter</entry>

              <entry>SGE Parameter</entry>

              <entry>SLURM parameter</entry>

              <entry>Moab Parameter</entry>

              <entry>Cobalt Parameter</entry>

              <entry>Description</entry>
            </row>
          </thead>

          <tbody>
            <row>
              <entry>pegasus.cores</entry>

              <entry>CORES</entry>

              <entry>n/a</entry>

              <entry>-pe ompi</entry>

              <entry>--ntasks cores</entry>

              <entry>n/a</entry>

              <entry>--proccount cores</entry>

              <entry>Pegasus uses cores to calculate either nodes or ppn. If
              cores and ppn are specified, then nodes is computed. If cores
              and nodes is specified, then ppn is computed. If both nodes and
              ppn are specified, then cores is ignored. The resulting values
              for nodes and ppn are used to set the job requirements for PBS
              and Moab. If neither nodes nor ppn is specified, then no
              requirements are set in the PBS or Moab submit script. For SGE,
              how the processes are distributed over nodes depends on how the
              parallel environment has been configured; it is set to 'ompi' by
              default.</entry>
            </row>

            <row>
              <entry>pegasus.nodes</entry>

              <entry>NODES</entry>

              <entry>-l nodes</entry>

              <entry>n/a</entry>

              <entry>--nodes nodes</entry>

              <entry>-l nodes</entry>

              <entry>-n nodes</entry>

              <entry>This specifies the number of nodes that the job should
              use. This is not used for SGE.</entry>
            </row>

            <row>
              <entry>pegasus.ppn</entry>

              <entry>PROCS</entry>

              <entry>-l ppn</entry>

              <entry>n/a</entry>

              <entry>n/a</entry>

              <entry>-l ppn</entry>

              <entry>--mode c[ppn]</entry>

              <entry>This specifies the number of processors per node that the
              job should use. This is not used for SGE.</entry>
            </row>

            <row>
              <entry>pegasus.runtime</entry>

              <entry>WALLTIME</entry>

              <entry>-l walltime</entry>

              <entry>-l h_rt</entry>

              <entry>--time walltime</entry>

              <entry>-l walltime</entry>

              <entry>-t walltime</entry>

              <entry>This specifies the maximum runtime for the job in
              seconds. It should be an integer value. Pegasus converts it to
              the "hh:mm:ss" format required by the batch system. The value is
              rounded up to the next whole minute.</entry>
            </row>

            <row>
              <entry>pegasus.memory</entry>

              <entry>PER_PROCESS_MEMORY</entry>

              <entry>-l pmem</entry>

              <entry>-l h_vmem</entry>

              <entry>--mem memory</entry>

              <entry>--mem-per-cpu pmem</entry>

              <entry>n/a</entry>

              <entry>This specifies the maximum amount of physical memory used
              by any process in the job. For example, if the job runs four
              processes and each requires up to 2 GB (gigabytes) of memory,
              then this value should be set to "2gb" for PBS and Moab, and
              "2G" for SGE. The corresponding PBS directive would be "#PBS -l
              pmem=2gb".</entry>
            </row>

            <row>
              <entry>pegasus.project</entry>

              <entry>PROJECT</entry>

              <entry>-A project_name</entry>

              <entry>n/a</entry>

              <entry>n/a</entry>

              <entry>-A project_name</entry>

              <entry>-A project_name</entry>

              <entry>Causes the job time to be charged to or associated with a
              particular project/account. This is not used for SGE.</entry>
            </row>

            <row>
              <entry>pegasus.queue</entry>

              <entry>n/a</entry>

              <entry>-q</entry>

              <entry>-q</entry>

              <entry>n/a</entry>

              <entry>-q</entry>

              <entry/>

              <entry>This specifies the queue for the job. This profile does
              not have a corresponding value in
              <literal>+remote_cerequirements</literal>. Instead, Pegasus sets
              the <literal>batch_queue</literal> key in the Condor submit
              file, which gLite/blahp translates into the appropriate batch
              system requirement.</entry>
            </row>

            <row>
              <entry>globus.totalmemory</entry>

              <entry>TOTAL_MEMORY</entry>

              <entry>-l mem</entry>

              <entry>n/a</entry>

              <entry>--mem memory</entry>

              <entry>-l mem</entry>

              <entry>n/a</entry>

              <entry>The total memory that your job requires. It is usually
              better to just specify the pegasus.memory profile. This is not
              mapped for SGE.</entry>
            </row>

            <row>
              <entry>pegasus.glite.arguments</entry>

              <entry>EXTRA_ARGUMENTS</entry>

              <entry>prefixed by "#PBS"</entry>

              <entry>prefixed by "#?"</entry>

              <entry>prefixed by "#SBATCH"</entry>

              <entry>prefixed by "#MSUB"</entry>

              <entry>n/a</entry>

              <entry>This specifies the extra arguments that must appear in
              the generated submit script for a job. The value of this profile
              is added to the submit script prefixed by the batch
              system-specific value. These requirements override any
              requirements specified using other profiles. This is useful when
              you want to pass through special options to the underlying batch
              system. For example, on the USC cluster we use resource
              properties to specify the network type. If you want to use the
              Myrinet network, you must specify something like "-l
              nodes=8:ppn=2:myri". For infiniband, you would use something
              like "-l nodes=8:ppn=2:IB". In that case, both the nodes and ppn
              profiles would be effectively ignored.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section>
      <title>Specifying a remote directory for the job</title>

      <para>gLite/blahp does not follow the
      <literal>remote_initialdir</literal> or <literal>initialdir</literal>
      classad directives. Therefore, all the jobs that have the
      <literal>glite</literal> style applied don't have a remote directory
      specified in the submit script. Instead, Pegasus uses Kickstart to
      change to the working directory when the job is launched on the remote
      system.</para>
    </section>
  </section>

  <section id="bosco_sdsc">
    <title>SDSC Comet with BOSCO glideins</title>

    <para>BOSCO documentation: <ulink
    url="https://twiki.opensciencegrid.org/bin/view/CampusGrids/BoSCO">https://twiki.opensciencegrid.org/bin/view/CampusGrids/BoSCO</ulink></para>

    <para>BOSCO is part of the HTCondor system which allows you to set up a
    personal pool of resources brought in from a remote cluster. In this
    section, we describe how to use BOSCO to run glideins (pilot jobs)
    dynamically on the SDSC Comet cluster. The glideins are submitted based on
    the demand of the user jobs in the pool.</para>

    <para>As your regular user, on the host you want to use as a workflow
    submit host, download the latest version of HTCondor from the <ulink
    url="https://research.cs.wisc.edu/htcondor/downloads/&gt;">HTCondor
    Download page</ulink>. At this point the latest version was 8.5.2 and we
    downloaded condor-8.5.2-x86_64_RedHat6-stripped.tar.gz. Untar, and run the
    installer:</para>

    <programlisting>
$ tar xzf condor-8.5.2-x86_64_RedHat6-stripped.tar.gz
$ cd condor-8.5.2-x86_64_RedHat6-stripped
$ ./bosco_install
...
Created a script you can source to setup your Condor environment
variables. This command must be run each time you log in or may
be placed in your login scripts:
   source /home/$USER/bosco/bosco_setenv
    </programlisting>

    <para>Source the setup file as instructed, run
    <emphasis>bosco_start</emphasis>, and then test that
    <emphasis>condor_q</emphasis> and <emphasis>condor_status</emphasis>
    works.</para>

    <programlisting>
$ source /home/$USER/bosco/bosco_setenv
$ condor_q

-- Schedd: workflow.iu.xsede.org : 127.0.0.1:11000?...
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD

0 jobs; 0 completed, 0 removed, 0 idle, 0 running, 0 held, 0 suspended
$ condor_status
    </programlisting>

    <para>Let's tell BOSCO about our SDSC Comet account:</para>

    <programlisting>
$ bosco_cluster -a YOUR_SDSC_USERNAME@comet-ln2.sdsc.edu pbs
    </programlisting>

    <para>BOSCO needs a little bit more information to be able to submit the
    glideins to Comet. Log in to your Comet account via ssh (important - this
    step has to take place on Comet) and create the
    <emphasis>~/bosco/glite/bin/pbs_local_submit_attributes.sh</emphasis> file
    with the following content. You can find your allocation by running
    <emphasis>show_accounts</emphasis> and looking at the project
    column.</para>

    <programlisting>
echo "#PBS -q compute"
echo "#PBS -l nodes=1:ppn=24"
echo "#PBS -l walltime=24:00:00"
echo "#PBS -A [YOUR_COMET_ALLOCATION]"
    </programlisting>

    <para>Also chmod the file:</para>

    <programlisting>
$ chmod 755 ~/bosco/glite/bin/pbs_local_submit_attributes.sh
    </programlisting>

    <para>Log out of Comet, and get back into the host and user BOSCO was
    installed into. We also need to edit a few files on that host.
    <emphasis>~/bosco/libexec/campus_factory/share/glidein_jobs/glidein_wrapper.sh</emphasis>
    has a bug in some versions of HTCondor. Open up the file and make sure the
    eval line in the beginning is below the unset/export HOME section. If that
    is not the case, edit the file to look like:</para>

    <programlisting>
#!/bin/sh 

starting_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )"

# BLAHP does weird things with home directory
unset HOME
export HOME

eval campus_factory_dir=$_campusfactory_CAMPUSFACTORY_LOCATION
    </programlisting>

    <para>If the order of the HOME and eval statements are reversed in your
    file, change them to look like the above. At the end of
    <emphasis>~/bosco/libexec/campus_factory/share/glidein_jobs/glidein_condor_config</emphasis>
    add:</para>

    <programlisting>
# dynamic slots
SLOT_TYPE_1 = cpus=100%,disk=100%,swap=100%
SLOT_TYPE_1_PARTITIONABLE = TRUE
NUM_SLOTS = 1
NUM_SLOTS_TYPE_1 = 1
    </programlisting>

    <para>In the file
    <emphasis>~/bosco/libexec/campus_factory/share/glidein_jobs/job.submit.template</emphasis>
    find the line reading:</para>

    <programlisting>
         _condor_NUM_CPUS=1; \
    </programlisting>

    <para>You should now have a functioning BOSCO setup. Submit a Pegasus
    workflow.</para>
  </section>

  <section id="bosco">
    <title>Remote PBS Cluster using BOSCO and SSH</title>

    <para><ulink url="http://bosco.opensciencegrid.org/about/">BOSCO</ulink>
    enables HTCondor to submit jobs to remote PBS clusters using SSH. This
    section describes how to specify a site catalog entry for a site that has
    been configured for BOSCO job submissions.</para>

    <para>First, the site needs to be setup for BOSCO according to the <ulink
    url="https://twiki.opensciencegrid.org/bin/view/CampusGrids/BoSCO"> BOSCO
    documentation</ulink>. BOSCO uses glite to submit jobs to the PBS
    scheduler on the remote cluster. You will also need to configure the glite
    installed for BOSCO on the remote system according to the documentation in
    the <link linkend="glite">glite section</link> in order for the mapping of
    Pegasus profiles to PBS job requirements to work. In particular, you will
    need to install the <literal>pbs_local_submit_attributes.sh</literal> and
    <literal>sge_local_submit_attributes.sh</literal> scripts in the correct
    place in the glite <literal>bin</literal> directory on the remote cluster,
    usually in the directory <emphasis>~/bosco/glite/bin/</emphasis> .</para>

    <para>Second, to tag a site for SSH submission, the following profiles
    need to be specified for the site in the site catalog:</para>

    <orderedlist>
      <listitem>
        <para><emphasis role="bold">pegasus</emphasis> profile <emphasis
        role="bold">style</emphasis> with value set to <emphasis
        role="bold">ssh</emphasis></para>
      </listitem>

      <listitem>
        <para>Specify the service information as grid gateways. This should
        match what BOSCO provided when the cluster was set up.</para>
      </listitem>
    </orderedlist>

    <para>An example site catalog entry for a BOSCO site looks like
    this:</para>

    <programlisting>
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;

    &lt;site  handle="USC_HPCC_Bosco" arch="x86_64" os="LINUX"&gt;

        &lt;!-- Specify the service information. This should match what Bosco provided when the cluster
             was set up. --&gt;
        &lt;grid type="batch" contact="vahi@hpc-pegasus.usc.edu" scheduler="PBS" jobtype="compute"/&gt;
        &lt;grid type="batch" contact="vahi@hpc-pegasus.usc.edu" scheduler="PBS" jobtype="auxillary"/&gt;

        &lt;!-- Scratch directory on the cluster --&gt;
        &lt;directory type="shared-scratch" path="/home/rcf-40/vahi/tmp"&gt;
            &lt;file-server operation="all" url="scp://vahi@hpc-pegasus.usc.edu/home/rcf-40/vahi/tmp"/&gt;
        &lt;/directory&gt;

        &lt;!-- SSH is the style to use for Bosco SSH submits --&gt;
        &lt;profile namespace="pegasus" key="style"&gt;ssh&lt;/profile&gt;

        &lt;!--  works around bug in the HTCondor GAHP, that does not
              set the remote directory --&gt;
        &lt;profile namespace="pegasus" key="change.dir"&gt;true&lt;/profile&gt;

        &lt;!-- Job requirements should be specified using Pegasus profiles --&gt;
        &lt;profile namespace="pegasus" key="queue"&gt;default&lt;/profile&gt;
        &lt;profile namespace="pegasus" key="runtime"&gt;30&lt;/profile&gt;

    &lt;/site&gt;


&lt;/sitecatalog&gt;

</programlisting>

    <note>
      <para>It is recommended to have a submit node configured either as a
      BOSCO submit node or a vanilla HTCondor node. You cannot have HTCondor
      configured both as a BOSCO install and a traditional HTCondor submit
      node at the same time as BOSCO will override the traditional HTCondor
      pool in the user environment.</para>
    </note>

    <para>There is a bosco-shared-fs example in the examples directory of the
    distribution.</para>

    <para>Job Requirements for the jobs can be set using the same profiles as
    listed <link linkend="glite_mappings">here</link> .</para>
  </section>

  <section id="campus_cluster">
    <title>Campus Cluster</title>

    <para>There are almost as many different configurations of campus clusters
    as there are campus clusters, and because of that it can be hard to
    determine what the best way to run Pegasus workflows. Below is a ordered
    checklist with some ideas we have collected from working with users in the
    past:</para>

    <orderedlist>
      <listitem>
        <para>If the cluster scheduler is HTCondor, please see the HTCondor
        Pool section.</para>
      </listitem>

      <listitem>
        <para>If the cluster is Globus GRAM enabled, see the Globus GRAM
        section. If you have have a lot of short jobs, also read the Glidein
        section.</para>
      </listitem>

      <listitem>
        <para>For clusters without GRAM, you might be able to do glideins. If
        outbound network connectivity is allowed, your submit host can be
        anywhere. If the cluster is setup to not allow any network connections
        to the outside, you will probably have to run the submit host inside
        the cluster as well.</para>
      </listitem>
    </orderedlist>

    <para>If the cluster you are trying to use is not fitting any of the above
    scenarios, please post to the <ulink
    url="http://pegasus.isi.edu/support">Pegasus users mailing list</ulink>
    and we will help you find a solution.</para>
  </section>

  <section id="xsede">
    <title>XSEDE</title>

    <para>The <ulink url="https://www.xsede.org/">Extreme Science and
    Engineering Discovery Environment (XSEDE)</ulink> provides a set of High
    Performance Computing (HPC) and High Throughput Computing (HTC)
    resources.</para>

    <para>For the HPC resources, it is recommended to run using <link
    linkend="globus_gram">Globus GRAM</link> or <link
    linkend="glideins">glideins</link>. Most of these resources have fast
    parallel file systesm, so running with <link
    linkend="data_staging_configuration">sharedfs data staging</link> is
    recommended. Below is example site catalog and pegasusrc to run on <ulink
    url="http://www.sdsc.edu/us/resources/trestles/">SDSC
    Trestles</ulink>:</para>

    <programlisting>
&lt;sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd"
             version="4.0"&gt;
      
    &lt;site  handle="local" arch="x86_64" os="LINUX"&gt;
        &lt;directory type="shared-scratch" path="/tmp/wf/work"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/work"/&gt;
        &lt;/directory&gt;
        &lt;directory type="local-storage" path="/tmp/wf/storage"&gt;
            &lt;file-server operation="all" url="file:///tmp/wf/storage"/&gt;
        &lt;/directory&gt;
    &lt;/site&gt;

    &lt;site handle="Trestles" arch="x86_64" os="LINUX"&gt;
       &lt;grid type="gt5" contact="trestles.sdsc.edu:2119/jobmanager-fork" scheduler="PBS" jobtype="auxillary"/&gt;
       &lt;grid type="gt5" contact="trestles.sdsc.edu:2119/jobmanager-pbs" scheduler="PBS" jobtype="compute"/&gt;
       &lt;directory type="shared-scratch" path="/phase1/USERNAME"&gt;
           &lt;file-server operation="all" url="gsiftp://trestles-dm1.sdsc.edu/phase1/USERNAME"/&gt;
       &lt;/directory&gt;
    &lt;/site&gt;

&lt;/sitecatalog&gt;
</programlisting>

    <para>pegasusrc:</para>

    <programlisting>pegasus.catalog.replica=SimpleFile
pegasus.catalog.replica.file=rc

pegasus.catalog.site.file=sites.xml

pegasus.catalog.transformation=Text
pegasus.catalog.transformation.file=tc

pegasus.data.configuration = sharedfs

# Pegasus might not be installed, or be of a different version
# so stage the worker package
pegasus.transfer.worker.package = true
</programlisting>

    <para>The HTC resources available on XSEDE are all HTCondor based, so
    standard <link linkend="condor_pool">HTCondor Pool</link> setup will work
    fine.</para>

    <para>If you need to run high throughput workloads on the HPC machines
    (for example, post processing after a large parallel job), <link
    linkend="glideins">glideins</link> can be useful as it is a more efficient
    method for small jobs on these systems.</para>
  </section>

  <section id="open_science_grid">
    <title>Open Science Grid Using glideinWMS</title>

    <section>
      <para><ulink
      url="http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/">
      glideinWMS</ulink> is a glidein system widely used on Open Science Grid.
      Running on top of glideinWMS is like running on a <link
      linkend="condor_pool">Condor Pool</link> without a shared
      filesystem.</para>
    </section>
  </section>
</chapter>
<?xxe-serial-numbers jb5ikm0k vahi
(1z141z5 (1z141z6) (1z141z7) (1z141z8 (1z141z9) (1z141za (1z141zb))
(1z141zc (1z141zd)) (1z141ze) (1z141zf (1z141zg) (1z141zh))) (1z141zi
(1z141zj) (1z141zk) (1z141zl (1z141zm) (1z141zn (1z141zo (1z141zp))))
(1z141zq) (1z141zr (1z141zs) (1z141zt) (1z141zu)) (1z141zv) (1z141zw)
(1z141zx) (1z141zy (1z141zz) (1z14200 (1z14201) (1z14202)) (1z14203
(1z14204 (1z14205) (1z14206) (1z14207))) (1z14208) (1z14209 (1z1420a
(1z1420b (1z1420c) (1z1420d))) (1z1420e (1z1420f (1z1420g))) (1z1420h
(1z1420i (1z1420j))) (1z1420k (1z1420l)))) (1z1420m (1z1420n) (1z1420o)
(1z1420p) (1z1420q) (1z1420r) (1z1420s))) (1z1420t (1z1420u) (1z1420v
(1z1420w (1z1420x) (1z1420y (1z1420z (1z14210))))) (1z14211) (1z14212)
(1z14213 (1z14214)) (1z14215) (1z14216) (1z14217) (1z14218 (1z14219))
(1z1421a (1z1421b)) (1z1421c) (1z1421d (1z1421e) (1z1421f) (1z1421g
(1z1421h (1z1421i) (1z1421j (1z1421k (1z1421l))))) (1z1421m (1z1421n))
(1z1421o (1z1421p))) (1z1421q (1z1421r) (1z1421s) (1z1421t) (1z1421u)
(1z1421v) (1z1421w))) (1z1421x (1z1421y) (1z1421z) (1z14220 (1z14221)
(1z14222) (1z14223) (1z14224)) (1z14225 (1z14226 (1z14227) (1z14228
(1z14229 (1z1422a))))) (1z1422b (1z1422c)) (1z1422d) (1z1422e (1z1422f))
(1z1422g) (1z1422h) (1z1422i (1z1422j) (1z1422k) (1z1422l) (1z1422m))
(1z1422n (1z1422o)) (1z1422p) (1z1422q) (1z1422r) (1z1422s (1z1422t))
(1z1422u) (1z1422v (1z1422w)) (1z1422x (1z1422y (1z1422z (1z14230)))
(1z14231 (1z14232 (1z14233))) (1z14234 (1z14235 (1z14236)))) (1z14237)
(1z14238) (1z14239) (1z1423a) (1z1423b)) (1z1423c (1z1423d) (1z1423e
(1z1423f (1z1423g) (1z1423h (1z1423i (1z1423j))))) (1z1423k (1z1423l))
(1z1423m (1z1423n)) (1z1423o (1z1423p)) (1z1423q) (1z1423r (1z1423s)
(1z1423t)) (1z1423u (1z1423v)) (1z1423w (1z1423x)) (1z1423y (1z1423z))
(1z14240) (1z14241) (1z14242) (1z14243)) (1z14244 (1z14245) (1z14246
(1z14247)) (1z14248) (1z14249 (1z1424a (1z1424b (1z1424c) (1z1424d)
(1z1424e))) (1z1424f (1z1424g (1z1424h) (1z1424i) (1z1424j))) (1z1424k
(1z1424l (1z1424m) (1z1424n) (1z1424o)))) (1z1424p) (1z1424q) (1z1424r)
(1z1424s (1z1424t (1z1424u)))) (1z1424v (1z1424w) (1z1424x) (1z1424y
(1z1424z)) (1z14250 (1z14251)) (1z14252 (1z14253) (1z14254) (1z14255))
(1z14256 (1z14257 (1z14258))) (1z14259 (1z1425a)) (1z1425b) (1z1425c
(1z1425d (1z1425e (1z1425f) (1z1425g) (1z1425h))) (1z1425i (1z1425j
(1z1425k) (1z1425l) (1z1425m) (1z1425n) (1z1425o)))) (1z1425p) (1z1425q)
(1z1425r (1z1425s)) (1z1425t (1z1425u) (1z1425v) (1z1425w) (1z1425x))
(1z1425y (1z1425z)) (1z14260) (1z14261) (1z14262 (1z14263) (1z14264)
(1z14265 (1z14266) (1z14267 (1z14268 (1z14269 (1z1426a) (1z1426b)
(1z1426c) (1z1426d) (1z142bc) (1z1426e) (1z1426f) (1z1426g))) (1z1426h
(1z1426i (1z1426j) (1z1426k) (1z1426l) (1z1426m) (1z142bd) (1z1426n)
(1z1426o) (1z1426p)) (1z1426q (1z1426r) (1z1426s) (1z1426t) (1z1426u)
(1z142be) (1z1426v) (1z1426w) (1z1426x)) (1z1426y (1z1426z) (1z14270)
(1z14271) (1z14272) (1z142bf) (1z14273) (1z14274) (1z14275)) (1z14276
(1z14277) (1z14278) (1z14279) (1z1427a) (1z142bg) (1z1427b) (1z1427c)
(1z1427d)) (1z1427e (1z1427f) (1z1427g) (1z1427h) (1z1427i) (1z142bh)
(1z1427j) (1z1427k) (1z1427l)) (1z1427m (1z1427n) (1z1427o) (1z1427p)
(1z1427q) (1z142bi) (1z1427r) (1z1427s) (1z1427t)) (1z1427u (1z1427v)
(1z1427w) (1z1427x) (1z1427y) (1z142bj) (1z1427z) (1z14280) (1z14281
(1z14282) (1z14283))) (1z14284 (1z14285) (1z14286) (1z14287) (1z14288)
(1z142bk) (1z14289) (1z1428a) (1z1428b)) (1z1428c (1z1428d) (1z1428e)
(1z1428f) (1z1428g) (1z142bl) (1z1428h) (1z1428i) (1z1428j))))) (1z1428k
(1z1428l))) (1z1428m (1z1428n) (1z1428o (1z1428p) (1z1428q) (1z1428r))))
(1z1428s (1z1428t) (1z1428u (1z1428v)) (1z1428w) (1z1428x (1z1428y))
(1z1428z) (1z14290 (1z14291) (1z14292) (1z14293)) (1z14294) (1z14295)
(1z14296) (1z14297 (1z14298) (1z14299)) (1z1429a) (1z1429b) (1z1429c)
(1z1429d (1z1429e)) (1z1429f) (1z1429g (1z1429h)) (1z1429i) (1z1429j
(1z1429k)) (1z1429l) (1z1429m)) (1z1429n (1z1429o) (1z1429p (1z1429q))
(1z1429r (1z1429s) (1z1429t) (1z1429u) (1z1429v) (1z1429w) (1z1429x))
(1z1429y) (1z1429z (1z142a0 (1z142a1 (1z142a2) (1z142a3) (1z142a4)))
(1z142a5 (1z142a6))) (1z142a7) (1z142a8) (1z142a9 (1z142aa)) (1z142ab)
(1z142ac (1z142ad))) (1z142ae (1z142af) (1z142ag) (1z142ah (1z142ai
(1z142aj)) (1z142ak (1z142al)) (1z142am (1z142an))) (1z142ao (1z142ap)))
(1z142aq (1z142ar) (1z142as (1z142at)) (1z142au (1z142av) (1z142aw)
(1z142ax) (1z142ay)) (1z142az) (1z142b0) (1z142b1) (1z142b2 (1z142b3))
(1z142b4 (1z142b5))) (1z142b6 (1z142b7) (1z142b8 (1z142b9 (1z142ba)
(1z142bb)))))?>
