<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<section id="profiles">
  <title>Configuration</title>

  <para>Pegasus has configuration options to configure </para>

  <orderedlist>
    <listitem>
      <para>the behaviour of an individual job via <emphasis
      role="bold">profiles</emphasis></para>
    </listitem>

    <listitem>
      <para>the behavior of the whole system via <emphasis
      role="bold">properties</emphasis></para>
    </listitem>
  </orderedlist>

  <para>For job level configuration ( such as what environment a job is set
  with ), the Pegasus Workflow Mapper uses the concept of profiles. Profiles
  encapsulate configurations for various aspects of dealing with the Grid
  infrastructure. They provide an abstract yet uniform interface to specify
  configuration options for various layers from planner/mapper behavior to
  remote environment settings. At various stages during the mapping process,
  profiles may be added associated with the job. The system supports five
  diffferent namespaces, with each namespace refers to a different aspect of a
  job's runtime settings. A profile's representation in the executable
  workflow (e.g. the Condor submit files) depends on its namespace. Pegasus
  supports the following Namespaces for profiles:</para>

  <itemizedlist>
    <listitem>
      <para><emphasis role="bold">env</emphasis> permits remote environment
      variables to be set.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">globus</emphasis> sets Globus RSL
      parameters.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">condor</emphasis> sets Condor configuration
      parameters for the submit file.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">dagman</emphasis> introduces Condor DAGMan
      configuration parameters.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">pegasus</emphasis> configures the behaviour
      of various planner/mapper components.</para>
    </listitem>
  </itemizedlist>

  <para/>

  <para>Properties are primarily used to configure the behavior of the Pegasus
  WMS system at a global level. The properties file is actually a java
  properties file and follows the same conventions as that to specify the
  properties.</para>

  <para>This chapter describes various types of profiles and properties,
  levels of priorities for intersecting profiles, and how to specify profiles
  in different contexts.</para>

  <section>
    <title>Differences between Profiles and Properties</title>

    <para>The main difference between properties and profiles is that profiles
    eventually get associated at a per job level in the workflow. On the other
    hand, properties are a way of configuring and controlling the behavior of
    the whole system. While all profiles can be specified in the properties
    file, not all properties can be used as profiles. This section lists out
    the properties supported by Pegasus and if any can be used as a profile,
    it is clearly indicated.</para>
  </section>

  <section>
    <title>Profile Structure Heading</title>

    <para>All profiles are triples comprised of a namespace, a name or key,
    and a value. The namespace is a simple identifier. The key has only
    meaning within its namespace, and it's yet another identifier. There are
    no constraints on the contents of a value</para>

    <para>Profiles may be represented with different syntaxes in different
    context. However, each syntax will describe the underlying triple.</para>
  </section>

  <section>
    <title>Sources for Profiles</title>

    <para>Profiles may enter the job-processing stream at various stages.
    Depending on the requirements and scope a profile is to apply, profiles
    can be associated at</para>

    <itemizedlist>
      <listitem>
        <para>as user property settings.</para>
      </listitem>

      <listitem>
        <para>dax level</para>
      </listitem>

      <listitem>
        <para>in the site catalog</para>
      </listitem>

      <listitem>
        <para>in the transformation catalog</para>
      </listitem>
    </itemizedlist>

    <para>Unfortunately, a different syntax applies to each level and context.
    This section shows the different profile sources and syntaxes. However, at
    the foundation of each profile lies the triple of namespace, key and
    value.</para>

    <section>
      <title>User Profiles in Properties</title>

      <para>Users can specify all profiles in the properties files where the
      property name is <emphasis role="bold">[namespace].key</emphasis> and
      <emphasis role="bold">value</emphasis> of the property is the value of
      the profile.</para>

      <para>Namespace can be env|condor|globus|dagman|pegasus</para>

      <para>Any profile specified as a property applies to the whole workflow
      i.e (all jobs in the workflow) unless overridden at the DAX level , Site
      Catalog , Transformation Catalog Level.</para>

      <para>Some profiles that they can be set in the properties file are
      listed below</para>

      <programlisting>env.JAVA_HOME "/software/bin/java"

condor.periodic_release 5
condor.periodic_remove  my_own_expression
condor.stream_error true
condor.stream_output fa

globus.maxwalltime  1000
globus.maxtime      900
globus.maxcputime   10
globus.project      test_project
globus.queue        main_queue

dagman.post.arguments --test arguments
dagman.retry  4
dagman.post simple_exitcode
dagman.post.path.simple_exitcode  /bin/exitcode/exitcode.sh
dagman.post.scope all
dagman.maxpre  12
dagman.priority 13

dagman.bigjobs.maxjobs 1


pegasus.clusters.size 5

pegasus.stagein.clusters 3</programlisting>
    </section>

    <section>
      <title>Profiles in DAX</title>

      <para>The user can associate profiles with logical transformations in
      DAX. Environment settings required by a job's application, or a maximum
      estimate on the run-time are examples for profiles at this stage.</para>

      <programlisting>&lt;job id="ID000001" namespace="asdf" name="preprocess" version="1.0"
 level="3" dv-namespace="voeckler" dv-name="top" dv-version="1.0"&gt;
  &lt;argument&gt;-a top -T10  -i &lt;filename file="voeckler.f.a"/&gt;
 -o &lt;filename file="voeckler.f.b1"/&gt;
 &lt;filename file="voeckler.f.b2"/&gt;&lt;/argument&gt;
  <emphasis role="bold">&lt;profile namespace="pegasus" key="walltime"&gt;2&lt;/profile&gt;
  &lt;profile namespace="pegasus" key="diskspace"&gt;1&lt;/profile&gt;</emphasis>
  &amp;mldr;
&lt;/job&gt;
</programlisting>
    </section>

    <section>
      <title>Profiles in Site Catalog</title>

      <para>If it becomes necessary to limit the scope of a profile to a
      single site, these profiles should go into the site catalog. A profile
      in the site catalog applies to all jobs and all application run at the
      site. Commonly, site catalog profiles set environment settings like the
      LD_LIBRARY_PATH, or globus rsl parameters like queue and project
      names.</para>

      <para>Currently, there is no tool to manipulate the site catalog, e.g.
      by adding profiles. Modifying the site catalog requires that you load it
      into your editor.</para>

      <para>The XML version of the site catalog uses the following
      syntax:</para>

      <programlisting><emphasis role="bold">&lt;profile namespace=</emphasis>"<emphasis>namespace</emphasis>" <emphasis
          role="bold">key=</emphasis>"<emphasis>key</emphasis>"&gt;<emphasis>value</emphasis><emphasis
          role="bold">&lt;/profile&gt;</emphasis></programlisting>

      <para>The XML schema requires that profiles are the first children of a
      pool element. If the element ordering is wrong, the XML parser will
      produce errors and warnings:</para>

      <programlisting>&lt;pool handle="isi_condor" gridlaunch="/home/shared/pegasus/bin/kickstart"&gt;
  <emphasis role="bold">&lt;profile namespace="env"
   key="GLOBUS_LOCATION"&gt;/home/shared/globus/&lt;/profile&gt;
  &lt;profile namespace="env"
   key="LD_LIBRARY_PATH" &gt;/home/shared/globus/lib&lt;/profile&gt;</emphasis>
  &lt;lrc url="rls://sukhna.isi.edu" /&gt;
  &amp;mldr;
&lt;/pool&gt;
</programlisting>

      <para>The multi-line textual version of the site catalog uses the
      following syntax:</para>

      <programlisting><emphasis role="bold">profile</emphasis> <emphasis>namespace "key" "value"</emphasis></programlisting>

      <para>The order within the textual pool definition is not important.
      Profiles can appear anywhere:</para>

      <programlisting>pool isi_condor {
  gridlaunch "/home/shared/pegasus/bin/kickstart"
  <emphasis role="bold">profile env "GLOBUS_LOCATION" "/home/shared/globus"
  profile env "LD_LIBRARY_PATH" "/home/shared/globus/lib"</emphasis>
  &amp;mldr;
}
</programlisting>
    </section>

    <section>
      <title>Profiles in Transformation Catalog</title>

      <para>Some profiles require a narrower scope than the site catalog
      offers. Some profiles only apply to certain applications on certain
      sites, or change with each application and site. Transformation-specific
      and CPU-specific environment variables, or job clustering profiles are
      good candidates. Such profiles are best specified in the transformation
      catalog.</para>

      <para>Profiles associate with a physical transformation and site in the
      transformation catalog. The Database version of the transformation
      catalog also permits the convenience of connecting a transformation with
      a profile.</para>

      <para>The Pegasus tc-client tool is a convenient helper to associate
      profiles with transformation catalog entries. As benefit, the user does
      not have to worry about formats of profiles in the various
      transformation catalog instances.</para>

      <programlisting>tc-client -a -P -E -p /home/shared/executables/analyze -t INSTALLED -r isi_condor -e env::GLOBUS_LOCATION=&amp;rdquor;/home/shared/globus&amp;rdquor;</programlisting>

      <para>The above example adds an environment variable GLOBUS_LOCATION to
      the application /home/shared/executables/analyze on site isi_condor. The
      transformation catalog guide has more details on the usage of the
      tc-client.</para>
    </section>
  </section>

  <section>
    <title>Profiles Conflict Resolution</title>

    <para>Irrespective of where the profiles are specified, eventually the
    profiles are associated with jobs. Multiple sources may specify the same
    profile for the same job. For instance, DAX may specify an environment
    variable X. The site catalog may also specify an environment variable X
    for the chosen site. The transformation catalog may specify an environment
    variable X for the chosen site and application. When the job is
    concretized, these three conflicts need to be resolved.</para>

    <para>Pegasus defines a priority ordering of profiles. The higher priority
    takes precedence (overwrites) a profile of a lower priority.</para>

    <orderedlist>
      <listitem>
        <para>Transformation Catalog Profiles</para>
      </listitem>

      <listitem>
        <para>Site Catalog Profiles</para>
      </listitem>

      <listitem>
        <para>DAX Profiles</para>
      </listitem>

      <listitem>
        <para>Profiles in Properties</para>
      </listitem>
    </orderedlist>
  </section>

  <section>
    <title>Details of Profile Handling</title>

    <para>The previous sections omitted some of the finer details for the sake
    of clarity. To understand some of the constraints that Pegasus imposes, it
    is required to look at the way profiles affect jobs.</para>

    <section>
      <title>Details of env Profiles</title>

      <para>Profiles in the env namespace are translated to a
      semicolon-separated list of key-value pairs. The list becomes the
      argument for the Condor environment command in the job's submit
      file.</para>

      <programlisting>######################################################################
# Pegasus WMS  SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
globusrsl = (jobtype=single)
<emphasis role="bold">environment=GLOBUS_LOCATION=/shared/globus;LD_LIBRARY_PATH=/shared/globus/lib;</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

      <para>Condor-G, in turn, will translate the
      <emphasis>environment</emphasis> command for any remote job into Globus
      RSL environment settings, and append them to any existing RSL syntax it
      generates. To permit proper mixing, all <emphasis>environment</emphasis>
      setting should solely use the env profiles, and none of the Condor nor
      Globus environment settings.</para>

      <para>If <emphasis>kickstart</emphasis> starts a job, it may make use of
      environment variables in its executable and arguments setting.</para>
    </section>

    <section>
      <title>Details of globus Profiles</title>

      <para>Profiles in the <emphasis>globus</emphasis> Namespaces are
      translated into a list of paranthesis-enclosed equal-separated key-value
      pairs. The list becomes the value for the Condor
      <emphasis>globusrsl</emphasis> setting in the job's submit file:</para>

      <programlisting>######################################################################
# Pegasus WMS SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
<emphasis role="bold">globusrsl = (jobtype=single)(queue=fast)(project=nvo)</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

      <para>For this reason, Pegasus prohibits the use of the
      <emphasis>globusrsl</emphasis> key in the <emphasis>condor</emphasis>
      profile namespace.</para>
    </section>
  </section>

  <section>
    <title>The env Profile Namespace</title>

    <para>The <emphasis>env</emphasis> namespace allows users to specify
    environment variables of remote jobs. Globus transports the environment
    variables, and ensure that they are set before the job starts.</para>

    <para>The key used in conjunction with an <emphasis>env</emphasis> profile
    denotes the name of the environment variable. The value of the profile
    becomes the value of the remote environment variable.</para>

    <para>Grid jobs usually only set a minimum of environment variables by
    virtue of Globus. You cannot compare the environment variables visible
    from an interactive login with those visible to a grid job. Thus, it often
    becomes necessary to set environment variables like LD_LIBRARY_PATH for
    remote jobs.</para>

    <para>If you use any of the Pegasus worker package tools like transfer or
    the rc-client, it becomes necessary to set PEGASUS_HOME and
    GLOBUS_LOCATION even for jobs that run locally</para>

    <table>
      <title>Useful Environment Settings</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile Key
            </emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>env.PEGASUS_HOME</entry>

            <entry>PEGASUS_HOME</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Used by auxillary jobs created by Pegasus both on remote
            site and local site. Should be set usually set in the Site Catalog
            for the sites</entry>
          </row>

          <row>
            <entry>env.GLOBUS_LOCATION</entry>

            <entry>GLOBUS_LOCATION</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Used by auxillary jobs created by Pegasus both on remote
            site and local site. Should be set usually set in the Site Catalog
            for the sites</entry>
          </row>

          <row>
            <entry>env.LD_LIBRARY_PATH</entry>

            <entry>LD_LIBRARY_PATH</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Point this to $GLOBUS_LOCATION/lib, except you cannot use
            the dollar variable. You must use the full path. Applies to both,
            local and remote jobs that use Globus components and should be
            usually set in the site catalog for the sites</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>Even though Condor and Globus both permit environment variable
    settings through their profiles, all remote environment variables must be
    set through the means of <emphasis>env</emphasis> profiles.</para>
  </section>

  <section>
    <title>The Globus Profile Namespace</title>

    <para>The <emphasis>globus</emphasis> profile namespace encapsulates
    Globus resource specification language (RSL) instructions. The RSL
    configures settings and behavior of the remote scheduling system. Some
    systems require queue name to schedule jobs, a project name for accounting
    purposes, or a run-time estimate to schedule jobs. The Globus RSL
    addresses all these issues.</para>

    <para>A key in the <emphasis>globus</emphasis> namespace denotes the
    command name of an RLS instruction. The profile value becomes the RSL
    value. Even though Globus RSL is typically shown using parentheses around
    the instruction, the out pair of parentheses is not necessary in globus
    profile specifications</para>

    <para>Table 2 shows some commonly used RSL instructions. For an
    authoritative list of all possible RSL instructions refer to the Globus
    RSL specification.</para>

    <table>
      <title>Useful Globus RSL Instructions</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile
            Key</emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>globus.count</entry>

            <entry>count</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the number of times an executable is started.</entry>
          </row>

          <row>
            <entry>globus.jobtype</entry>

            <entry>jobtype</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>specifies how the job manager should start the remote job.
            While Pegasus defaults to single, use mpi when running MPI
            jobs.</entry>
          </row>

          <row>
            <entry>globus.maxcputime</entry>

            <entry>maxcputime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the max CPU time in minutes for a single execution of a
            job.</entry>
          </row>

          <row>
            <entry>globus.maxmemory</entry>

            <entry>maxmemory</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the maximum memory in MB required for the job</entry>
          </row>

          <row>
            <entry>globus.maxtime</entry>

            <entry>maxtime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the maximum time or walltime in minutes for a single
            execution of a job.</entry>
          </row>

          <row>
            <entry>globus.maxwalltime</entry>

            <entry>maxwalltime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the maximum walltime in minutes for a single execution of a
            job.</entry>
          </row>

          <row>
            <entry>globus.minmemory</entry>

            <entry>minmemory</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the minumum amount of memory required for this job</entry>
          </row>

          <row>
            <entry>globus.project</entry>

            <entry>project</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>associates an account with a job at the remote end.</entry>
          </row>

          <row>
            <entry>globus.queue</entry>

            <entry>queue</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the remote queue in which the job should be run. Used when
            remote scheduler is PBS that supports queues.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>Pegasus prevents the user from specifying certain RSL instructions
    as globus profiles, because they are either automatically generated or can
    be overridden through some different means. For instance, if you need to
    specify remote environment settings, do not use the environment key in the
    globus profiles. Use one or more env profiles instead.</para>

    <table>
      <title> RSL Instructions that are not permissible</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry><emphasis role="bold">Key</emphasis></entry>

            <entry><emphasis role="bold">Reason for
            Prohibition</emphasis></entry>
          </row>

          <row>
            <entry>arguments</entry>

            <entry>you specify arguments in the arguments section for a job in
            the DAX</entry>
          </row>

          <row>
            <entry>directory</entry>

            <entry>the site catalog and properties determine which directory a
            job will run in.</entry>
          </row>

          <row>
            <entry>environment</entry>

            <entry>use multiple env profiles instead</entry>
          </row>

          <row>
            <entry>executable</entry>

            <entry>the physical executable to be used is specified in the
            transformation catalog and is also dependant on the gridstart
            module being used. If you are launching jobs via kickstart then
            the executable created is the path to kickstart and the
            application executable path appears in the arguments for
            kickstart</entry>
          </row>

          <row>
            <entry>stdin</entry>

            <entry>you specify in the DAX for the job</entry>
          </row>

          <row>
            <entry>stdout</entry>

            <entry>you specify in the DAX for the job</entry>
          </row>

          <row>
            <entry>stderr</entry>

            <entry>you specify in the DAX for the job</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>The Condor Profile Namespace</title>

    <para>The Condor submit file controls every detail how and where a job is
    run. The <emphasis>condor</emphasis> profiles permit to add or overwrite
    instructions in the Condor submit file.</para>

    <para>The <emphasis>condor</emphasis> namespace directly sets commands in
    the Condor submit file for a job the profile applies to. Keys in the
    <emphasis>condor</emphasis> profile namespace denote the name of the
    Condor command. The profile value becomes the command's argument. All
    <emphasis>condor</emphasis> profiles are translated into key=value lines
    in the Condor submit file</para>

    <para>Some of the common condor commands that a user may need to specify
    are listed below. For an authoritative list refer to the online condor
    documentation. Note: Pegasus Workflow Planner/Mapper by default specify a
    lot of condor commands in the submit files depending upon the job, and
    where it is being run.</para>

    <table>
      <title> Useful Condor Commands</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile
            Key</emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>condor.universe</entry>

            <entry>universe</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Pegasus defaults to either globus or scheduler universes.
            Set to standard for compute jobs that require standard universe.
            Set to vanilla to run natively in a condor pool, or to run on
            resources grabbed via condor glidein.</entry>
          </row>

          <row>
            <entry>condor.periodic_release</entry>

            <entry>periodic_release</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>is the number of times job is released back to the queue if
            it goes to HOLD, e.g. due to Globus errors. Pegasus defaults to
            3.</entry>
          </row>

          <row>
            <entry>condor.periodic_remove</entry>

            <entry>periodic_remove</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>is the number of times a job is allowed to get into HOLD
            state before being removed from the queue. Pegasus defaults to
            3.</entry>
          </row>

          <row>
            <entry>condor.filesystemdomain</entry>

            <entry>filesystemdomain</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Useful for Condor glide-ins to pin a job to a remote
            site.</entry>
          </row>

          <row>
            <entry>condor.stream_error</entry>

            <entry>stream_error</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>boolean to turn on the streaming of the stderr of the
            remote job back to submit host.</entry>
          </row>

          <row>
            <entry>condor.stream_output</entry>

            <entry>stream_output</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>boolean to turn on the streaming of the stdout of the
            remote job back to submit host.</entry>
          </row>

          <row>
            <entry>condor.priority</entry>

            <entry>priority</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>integer value to assign the priority of a job. Higher value
            means higher priority. The priorities are only applied for vanilla
            / standard/ local universe jobs. Determines the order in which a
            users own jobs are executed.</entry>
          </row>

          <row>
            <entry>condor.request_cpus</entry>

            <entry>request_cpus</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>New in Condor 7.8.0 . Number of CPU's a job
            requires.</entry>
          </row>

          <row>
            <entry>condor.request_memory</entry>

            <entry>request_memory</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>New in Condor 7.8.0 . Amount of memory a job
            requires.</entry>
          </row>

          <row>
            <entry>condor.request_disk</entry>

            <entry>request_disk</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>New in Condor 7.8.0 . Amount of disk a job
            requires.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>Other useful condor keys, that advanced users may find useful and
    can be set by profiles are</para>

    <orderedlist>
      <listitem>
        <para>should_transfer_files</para>
      </listitem>

      <listitem>
        <para>transfer_output</para>
      </listitem>

      <listitem>
        <para>transfer_error</para>
      </listitem>

      <listitem>
        <para>whentotransferoutput</para>
      </listitem>

      <listitem>
        <para>requirements</para>
      </listitem>

      <listitem>
        <para>rank</para>
      </listitem>
    </orderedlist>

    <para>Pegasus prevents the user from specifying certain Condor commands in
    condor profiles, because they are automatically generated or can be
    overridden through some different means. Table 5 shows prohibited Condor
    commands.</para>

    <table>
      <title>Table 5: Condor commands prohibited in condor profiles</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry><emphasis role="bold">Key</emphasis></entry>

            <entry><emphasis role="bold">Reason for
            Prohibition</emphasis></entry>
          </row>

          <row>
            <entry>arguments</entry>

            <entry>you specify arguments in the arguments section for a job in
            the DAX</entry>
          </row>

          <row>
            <entry>environment</entry>

            <entry>use multiple env profiles instead</entry>
          </row>

          <row>
            <entry>executable</entry>

            <entry>the physical executable to be used is specified in the
            transformation catalog and is also dependant on the gridstart
            module being used. If you are launching jobs via kickstart then
            the executable created is the path to kickstart and the
            application executable path appears in the arguments for
            kickstart</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>The Dagman Profile Namespace</title>

    <para>DAGMan is Condor's workflow manager. While planners generate most of
    DAGMan's configuration, it is possible to tweak certain job-related
    characteristics using dagman profiles. A dagman profile can be used to
    specify a DAGMan pre- or post-script.</para>

    <para>Pre- and post-scripts execute on the submit machine. Both inherit
    the environment settings from the submit host when pegasus-submit-dag or
    pegasus-run is invoked.</para>

    <para>By default, kickstart launches all jobs except standard universe and
    MPI jobs. Kickstart tracks the execution of the job, and returns usage
    statistics for the job. A DAGMan post-script starts the Pegasus
    application exitcode to determine, if the job succeeded. DAGMan receives
    the success indication as exit status from exitcode.</para>

    <para>If you need to run your own post-script, you have to take over the
    job success parsing. The planner is set up to pass the file name of the
    remote job's stdout, usually the output from kickstart, as sole argument
    to the post-script.</para>

    <para>Table 6 shows the keys in the dagman profile domain that are
    understood by Pegasus and can be associated at a per job basis.</para>

    <para><table>
        <title> Useful dagman Commands that can be associated at a per job
        basis</title>

        <tgroup cols="4">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Corresponding Profile Key
              </emphasis></entry>

              <entry><emphasis role="bold">Where can it be
              specified</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>dagman.pre</entry>

              <entry>PRE</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>is the path to the pre-script. DAGMan executes the
              pre-script before it runs the job.</entry>
            </row>

            <row>
              <entry>dagman.pre.arguments</entry>

              <entry>PRE.ARGUMENTS</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>are command-line arguments for the pre-script, if
              any.</entry>
            </row>

            <row>
              <entry>dagman.post</entry>

              <entry>POST</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>is the postscript type/mode that a user wants to
              associate with a job. <orderedlist>
                  <listitem>
                    <para><emphasis role="bold">pegasus-exitcode</emphasis> -
                    pegasus will by default associate this postscript with all
                    jobs launched via kickstart, as long the POST.SCOPE value
                    is not set to NONE.</para>
                  </listitem>

                  <listitem>
                    <para><emphasis role="bold">none</emphasis> -means that no
                    postscript is generated for the jobs. This is useful for
                    MPI jobs that are not launched via kickstart
                    currently.</para>
                  </listitem>

                  <listitem>
                    <para><emphasis role="bold">any legal
                    identifier</emphasis> - Any other identifier of the form
                    ([_A-Za-z][_A-Za-z0-9]*), than one of the 2 reserved
                    keywords above, signifies a user postscript. This allows
                    the user to specify their own postscript for the jobs in
                    the workflow. The path to the postscript can be specified
                    by the dagman profile <emphasis
                    role="bold">POST.PATH.[value</emphasis>] where [value] is
                    this legal identifier specified. The user postscript is
                    passed the name of the .out file of the job as the last
                    argument on the command line.</para>

                    <para>For e.g. if the following dagman profiles were
                    associated with a job X</para>

                    <orderedlist>
                      <listitem>
                        <para>POST with value user_script
                        /bin/user_postscript</para>
                      </listitem>

                      <listitem>
                        <para>POST.PATH.user_script with value
                        /path/to/user/script</para>
                      </listitem>

                      <listitem>
                        <para>POST.ARGUMENTS with value -verbose</para>
                      </listitem>
                    </orderedlist>

                    <para>then the following postscript will be associated
                    with the job X in the .dag file</para>

                    <para>/path/to/user/script -verbose X.out where X.out
                    contains the stdout of the job X</para>
                  </listitem>
                </orderedlist></entry>
            </row>

            <row>
              <entry>dagman.post.path.[value of dagman.post]</entry>

              <entry>POST.PATH.* ( where * is replaced by the value of the
              POST Profile )</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>the path to the post script on the submit host.</entry>
            </row>

            <row>
              <entry>dagman.post.arguments</entry>

              <entry>POST.ARGUMENTS</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>are the command line arguments for the post script, if
              any.</entry>
            </row>

            <row>
              <entry>dagman.retry</entry>

              <entry>RETRY</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>is the number of times DAGMan retries the full job cycle
              from pre-script through post-script, if failure was
              detected.</entry>
            </row>

            <row>
              <entry>dagman.category</entry>

              <entry>CATEGORY</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>the DAGMan category the job belongs to.</entry>
            </row>

            <row>
              <entry>dagman.priority</entry>

              <entry>PRIORITY</entry>

              <entry>Transformation Catalog, Site Catalog, DAX, Properties
              File</entry>

              <entry>the priority to apply to a job. DAGMan uses this to
              select what jobs to release when MAXJOBS is enforced for the
              DAG.</entry>
            </row>
          </tbody>
        </tgroup>
      </table></para>

    <para/>

    <para>Table 7 shows the keys in the dagman profile domain that are
    understood by Pegasus and can be used to apply to the whole workflow.
    These are used to control DAGMan's behavior at the workflow level, and are
    recommended to be specified in the properties file.</para>

    <table>
      <title>Useful dagman Commands that can be specified in the properties
      file.</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile
            Key</emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>dagman.maxpre</entry>

            <entry>MAXPRE</entry>

            <entry>Properties File</entry>

            <entry>sets the maximum number of PRE scripts within the DAG that
            may be running at one time</entry>
          </row>

          <row>
            <entry>dagman.maxpost</entry>

            <entry>MAXPOST</entry>

            <entry>Properties File</entry>

            <entry>sets the maximum number of PRE scripts within the DAG that
            may be running at one time</entry>
          </row>

          <row>
            <entry>dagman.maxjobs</entry>

            <entry>MAXJOBS</entry>

            <entry>Properties File</entry>

            <entry>sets the maximum number of jobs within the DAG that will be
            submitted to Condor at one time.</entry>
          </row>

          <row>
            <entry>dagman.maxidle</entry>

            <entry>MAXIDLE</entry>

            <entry>Properties File</entry>

            <entry>sets the maximum number of idle jobs within the DAG that
            will be submitted to Condor at one time.</entry>
          </row>

          <row>
            <entry>dagman.[CATEGORY-NAME].maxjobs</entry>

            <entry>[CATEGORY-NAME].MAXJOBS</entry>

            <entry>Properties File</entry>

            <entry>is the value of maxjobs for a particular category. Users
            can associate different categories to the jobs at a per job basis.
            However, the value of a dagman knob for a category can only be
            specified at a per workflow basis in the properties.</entry>
          </row>

          <row>
            <entry>dagman.post.scope</entry>

            <entry>POST.SCOPE</entry>

            <entry>Properties File</entry>

            <entry>scope for the postscripts. <orderedlist>
                <listitem>
                  <para>If set to <emphasis role="bold">all</emphasis> , means
                  each job in the workflow will have a postscript associated
                  with it.</para>
                </listitem>

                <listitem>
                  <para>If set to <emphasis role="bold">none</emphasis> ,
                  means no job has postscript associated with it. None mode
                  should be used if you are running vanilla / standard/ local
                  universe jobs, as in those cases Condor traps the remote
                  exitcode correctly. None scope is not recommended for grid
                  universe jobs.</para>
                </listitem>

                <listitem>
                  <para>If set to <emphasis role="bold">essential</emphasis>,
                  means only essential jobs have post scripts associated with
                  them. At present the only non essential job is the replica
                  registration job.</para>
                </listitem>
              </orderedlist></entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>The Pegasus Profile Namespace</title>

    <para>The <emphasis>pegasus</emphasis> profiles allow users to configure
    extra options to the Pegasus Workflow Planner that can be applied
    selectively to a job or a group of jobs. Site selectors may use a sub-set
    of <emphasis>pegasus</emphasis> profiles for their decision-making.</para>

    <para>Table 8 shows some of the useful configuration option Pegasus
    understands.</para>

    <table>
      <title>Useful pegasus Profiles.</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile
            Key</emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>pegasus.clusters.num</entry>

            <entry>clusters.num</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Please refer to the <link
            linkend="horizontal_clustering">Pegasus Clustering Guide</link>
            for detailed description. This option determines the total number
            of clusters per level. Jobs are evenly spread across
            clusters.</entry>
          </row>

          <row>
            <entry>pegasus.clusters.size</entry>

            <entry>clusters.size</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Please refer to the <link
            linkend="horizontal_clustering">Pegasus Clustering Guide</link>
            for detailed description. This profile determines the number of
            jobs in each cluster. The number of clusters depends on the total
            number of jobs on the level.</entry>
          </row>

          <row>
            <entry>pegasus.cores</entry>

            <entry>cores</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>The number of cores, associated with the job. This is
            solely used for accounting purposes in the database while
            generating statistics. It corresponds to the multiplier_factor in
            the job_instance table described <link
            linkend="stampede-schema">here</link>.</entry>
          </row>

          <row>
            <entry>pegasus.runtime</entry>

            <entry>runtime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Please refer to the <link
            linkend="runtime_clustering">Pegasus Clustering Guide</link> for
            detailed description. This profile specifies the expected runtime
            of a job.</entry>
          </row>

          <row>
            <entry>pegasus.clusters.maxruntime</entry>

            <entry>clusters.maxruntime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Please refer to the <link
            linkend="runtime_clustering">Pegasus Clustering Guide</link> for
            detailed description. This profile specifies the maximum runtime
            of a job.</entry>
          </row>

          <row>
            <entry>pegasus.job.aggregator</entry>

            <entry>job.aggregator</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Indicates the clustering executable that is used to run the
            clustered job on the remote site.</entry>
          </row>

          <row>
            <entry>pegasus.gridstart</entry>

            <entry>gridstart</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Determines the executable for launching a job. Possible
            values are <emphasis role="bold"><emphasis>Kickstart |
            NoGridStart</emphasis></emphasis> at the moment.</entry>
          </row>

          <row>
            <entry>pegasus.gridstart.path</entry>

            <entry>gridstart.path</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Sets the path to the gridstart . This profile is best set
            in the Site Catalog.</entry>
          </row>

          <row>
            <entry>pegasus.gridstart.arguments</entry>

            <entry>gridstart.arguments</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Sets the arguments with which GridStart is used to launch a
            job on the remote site.</entry>
          </row>

          <row>
            <entry>pegasus.stagein.clusters</entry>

            <entry>stagein.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key determines the maximum number of
            <emphasis>stage-in</emphasis> jobs that are can executed locally
            or remotely per compute site per workflow. This is used to
            configure the <emphasis>Bundle</emphasis> Transfer Refiner, which
            is the Default Refiner used in Pegasus. This profile is best set
            in the Site Catalog or in the Properties file</entry>
          </row>

          <row>
            <entry>pegasus.stagein.local.clusters</entry>

            <entry>stagein.local.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key provides finer grained control in determining the
            number of stage-in jobs that are executed locally and are
            responsible for staging data to a particular remote site. This
            profile is best set in the Site Catalog or in the Properties
            file</entry>
          </row>

          <row>
            <entry>pegasus.stagein.remote.clusters</entry>

            <entry>stagein.remote.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key provides finer grained control in determining the
            number of stage-in jobs that are executed remotely on the remote
            site and are responsible for staging data to it. This profile is
            best set in the Site Catalog or in the Properties file</entry>
          </row>

          <row>
            <entry>pegasus.stageout.clusters</entry>

            <entry>stageout.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key determines the maximum number of
            <emphasis>stage-out</emphasis> jobs that are can executed locally
            or remotely per compute site per workflow. This is used to
            configure the <emphasis>Bundle</emphasis> Transfer Refiner, ,
            which is the Default Refiner used in Pegasus.</entry>
          </row>

          <row>
            <entry>pegasus.stageout.local.clusters</entry>

            <entry>stageout.local.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key provides finer grained control in determining the
            number of stage-out jobs that are executed locally and are
            responsible for staging data from a particular remote site. This
            profile is best set in the Site Catalog or in the Properties
            file</entry>
          </row>

          <row>
            <entry>pegasus.stageout.remote.clusters</entry>

            <entry>stageout.remote.clusters</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key provides finer grained control in determining the
            number of stage-out jobs that are executed remotely on the remote
            site and are responsible for staging data from it. This profile is
            best set in the Site Catalog or in the Properties file</entry>
          </row>

          <row>
            <entry>pegasus.group</entry>

            <entry>group</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Tags a job with an arbitrary group identifier. The group
            site selector makes use of the tag.</entry>
          </row>

          <row>
            <entry>pegasus.change.dir</entry>

            <entry>change.dir</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>If true, tells <emphasis>kickstart</emphasis> to change
            into the remote working directory. Kickstart itself is executed in
            whichever directory the remote scheduling system chose for the
            job.</entry>
          </row>

          <row>
            <entry>pegasus.create.dir</entry>

            <entry>create.dir</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>If true, tells <emphasis>kickstart</emphasis> to create the
            the remote working directory before changing into the remote
            working directory. Kickstart itself is executed in whichever
            directory the remote scheduling system chose for the job.</entry>
          </row>

          <row>
            <entry>pegasus.transfer.proxy</entry>

            <entry>transfer.proxy</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>If true, tells Pegasus to explicitly transfer the proxy for
            transfer jobs to the remote site. This is useful, when you want to
            use a full proxy at the remote end, instead of the limited proxy
            that is transferred by CondorG.</entry>
          </row>

          <row>
            <entry>pegasus.transfer.arguments</entry>

            <entry>transfer.arguments</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Allows the user to specify the arguments with which the
            transfer executable is invoked. However certain options are always
            generated for the transfer executable. The profile applies to the
            separate data transfer nodes added by Pegasus to the executable
            workflow.</entry>
          </row>

          <row>
            <entry>pegasus.transfer.threads</entry>

            <entry>transfer.threads</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the number of threads launched by pegasus-transfer when
            doing the transfers. The profile applies to the separate data
            transfer nodes added by Pegasus to the executable
            workflow.</entry>
          </row>

          <row>
            <entry>pegasus.transfer.lite.arguments</entry>

            <entry>transfer.lite.arguments</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Similar to transfer.arguments, but applies to the transfers
            performed in the PegasusLite jobs in the nonsharedfs data
            configuration.</entry>
          </row>

          <row>
            <entry>pegasus.transfer.lite.threads</entry>

            <entry>transfer.lite.threads</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Similar to threads, but applies to the transfers performed
            in the PegasusLite jobs in the nonsharedfs data
            configuration.</entry>
          </row>

          <row>
            <entry>pegasus.style</entry>

            <entry>style</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>Sets the condor submit file style. If set to globus, submit
            file generated refers to CondorG job submissions. If set to
            condor, submit file generated refers to direct Condor submission
            to the local Condor pool. It applies for glidein, where nodes from
            remote grid sites are glided into the local condor pool. The
            default style that is applied is globus.</entry>
          </row>

          <row>
            <entry>pegasus.pmc_request_memory</entry>

            <entry>pmc_request_memory</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key is used to set the -m option for
            pegasus-mpi-cluster. It specifies the amount of memory in MB that
            a job requires. This profile is usually set in the DAX for each
            job.</entry>
          </row>

          <row>
            <entry>pegasus.pmc_request_cpus</entry>

            <entry>pmc_request_cpus</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key is used to set the -c option for
            pegasus-mpi-cluster. It specifies the number of cpu's that a job
            requires. This profile is usually set in the DAX for each
            job.</entry>
          </row>

          <row>
            <entry>pegasus.pmc_priority</entry>

            <entry>pmc_priority</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>This key is used to set the -p option for
            pegasus-mpi-cluster. It specifies the priority for a job . This
            profile is usually set in the DAX for each job. Negative values
            are allowed for priorities.</entry>
          </row>

          <row>
            <entry>pegasus.pmc_task_arguments</entry>

            <entry>pmc_task_arguments</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>The key is used to pass any extra arguments to the PMC task
            during the planning time. They are added to the very end of the
            argument string constructed for the task in the PMC file. Hence,
            allows for overriding of any argument constructed by the planner
            for any particular task in the PMC job.</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.failuremsg</entry>

            <entry>exitcode.failuremsg</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>The message string that pegasus-exitcode searches for in
            the stdout and stderr of the job to flag failures.</entry>
          </row>

          <row>
            <entry>pegasus.exitcode.successmsg</entry>

            <entry>exitcode.successmsg</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>The message string that pegasus-exitcode searches for in
            the stdout and stderr of the job to determine whether a job logged
            it's success message or not. Note this value is used to check for
            whether a job failed or not i.e if this profile is specified, and
            pegasus-exitcode DOES NOT find the string in the job stdout or
            stderr, the job is flagged as failed. The complete rules for
            determining failure are described in the man page for
            pegasus-exitcode.</entry>
          </row>

          <row>
            <entry>pegasus.checkpoint_time</entry>

            <entry>checkpoint_time</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the expected time in seconds for a job after which it
            should be sent a TERM signal to generate a job checkpoint
            file</entry>
          </row>

          <row>
            <entry>pegasus.maxwalltime</entry>

            <entry>maxwalltime</entry>

            <entry>Transformation Catalog, Site Catalog, DAX, Properties
            File</entry>

            <entry>the maximum walltime in minutes for a single execution of a
            job.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>Properties Introduction</title>

    <para>Properties are primarily used to configure the behavior of the
    Pegasus Workflow Planner at a global level. The properties file is
    actually a java properties file and follows the same conventions as that
    to specify the properties.</para>

    <para>Please note that the values rely on proper capitalization, unless
    explicitly noted otherwise.</para>

    <para>Some properties rely with their default on the value of other
    properties. As a notation, the curly braces refer to the value of the
    named property. For instance, ${pegasus.home} means that the value depends
    on the value of the pegasus.home property plus any noted additions. You
    can use this notation to refer to other properties, though the extent of
    the subsitutions are limited. Usually, you want to refer to a set of the
    standard system properties. Nesting is not allowed. Substitutions will
    only be done once.</para>

    <para>There is a priority to the order of reading and evaluating
    properties. Usually one does not need to worry about the priorities.
    However, it is good to know the details of when which property applies,
    and how one property is able to overwrite another. The following is a
    mutually exclusive list ( highest priority first ) of property file
    locations.</para>

    <para><orderedlist>
        <listitem>
           --conf option to the tools. Almost all of the clients that use properties have a --conf option to specify the property file to pick up. 
        </listitem>

        <listitem>
           submit-dir/pegasus.xxxxxxx.properties file. All tools that work on the submit directory ( i.e after pegasus has planned a workflow) pick up the pegasus.xxxxx.properties file from the submit directory. The location for the pegasus.xxxxxxx.propertiesis picked up from the braindump file. 
        </listitem>

        <listitem>
           The properties defined in the user property file 

          <emphasis>${user.home}/.pegasusrc</emphasis>

           have lowest priority. 
        </listitem>
      </orderedlist></para>

    <para>Commandline properties have the highest priority. These override any
    property loaded from a property file. Each commandline property is
    introduced by a -D argument. Note that these arguments are parsed by the
    shell wrapper, and thus the -D arguments must be the first arguments to
    any command. Commandline properties are useful for debugging
    purposes.</para>

    <para>From Pegasus 3.1 release onwards, support has been dropped for the
    following properties that were used to signify the location of the
    properties file</para>

    <para><itemizedlist>
        <listitem>
           pegasus.properties 
        </listitem>

        <listitem>
           pegasus.user.properties 
        </listitem>
      </itemizedlist></para>

    <para>The following example provides a sensible set of properties to be
    set by the user property file. These properties use mostly non-default
    settings. It is an example only, and will not work for you:</para>

    <para><screen>
pegasus.catalog.replica              File
pegasus.catalog.replica.file         ${pegasus.home}/etc/sample.rc.data
pegasus.catalog.transformation       Text
pegasus.catalog.transformation.file  ${pegasus.home}/etc/sample.tc.text
pegasus.catalog.site.file            ${pegasus.home}/etc/sample.sites.xml
</screen></para>

    <para>If you are in doubt which properties are actually visible, pegasus
    during the planning of the workflow dumps all properties after reading and
    prioritizing in the submit directory in a file with the suffix
    properties.</para>
  </section>

  <section>
    <title>Local Directories Properties</title>

    <para>This section describes the GNU directory structure conventions. GNU
    distinguishes between architecture independent and thus sharable
    directories, and directories with data specific to a platform, and thus
    often local. It also distinguishes between frequently modified data and
    rarely changing data. These two axis form a space of four distinct
    directories.</para>

    <para><table>
        <title> Local Directories Related Properties</title>

        <tgroup cols="5">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Corresponding Profile Key
              </emphasis></entry>

              <entry><emphasis role="bold">Where can it be
              specified</emphasis></entry>

              <entry><emphasis role="bold">Default Value</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>pegasus.home.datadir</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>${pegasus.home}/share</entry>

              <entry>The datadir directory contains broadly visible and
              possibly exported configuration files that rarely change. This
              directory is currently unused.</entry>
            </row>

            <row>
              <entry>pegasus.home.sysconfdir</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>${pegasus.home}/etc</entry>

              <entry>The system configuration directory contains configuration
              files that are specific to the machine or installation, and that
              rarely change. This is the directory where the XML schema
              definition copies are stored, and where the base pool
              configuration file is stored.</entry>
            </row>

            <row>
              <entry>pegasus.home.sharedstatedir</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>${pegasus.home}/com</entry>

              <entry>Frequently changing files that are broadly visible are
              stored in the shared state directory. This is currently
              unused.</entry>
            </row>

            <row>
              <entry>pegasus.home.localstatedir</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>${pegasus.home}/var</entry>

              <entry>Frequently changing files that are specific to a machine
              and/or installation are stored in the local state directory.
              This is currently unused</entry>
            </row>

            <row>
              <entry>pegasus.dir.submit.logs</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>(no default)</entry>

              <entry><para>This property can be used to specify the directory
              where the condor logs for the workflow should go to. By default,
              starting 4.2.1 release, Pegasus will setup the log to be in the
              workflow submit directory. This can create problems, in case
              users submit directories are on NSF.</para><para>This is done to
              ensure that the logs are created in a local directory even
              though the submit directory maybe on NFS</para></entry>
            </row>
          </tbody>
        </tgroup>
      </table></para>
  </section>

  <section>
    <title>Site Directories Properties</title>

    <para>The site directory properties modify the behavior of remotely run
    jobs. In rare occasions, it may also pertain to locally run compute
    jobs.</para>

    <table>
      <title>Site Directories Related Properties</title>

      <tgroup cols="6">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile Key
            </emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Since</emphasis></entry>

            <entry><emphasis role="bold">Default Value</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>pegasus.dir.useTimestamp</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.1</entry>

            <entry>false</entry>

            <entry>While creating the submit directory, Pegasus employs a run
            numbering scheme. Users can use this Boolean property to use a
            timestamp based numbering scheme instead of the runxxxx
            scheme.</entry>
          </row>

          <row>
            <entry>pegasus.dir.exec</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry>This property modifies the remote location work directory
            in which all your jobs will run. If the path is relative then it
            is appended to the work directory (associated with the site), as
            specified in the site catalog. If the path is absolute then it
            overrides the work directory specified in the site
            catalog.</entry>
          </row>

          <row>
            <entry>pegasus.dir.storage.mapper</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>4.3</entry>

            <entry>Flat</entry>

            <entry>This property modifies determines how the output files are
            mapped on the output site storage location. <para/>In order to
            preserve backward compatibility, setting the boolean property
            pegasus.dir.storage.deep results in the Hashed output mapper to be
            loaded, if no output mapper property is specified. <variablelist>
                <varlistentry>
                  <term>Flat</term>

                  <listitem>
                     By default, Pegasus will place the output files in the storage directory specified in the site catalog for the output site. 
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Fixed</term>

                  <listitem>
                     Using this mapper, users can specify an externally accesible url to the storage directory in their properties file. The following property needs to be set. 

                    <screen>
pegasus.dir.storage.mapper.fixed.url  an externally accessible URL to the
storage directory on the output site
e.g. gsiftp://outputs.isi.edu/shared/outputs
</screen>

                     Note: For hierarchal workflows, the above property needs to be set separately for each dax job, if you want the sub workflow outputs to goto a different directory. 
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Hashed</term>

                  <listitem>
                     This mapper results in the creation of a deep directory structure on the output site, while populating the results. The base directory on the remote end is determined from the site catalog. Depending on the number of files being staged to the remote site a Hashed File Structure is created that ensures that only 256 files reside in one directory. To create this directory structure on the storage site, Pegasus relies on the directory creation feature of the Grid FTP server, which appeared in globus 4.0.x 
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Replica</term>

                  <listitem>
                     This mapper determines the path for an output file on the output site by querying an output replica catalog. The output site is one that is passed on the command line. The output replica catalog can be configured by specifiing the properties with the prefix pegasus.dir.storage.replica. By default, a Regex File based backend is assumed unless overridden. For example 

                    <screen>
pegasus.dir.storage.mapper.replica       Regex|File
pegasus.dir.storage.mapper.replica.file  the RC file at the backend to use if using a file based RC
</screen>

                     
                  </listitem>
                </varlistentry>
              </variablelist></entry>
          </row>

          <row>
            <entry>pegasus.dir.storage.deep</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.1</entry>

            <entry>false</entry>

            <entry><para>This Boolean property results in the creation of a
            deep directory structure on the output site, while populating the
            results. The base directory on the remote end is determined from
            the site catalog.</para><para>To this base directory, the relative
            submit directory structure ( $user/$vogroup/$label/runxxxx ) is
            appended.</para><para>$storage = $base +
            $relative_submit_directory</para><para>This is the base directory
            that is passed to the storage mapper.</para><para>Note: To
            preserve backward compatibilty, setting this property results in
            the Hashed mapper to be loaded unless pegasus.dir.storage.mapper
            is explicitly specified. Before 4.3, this property resulted in
            HashedDirectory structure.</para></entry>
          </row>

          <row>
            <entry>pegasus.dir.create.strategy</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.2</entry>

            <entry>Minimal</entry>

            <entry><para>If the <screen>--randomdir</screen> option is given
            to the Planner at runtime, the Pegasus planner adds nodes that
            create the random directories at the remote pool sites, before any
            jobs are actually run. The two modes determine the placement of
            these nodes and their dependencies to the rest of the
            graph.</para><para><variablelist>
                <varlistentry>
                  <term>HourGlass</term>

                  <listitem>
                     It adds a make directory node at the top level of the graph, and all these concat to a single dummy job before branching out to the root nodes of the original/ concrete dag so far. So we introduce a classic X shape at the top of the graph. Hence the name HourGlass. 
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Tentacles</term>

                  <listitem>
                     This option places the jobs creating directories at the top of the graph. However instead of constricting it to an hour glass shape, this mode links the top node to all the relevant nodes for which the create dir job is necessary. It looks as if the node spreads its tentacleas all around. This puts more load on the DAGMan because of the added dependencies but removes the restriction of the plan progressing only when all the create directory jobs have progressed on the remote pools, as is the case in the HourGlass model. 
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Minimal</term>

                  <listitem>
                     The strategy involves in walking the graph in a BFS order, and updating a bit set associated with each job based on the BitSet of the parent jobs. The BitSet indicates whether an edge exists from the create dir job to an ancestor of the node. For a node, the bit set is the union of all the parents BitSets. The BFS traversal ensures that the bitsets are of a node are only updated once the parents have been processed. 
                  </listitem>
                </varlistentry>
              </variablelist></para></entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para/>
  </section>

  <section>
    <title>Schema File Location Properties</title>

    <para>This section defines the location of XML schema files that are used
    to parse the various XML document instances in the PEGASUS. The schema
    backups in the installed file-system permit PEGASUS operations without
    being online.</para>

    <para><table>
        <title>Schema File Location Properties</title>

        <tgroup cols="6">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Corresponding Profile Key
              </emphasis></entry>

              <entry><emphasis role="bold">Where can it be
              specified</emphasis></entry>

              <entry><emphasis role="bold">Since</emphasis></entry>

              <entry><emphasis role="bold">Default Value</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>pegasus.schema.dax</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>2.0</entry>

              <entry>${pegasus.home.sysconfdir}/dax-3.4.xsd</entry>

              <entry>This file is a copy of the XML schema that describes
              abstract DAG files that are the result of the abstract planning
              process, and input into any concrete planning. Providing a copy
              of the schema enables the parser to use the local copy instead
              of reaching out to the Internet, and obtaining the latest
              version from the Pegasus website dynamically.</entry>
            </row>

            <row>
              <entry>pegasus.schema.sc</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>2.0</entry>

              <entry>${pegasus.home.sysconfdir}/sc-4.0.xsd</entry>

              <entry>This file is a copy of the XML schema that describes the
              xml description of the site catalog. Providing a copy of the
              schema enables the parser to use the local copy instead of
              reaching out to the internet, and obtaining the latest version
              from the GriPhyN website dynamically.</entry>
            </row>

            <row>
              <entry>pegasus.schema.ivr</entry>

              <entry>N/A</entry>

              <entry>Properties</entry>

              <entry>2.0</entry>

              <entry>${pegasus.home.sysconfdir}/iv-2.0.xsd</entry>

              <entry>This file is a copy of the XML schema that describes
              invocation record files that are the result of the a grid launch
              in a remote or local site. Providing a copy of the schema
              enables the parser to use the local copy instead of reaching out
              to the Internet, and obtaining the latest version from the
              Pegasus website dynamically.</entry>
            </row>
          </tbody>
        </tgroup>
      </table></para>
  </section>

  <section>
    <title>Database Drivers For All Relational Catalogs</title>

    <para/>

    <table>
      <title>Database Driver Properties</title>

      <tgroup cols="6">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><emphasis role="bold">Corresponding Profile Key
            </emphasis></entry>

            <entry><emphasis role="bold">Where can it be
            specified</emphasis></entry>

            <entry><emphasis role="bold">Since</emphasis></entry>

            <entry><emphasis role="bold">Default Value</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>pegasus.catalog.*.db.driver</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry><para>The database driver class is dynamically loaded, as
            required by the schema. Currently, only MySQL 5.x, PostGreSQL 7.3
            and SQlite are supported. Their respective JDBC3 driver is
            provided as part and parcel of the PEGASUS.</para><para>A user may
            provide their own implementation, derived from
            org.griphyn.vdl.dbdriver.DatabaseDriver, to talk to a database of
            their choice.</para><para>The * in the property name can be
            replaced by a catalog name to apply the property only for that
            catalog. Valid catalog names are</para><para><screen>replica
</screen></para></entry>
          </row>

          <row>
            <entry>pegasus.catalog.*.db.url</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry>Each database has its own string to contact the database on
            a given host, port, and database. Although most driver URLs allow
            to pass arbitrary arguments, please use the
            pegasus.catalog.[catalog-name].db.* keys or pegasus.catalog.*.db.*
            to preload these arguments. <para/>THE URL IS A MANDATORY PROPERTY
            FOR ANY DBMS BACKEND.</entry>
          </row>

          <row>
            <entry>pegasus.catalog.*.db.user</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry><para>In order to access a database, you must provide the
            name of your account on the DBMS. This property is
            database-independent. THIS IS A MANDATORY PROPERTY FOR MANY DBMS
            BACKENDS.</para><para>The * in the property name can be replaced
            by a catalog name to apply the property only for that catalog.
            Valid catalog names are</para><para><screen>replica</screen></para></entry>
          </row>

          <row>
            <entry>pegasus.catalog.*.db.password</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry><para>In order to access a database, you must provide an
            optional password of your account on the DBMS. This property is
            database-independent. THIS IS A MANDATORY PROPERTY, IF YOUR DBMS
            BACKEND ACCOUNT REQUIRES A PASSWORD.</para><para>The * in the
            property name can be replaced by a catalog name to apply the
            property only for that catalog. Valid catalog names are<screen>replica</screen></para></entry>
          </row>

          <row>
            <entry>pegasus.catalog.*.db.*</entry>

            <entry>N/A</entry>

            <entry>Properties</entry>

            <entry>2.0</entry>

            <entry>(no default)</entry>

            <entry><para/><para>Each database has a multitude of options to
            control in fine detail the further behaviour. You may want to
            check the JDBC3 documentation of the JDBC driver for your database
            for details. The keys will be passed as part of the connect
            properties by stripping the "pegasus.catalog.[catalog-name].db."
            prefix from them. The catalog-name can be replaced by the
            following values provenance for Provenance Catalog (PTC), replica
            for Replica Catalog (RC)</para><para>Postgres 7.3 parses the
            following properties: <screen>
pegasus.catalog.*.db.user
pegasus.catalog.*.db.password
pegasus.catalog.*.db.PGHOST
pegasus.catalog.*.db.PGPORT
pegasus.catalog.*.db.charSet
pegasus.catalog.*.db.compatible
</screen></para><para>MySQL 5.0 parses the following
            properties:</para><para><screen>
pegasus.catalog.*.db.user
pegasus.catalog.*.db.password
pegasus.catalog.*.db.databaseName
pegasus.catalog.*.db.serverName
pegasus.catalog.*.db.portNumber
pegasus.catalog.*.db.socketFactory
pegasus.catalog.*.db.strictUpdates
pegasus.catalog.*.db.ignoreNonTxTables
pegasus.catalog.*.db.secondsBeforeRetryMaster
pegasus.catalog.*.db.queriesBeforeRetryMaster
pegasus.catalog.*.db.allowLoadLocalInfile
pegasus.catalog.*.db.continueBatchOnError
pegasus.catalog.*.db.pedantic
pegasus.catalog.*.db.useStreamLengthsInPrepStmts
pegasus.catalog.*.db.useTimezone
pegasus.catalog.*.db.relaxAutoCommit
pegasus.catalog.*.db.paranoid
pegasus.catalog.*.db.autoReconnect
pegasus.catalog.*.db.capitalizeTypeNames
pegasus.catalog.*.db.ultraDevHack
pegasus.catalog.*.db.strictFloatingPoint
pegasus.catalog.*.db.useSSL
pegasus.catalog.*.db.useCompression
pegasus.catalog.*.db.socketTimeout
pegasus.catalog.*.db.maxReconnects
pegasus.catalog.*.db.initialTimeout
pegasus.catalog.*.db.maxRows
pegasus.catalog.*.db.useHostsInPrivileges
pegasus.catalog.*.db.interactiveClient
pegasus.catalog.*.db.useUnicode
pegasus.catalog.*.db.characterEncoding
</screen></para><para>MS SQL Server 2000 support the following properties
            (keys are case-insensitive, e.g. both "user" and "User" are
            valid):</para><para><screen>
pegasus.catalog.*.db.User
pegasus.catalog.*.db.Password
pegasus.catalog.*.db.DatabaseName
pegasus.catalog.*.db.ServerName
pegasus.catalog.*.db.HostProcess
pegasus.catalog.*.db.NetAddress
pegasus.catalog.*.db.PortNumber
pegasus.catalog.*.db.ProgramName
pegasus.catalog.*.db.SendStringParametersAsUnicode
pegasus.catalog.*.db.SelectMethod
</screen></para><para>The * in the property name can be replaced by a catalog
            name to apply the property only for that catalog. Valid catalog
            names are</para><para><screen>replica</screen></para></entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section>
    <title>Catalog Related Properties</title>

    <para/>

    <table>
      <title>Replica Catalog Properties</title>

      <tgroup cols="4">
        <tbody>
          <row>
            <entry><emphasis role="bold">Property Key </emphasis></entry>

            <entry><para><emphasis
            role="bold">Corresponding</emphasis></para><emphasis
            role="bold">Profile Key </emphasis></entry>

            <entry><emphasis role="bold">Metadata</emphasis></entry>

            <entry><emphasis role="bold">Description</emphasis></entry>
          </row>

          <row>
            <entry>pegasus.catalog.replica</entry>

            <entry>N/A</entry>

            <entry><emphasis role="bold">Scope:</emphasis>
            Properties<para/><emphasis role="bold">Since:</emphasis>
            2.0<para/><emphasis role="bold">Default Value:</emphasis>
            File</entry>

            <entry><para>Pegasus queries a Replica Catalog to discover the
            physical filenames (PFN) for input files specified in the DAX.
            Pegasus can interface with various types of Replica Catalogs. This
            property specifies which type of Replica Catalog to use during the
            planning process.</para><para><variablelist>
                <varlistentry>
                  <term>JDBCRC</term>

                  <listitem>
                     In this mode, Pegasus queries a SQL based replica catalog that is accessed via JDBC. The sql schema's for this catalog can be found at $PEGASUS_HOME/sql directory. To use JDBCRC, the user additionally needs to set the following properties 

                    <orderedlist>
                      <listitem>pegasus.catalog.replica.db.driver =
                      mysql</listitem>

                      <listitem>pegasus.catalog.replica.db.url = jdbc url to
                      database e.g
                      jdbc:mysql://database-host.isi.edu/database-name</listitem>

                      <listitem>pegasus.catalog.replica.db.user =
                      database-user</listitem>

                      <listitem>pegasus.catalog.replica.db.password =
                      database-password</listitem>
                    </orderedlist>

                     
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>File</term>

                  <listitem>
                    <para>In this mode, Pegasus queries a file based replica
                    catalog. It is neither transactionally safe, nor advised
                    to use for production purposes in any way. Multiple
                    concurrent instances <emphasis>will clobber</emphasis>
                    each other!. The site attribute should be specified
                    whenever possible. The attribute key for the site
                    attribute is "pool".</para>

                    <para>The LFN may or may not be quoted. If it contains
                    linear whitespace, quotes, backslash or an equality sign,
                    it must be quoted and escaped. Ditto for the PFN. The
                    attribute key-value pairs are separated by an equality
                    sign without any whitespaces. The value may be in quoted.
                    The LFN sentiments about quoting apply.</para>

                    <para><screen>
LFN PFN
LFN PFN a=b [..]
LFN PFN a="b" [..]
"LFN w/LWS" "PFN w/LWS" [..]
</screen></para>

                    <para>To use File, the user additionally needs to specify
                    pegasus.catalog.replica.file property to specify the path
                    to the file based RC.</para>
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Regex</term>

                  <listitem>
                    <para>In this mode, Pegasus queries a file based replica
                    catalog. It is neither transactionally safe, nor advised
                    to use for production purposes in any way. Multiple
                    concurrent access to the File will end up clobbering the
                    contents of the file. The site attribute should be
                    specified whenever possible. The attribute key for the
                    site attribute is "pool".</para>

                    <para>The LFN may or may not be quoted. If it contains
                    linear whitespace, quotes, backslash or an equality sign,
                    it must be quoted and escaped. Ditto for the PFN. The
                    attribute key-value pairs are separated by an equality
                    sign without any whitespaces. The value may be in quoted.
                    The LFN sentiments about quoting apply.</para>

                    <para>In addition users can specifiy regular expression
                    based LFN's. A regular expression based entry should be
                    qualified with an attribute named 'regex'. The attribute
                    regex when set to true identifies the catalog entry as a
                    regular expression based entry. Regular expressions should
                    follow Java regular expression syntax.</para>

                    <para>For example, consider a replica catalog as shown
                    below.</para>

                    <para>Entry 1 refers to an entry which does not use a
                    resular expressions. This entry would only match a file
                    named 'f.a', and nothing else. Entry 2 referes to an entry
                    which uses a regular expression. In this entry f.a referes
                    to files having name as f[any-character]a i.e. faa, f.a,
                    f0a, etc.</para>

                    <para><screen>
f.a file:///Volumes/data/input/f.a pool="local"
f.a file:///Volumes/data/input/f.a pool="local" regex="true"
</screen></para>

                    <para>Regular expression based entries also support
                    substitutions. For example, consider the regular
                    expression based entry shown below.</para>

                    <para>Entry 3 will match files with name alpha.csv,
                    alpha.txt, alpha.xml. In addition, values matched in the
                    expression can be used to generate a PFN.</para>

                    <para>For the entry below if the file being looked up is
                    alpha.csv, the PFN for the file would be generated as
                    file:///Volumes/data/input/csv/alpha.csv. Similary if the
                    file being lookedup was alpha.csv, the PFN for the file
                    would be generated as
                    file:///Volumes/data/input/xml/alpha.xml i.e. The section
                    [0], [1] will be replaced. Section [0] refers to the
                    entire string i.e. alpha.csv. Section [1] refers to a
                    partial match in the input i.e. csv, or txt, or xml. Users
                    can utilize as many sections as they wish.</para>

                    <para><screen>
alpha\.(csv|txt|xml) file:///Volumes/data/input/[1]/[0] pool="local" regex="true"
</screen></para>

                    <para>To use File, the user additionally needs to specify
                    pegasus.catalog.replica.file property to specify the path
                    to the file based RC.</para>
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>Directory</term>

                  <listitem>
                    <para>In this mode, Pegasus does a directory listing on an
                    input directory to create the LFN to PFN mappings. The
                    directory listing is performed recursively, resulting in
                    deep LFN mappings. For example, if an input directory
                    $input is specified with the following structure <screen>
$input
$input/f.1
$input/f.2
$input/D1
$input/D1/f.3
</screen> Pegasus will create the mappings the following LFN PFN mappings
                    internally <screen>
f.1 file://$input/f.1  pool="local"
f.2 file://$input/f.2  pool="local"
D1/f.3 file://$input/D2/f.3 pool="local"
</screen></para>

                    <para>If you don't want the deep lfn's to be created then,
                    you can set pegasus.catalog.replica.directory.flat.lfn to
                    true In that case, for the previous example, Pegasus will
                    create the following LFN PFN mappings internally. <screen>
f.1 file://$input/f.1  pool="local"
f.2 file://$input/f.2  pool="local"
f.3 file://$input/D2/f.3 pool="local"
</screen></para>

                    <para>pegasus-plan has --input-dir option that can be used
                    to specify an input directory.</para>

                    <para>Users can optionally specify additional properties
                    to configure the behvavior of this implementation.</para>

                    <para>pegasus.catalog.replica.directory.site to specify a
                    site attribute other than local to associate with the
                    mappings.</para>

                    <para>pegasus.catalog.replica.directory.url.prefix to
                    associate a URL prefix for the PFN's constructed. If not
                    specified, the URL defaults to file://</para>
                  </listitem>
                </varlistentry>

                <varlistentry>
                  <term>MRC</term>

                  <listitem>
                    <para>In this mode, Pegasus queries multiple replica
                    catalogs to discover the file locations on the grid. To
                    use it set</para>

                    <para><screen>
pegasus.catalog.replica MRC
</screen></para>

                    <para>Each associated replica catalog can be configured
                    via properties as follows.</para>

                    <para>The user associates a variable name referred to as
                    [value] for each of the catalogs, where [value] is any
                    legal identifier (concretely [A-Za-z][_A-Za-z0-9]*) For
                    each associated replica catalogs the user specifies the
                    following properties.</para>

                    <para><screen>
pegasus.catalog.replica.mrc.[value]       specifies the type of replica catalog.
pegasus.catalog.replica.mrc.[value].key   specifies a property name key for a
particular catalog
</screen></para>

                    <para>For example, if a user wants to query two
                    directories at the same time he/she can specify as
                    follows</para>

                    <para><screen>
pegasus.catalog.replica.mrc.directory1 LRC
pegasus.catalog.replica.mrc.directory1.url /input/dir1
pegasus.catalog.replica.mrc.directory2 LRC
pegasus.catalog.replica.mrc.directory2.url /input/dir2
</screen></para>

                    <para>In the above example, directory1, directory2 are any
                    valid identifier names and url is the property key that
                    needed to be specified.</para>
                  </listitem>
                </varlistentry>
              </variablelist></para></entry>
          </row>

          <row>
            <entry>pegasus.catalog.replica.url</entry>

            <entry>N/A</entry>

            <entry><emphasis role="bold">Scope:</emphasis>
            Properties<para/><emphasis role="bold">Since:</emphasis>
            2.0<para/><emphasis role="bold">Default Value:</emphasis> (no
            default)</entry>

            <entry>When using the modern RLS replica catalog, the URI to the
            Replica catalog must be provided to Pegasus to enable it to look
            up filenames. There is no default.</entry>
          </row>

          <row>
            <entry>pegasus.catalog.replica.chunk.size</entry>

            <entry>N/A</entry>

            <entry><emphasis role="bold">Scope:</emphasis>
            Properties<para/><emphasis role="bold">Since:</emphasis>
            2.0<para/><emphasis role="bold">Default Value:</emphasis>
            1000</entry>

            <entry><para>The rc-client takes in an input file containing the
            mappings upon which to work. This property determines, the number
            of lines that are read in at a time, and worked upon at together.
            This allows the various operations like insert, delete happen in
            bulk if the underlying replica implementation supports
            it.</para></entry>
          </row>

          <row>
            <entry>pegasus.catalog.replica.cache.asrc</entry>

            <entry>N/A</entry>

            <entry><emphasis role="bold">Scope:</emphasis>
            Properties<para/><emphasis role="bold">Since:</emphasis>
            2.0<para/><emphasis role="bold">Default Value:</emphasis>
            false</entry>

            <entry><para>This Boolean property determines whether to treat the
            cache file specified as a supplemental replica catalog or not.
            User can specify on the command line to pegasus-plan a comma
            separated list of cache files using the --cache option. By
            default, the LFN-&gt;PFN mappings contained in the cache file are
            treated as cache, i.e if an entry is found in a cache file the
            replica catalog is not queried. This results in only the entry
            specified in the cache file to be available for replica
            selection.</para>Setting this property to true, results in the
            cache files to be treated as supplemental replica catalogs. This
            results in the mappings found in the replica catalog (as specified
            by pegasus.catalog.replica) to be merged with the ones found in
            the cache files. Thus, mappings for a particular LFN found in both
            the cache and the replica catalog are available for replica
            selection.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>
</section>
