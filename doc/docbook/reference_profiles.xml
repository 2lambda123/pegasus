<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<section id="profiles">
  <title>Profiles</title>

  <para>The Pegasus Workflow Mapper uses the concept of profiles to
  encapsulate configurations for various aspects of dealing with the Grid
  infrastructure. Profiles provide an abstract yet uniform interface to
  specify configuration options for various layers from planner/mapper
  behavior to remote environment settings. At various stages during the
  mapping process, profiles may be added associated with the job.</para>

  <para>This document describes various types of profiles, levels of
  priorities for intersecting profiles, and how to specify profiles in
  different contexts.</para>

  <section>
    <title>Profile Structure Heading</title>

    <para>All profiles are triples comprised of a namespace, a name or key,
    and a value. The namespace is a simple identifier. The key has only
    meaning within its namespace, and it&amp;rsquor;s yet another identifier.
    There are no constraints on the contents of a value</para>

    <para>Profiles may be represented with different syntaxes in different
    context. However, each syntax will describe the underlying triple.</para>
  </section>

  <section>
    <title>Profile Namespaces</title>

    <para>Each namespace refers to a different aspect of a job&amp;rsquor;s
    runtime settings. A profile&amp;rsquor;s representation in the concrete
    plan (e.g. the Condor submit files) depends its namespace. Pegasus
    supports the following Namespaces for profiles:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">env</emphasis> permits remote environment
        variables to be set.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">globus</emphasis> sets Globus RSL
        parameters.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">condor</emphasis> sets Condor
        configuration parameters for the submit file.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">dagman</emphasis> introduces Condor DAGMan
        configuration parameters.</para>
      </listitem>

      <listitem>
        <para><emphasis role="bold">pegasus</emphasis> configures the
        behaviour of various planner/mapper components.</para>
      </listitem>
    </itemizedlist>

    <section>
      <title>The env Profile Namespace</title>

      <para>The <emphasis>env</emphasis> namespace allows users to specify
      environment variables of remote jobs. Globus transports the environment
      variables, and ensure that they are set before the job starts.</para>

      <para>The key used in conjunction with an <emphasis>env</emphasis>
      profile denotes the name of the environment variable. The value of the
      profile becomes the value of the remote environment variable.</para>

      <para>Grid jobs usually only set a minimum of environment variables by
      virtue of Globus. You cannot compare the environment variables visible
      from an interactive login with those visible to a grid job. Thus, it
      often becomes necessary to set environment variables like
      LD_LIBRARY_PATH for remote jobs.</para>

      <para>If you use any of the Pegasus worker package tools like transfer
      or the rc-client, it becomes necessary to set PEGASUS_HOME and
      GLOBUS_LOCATION even for jobs that run locally</para>

      <table>
        <title>Table 1: Useful Environment Settings</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Environment
              Variable</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>PEGASUS_HOME</entry>

              <entry>Used by auxillary jobs created by Pegasus both on remote
              site and local site. Should be set usually set in the Site
              Catalog for the sites</entry>
            </row>

            <row>
              <entry>GLOBUS_LOCATION</entry>

              <entry>Used by auxillary jobs created by Pegasus both on remote
              site and local site. Should be set usually set in the Site
              Catalog for the sites</entry>
            </row>

            <row>
              <entry>LD_LIBRARY_PATH</entry>

              <entry>Point this to $GLOBUS_LOCATION/lib, except you cannot use
              the dollar variable. You must use the full path. Applies to
              both, local and remote jobs that use Globus components and
              should be usually set in the site catalog for the sites</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Even though Condor and Globus both permit environment variable
      settings through their profiles, all remote environment variables must
      be set through the means of <emphasis>env</emphasis> profiles.</para>
    </section>

    <section>
      <title>The Globus Profile Namespace</title>

      <para>The <emphasis>globus</emphasis> profile namespace encapsulates
      Globus resource specification language (RSL) instructions. The RSL
      configures settings and behavior of the remote scheduling system. Some
      systems require queue name to schedule jobs, a project name for
      accounting purposes, or a run-time estimate to schedule jobs. The Globus
      RSL addresses all these issues.</para>

      <para>A key in the <emphasis>globus</emphasis> namespace denotes the
      command name of an RLS instruction. The profile value becomes the RSL
      value. Even though Globus RSL is typically shown using parentheses
      around the instruction, the out pair of parentheses is not necessary in
      globus profile specifications</para>

      <para>Table 2 shows some commonly used RSL instructions. For an
      authoritative list of all possible RSL instructions refer to the Globus
      RSL specification.</para>

      <table>
        <title>Table 2: Useful Globus RSL Instructions</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>count</entry>

              <entry>the number of times an executable is started.</entry>
            </row>

            <row>
              <entry>jobtype</entry>

              <entry>specifies how the job manager should start the remote
              job. While Pegasus defaults to single, use mpi when running MPI
              jobs.</entry>
            </row>

            <row>
              <entry>maxcputime</entry>

              <entry>the max cpu time for a single execution of a job.</entry>
            </row>

            <row>
              <entry>maxmemory</entry>

              <entry>the maximum memory in MB required for the job</entry>
            </row>

            <row>
              <entry>maxtime</entry>

              <entry>the maximum time or walltime for a single execution of a
              job.</entry>
            </row>

            <row>
              <entry>maxwalltime</entry>

              <entry>the maximum walltime for a single execution of a
              job.</entry>
            </row>

            <row>
              <entry>minmemory</entry>

              <entry>the minumum amount of memory required for this
              job</entry>
            </row>

            <row>
              <entry>project</entry>

              <entry>associates an account with a job at the remote
              end.</entry>
            </row>

            <row>
              <entry>queue</entry>

              <entry>the remote queue in which the job should be run. Used
              when remote scheduler is PBS that supports queues.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Pegasus prevents the user from specifying certain RSL instructions
      as globus profiles, because they are either automatically generated or
      can be overridden through some different means. For instance, if you
      need to specify remote environment settings, do not use the environment
      key in the globus profiles. Use one or more env profiles instead.</para>

      <table>
        <title>Table 3: RSL Instructions that are not permissible</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Reason for
              Prohibition</emphasis></entry>
            </row>

            <row>
              <entry>arguments</entry>

              <entry>you specify arguments in the arguments section for a job
              in the DAX</entry>
            </row>

            <row>
              <entry>directory</entry>

              <entry>the site catalog and properties determine which directory
              a job will run in.</entry>
            </row>

            <row>
              <entry>environment</entry>

              <entry>use multiple env profiles instead</entry>
            </row>

            <row>
              <entry>executable</entry>

              <entry>the physical executable to be used is specified in the
              transformation catalog and is also dependant on the gridstart
              module being used. If you are launching jobs via kickstart then
              the executable created is the path to kickstart and the
              application executable path appears in the arguments for
              kickstart</entry>
            </row>

            <row>
              <entry>stdin</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>

            <row>
              <entry>stdout</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>

            <row>
              <entry>stderr</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section>
      <title>The Condor Profile Namespace</title>

      <para>The Condor submit file controls every detail how and where a job
      is run. The <emphasis>condor</emphasis> profiles permit to add or
      overwrite instructions in the Condor submit file.</para>

      <para>The <emphasis>condor</emphasis> namespace directly sets commands
      in the Condor submit file for a job the profile applies to. Keys in the
      <emphasis>condor</emphasis> profile namespace denote the name of the
      Condor command. The profile value becomes the command's argument. All
      <emphasis>condor</emphasis> profiles are translated into key=value lines
      in the Condor submit file</para>

      <para>Some of the common condor commands that a user may need to specify
      are listed below. For an authoritative list refer to the online condor
      documentation. Note: Pegasus Workflow Planner/Mapper by default specify
      a lot of condor commands in the submit files depending upon the job, and
      where it is being run.</para>

      <table>
        <title>Table 4: Useful Condor Commands</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>universe</entry>

              <entry>Pegasus defaults to either globus or scheduler universes.
              Set to standard for compute jobs that require standard universe.
              Set to vanilla to run natively in a condor pool, or to run on
              resources grabbed via condor glidein.</entry>
            </row>

            <row>
              <entry>periodic_release</entry>

              <entry>is the number of times job is released back to the queue
              if it goes to HOLD, e.g. due to Globus errors. Pegasus defaults
              to 3.</entry>
            </row>

            <row>
              <entry>periodic_remove</entry>

              <entry>is the number of times a job is allowed to get into HOLD
              state before being removed from the queue. Pegasus defaults to
              3.</entry>
            </row>

            <row>
              <entry>filesystemdomain</entry>

              <entry>Useful for Condor glide-ins to pin a job to a remote
              site.</entry>
            </row>

            <row>
              <entry>stream_error</entry>

              <entry>boolean to turn on the streaming of the stderr of the
              remote job back to submit host.</entry>
            </row>

            <row>
              <entry>stream_output</entry>

              <entry>boolean to turn on the streaming of the stdout of the
              remote job back to submit host.</entry>
            </row>

            <row>
              <entry>priority</entry>

              <entry>integer value to assign the priority of a job. Higher
              value means higher priority. The priorities are only applied for
              vanilla / standard/ local universe jobs. Determines the order in
              which a users own jobs are executed.</entry>
            </row>

            <row>
              <entry>request_cpus</entry>

              <entry>New in Condor 7.8.0 . Number of CPU's a job
              requires.</entry>
            </row>

            <row>
              <entry>request_memory</entry>

              <entry>New in Condor 7.8.0 . Amount of memory a job
              requires.</entry>
            </row>

            <row>
              <entry>request_disk</entry>

              <entry>New in Condor 7.8.0 . Amount of disk a job
              requires.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Other useful condor keys, that advanced users may find useful and
      can be set by profiles are</para>

      <orderedlist>
        <listitem>
          <para>should_transfer_files</para>
        </listitem>

        <listitem>
          <para>transfer_output</para>
        </listitem>

        <listitem>
          <para>transfer_error</para>
        </listitem>

        <listitem>
          <para>whentotransferoutput</para>
        </listitem>

        <listitem>
          <para>requirements</para>
        </listitem>

        <listitem>
          <para>rank</para>
        </listitem>
      </orderedlist>

      <para>Pegasus prevents the user from specifying certain Condor commands
      in condor profiles, because they are automatically generated or can be
      overridden through some different means. Table 5 shows prohibited Condor
      commands.</para>

      <table>
        <title>Table 5: Condor commands prohibited in condor profiles</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Reason for
              Prohibition</emphasis></entry>
            </row>

            <row>
              <entry>arguments</entry>

              <entry>you specify arguments in the arguments section for a job
              in the DAX</entry>
            </row>

            <row>
              <entry>environment</entry>

              <entry>use multiple env profiles instead</entry>
            </row>

            <row>
              <entry>executable</entry>

              <entry>the physical executable to be used is specified in the
              transformation catalog and is also dependant on the gridstart
              module being used. If you are launching jobs via kickstart then
              the executable created is the path to kickstart and the
              application executable path appears in the arguments for
              kickstart</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section>
      <title>The Dagman Profile Namespace</title>

      <para>DAGMan is Condor's workflow manager. While planners generate most
      of DAGMan's configuration, it is possible to tweak certain job-related
      characteristics using dagman profiles. A dagman profile can be used to
      specify a DAGMan pre- or post-script.</para>

      <para>Pre- and post-scripts execute on the submit machine. Both inherit
      the environment settings from the submit host when pegasus-submit-dag or
      pegasus-run is invoked.</para>

      <para>By default, kickstart launches all jobs except standard universe
      and MPI jobs. Kickstart tracks the execution of the job, and returns
      usage statistics for the job. A DAGMan post-script starts the Pegasus
      application exitcode to determine, if the job succeeded. DAGMan receives
      the success indication as exit status from exitcode.</para>

      <para>If you need to run your own post-script, you have to take over the
      job success parsing. The planner is set up to pass the file name of the
      remote job's stdout, usually the output from kickstart, as sole argument
      to the post-script.</para>

      <para>Table 6 shows the keys in the dagman profile domain that are
      understood by Pegasus and can be associated at a per job basis.</para>

      <para><table>
          <title>Table 6: Useful dagman Commands that can be associated at a
          per job basis</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key</emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry>PRE</entry>

                <entry>is the path to the pre-script. DAGMan executes the
                pre-script before it runs the job.</entry>
              </row>

              <row>
                <entry>PRE.ARGUMENTS</entry>

                <entry>are command-line arguments for the pre-script, if
                any.</entry>
              </row>

              <row>
                <entry>POST</entry>

                <entry>is the postscript type/mode that a user wants to
                associate with a job. <orderedlist>
                    <listitem>
                      <para><emphasis role="bold">pegasus-exitcode</emphasis>
                      - pegasus will by default associate this postscript with
                      all jobs launched via kickstart, as long the POST.SCOPE
                      value is not set to NONE.</para>
                    </listitem>

                    <listitem>
                      <para><emphasis role="bold">none</emphasis> -means that
                      no postscript is generated for the jobs. This is useful
                      for MPI jobs that are not launched via kickstart
                      currently.</para>
                    </listitem>

                    <listitem>
                      <para><emphasis role="bold">any legal
                      identifier</emphasis> - Any other identifier of the form
                      ([_A-Za-z][_A-Za-z0-9]*), than one of the 2 reserved
                      keywords above, signifies a user postscript. This allows
                      the user to specify their own postscript for the jobs in
                      the workflow. The path to the postscript can be
                      specified by the dagman profile <emphasis
                      role="bold">POST.PATH.[value</emphasis>] where [value]
                      is this legal identifier specified. The user postscript
                      is passed the name of the .out file of the job as the
                      last argument on the command line.</para>

                      <para>For e.g. if the following dagman profiles were
                      associated with a job X</para>

                      <orderedlist>
                        <listitem>
                          <para>POST with value user_script
                          /bin/user_postscript</para>
                        </listitem>

                        <listitem>
                          <para>POST.PATH.user_script with value
                          /path/to/user/script</para>
                        </listitem>

                        <listitem>
                          <para>POST.ARGUMENTS with value -verbose</para>
                        </listitem>
                      </orderedlist>

                      <para>then the following postscript will be associated
                      with the job X in the .dag file</para>

                      <para>/path/to/user/script -verbose X.out where X.out
                      contains the stdout of the job X</para>
                    </listitem>
                  </orderedlist></entry>
              </row>

              <row>
                <entry>POST.PATH.* ( where * is replaced by the value of the
                POST Profile )</entry>

                <entry>the path to the post script on the submit host.</entry>
              </row>

              <row>
                <entry>POST.ARGUMENTS</entry>

                <entry>are the command line arguments for the post script, if
                any.</entry>
              </row>

              <row>
                <entry>RETRY</entry>

                <entry>is the number of times DAGMan retries the full job
                cycle from pre-script through post-script, if failure was
                detected.</entry>
              </row>

              <row>
                <entry>CATEGORY</entry>

                <entry>the DAGMan category the job belongs to.</entry>
              </row>

              <row>
                <entry>PRIORITY</entry>

                <entry>the priority to apply to a job. DAGMan uses this to
                select what jobs to release when MAXJOBS is enforced for the
                DAG.</entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>

      <para/>

      <para>Table 7 shows the keys in the dagman profile domain that are
      understood by Pegasus and can be used to apply to the whole workflow.
      These are used to control DAGMan's behavior at the workflow level, and
      are recommended to be specified in the properties file.</para>

      <table>
        <title>Table 7: Useful dagman Commands that can be specified in the
        properties file.</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>MAXPRE</entry>

              <entry>sets the maximum number of PRE scripts within the DAG
              that may be running at one time</entry>
            </row>

            <row>
              <entry>MAXPOST</entry>

              <entry>sets the maximum number of PRE scripts within the DAG
              that may be running at one time</entry>
            </row>

            <row>
              <entry>MAXJOBS</entry>

              <entry>sets the maximum number of jobs within the DAG that will
              be submitted to Condor at one time.</entry>
            </row>

            <row>
              <entry>MAXIDLE</entry>

              <entry>sets the maximum number of idle jobs within the DAG that
              will be submitted to Condor at one time.</entry>
            </row>

            <row>
              <entry>[CATEGORY-NAME].MAXJOBS</entry>

              <entry>is the value of maxjobs for a particular category. Users
              can associate different categories to the jobs at a per job
              basis. However, the value of a dagman knob for a category can
              only be specified at a per workflow basis in the
              properties.</entry>
            </row>

            <row>
              <entry>POST.SCOPE</entry>

              <entry>scope for the postscripts. <orderedlist>
                  <listitem>
                    <para>If set to <emphasis role="bold">all</emphasis> ,
                    means each job in the workflow will have a postscript
                    associated with it.</para>
                  </listitem>

                  <listitem>
                    <para>If set to <emphasis role="bold">none</emphasis> ,
                    means no job has postscript associated with it. None mode
                    should be used if you are running vanilla / standard/
                    local universe jobs, as in those cases Condor traps the
                    remote exitcode correctly. None scope is not recommended
                    for grid universe jobs.</para>
                  </listitem>

                  <listitem>
                    <para>If set to <emphasis
                    role="bold">essential</emphasis>, means only essential
                    jobs have post scripts associated with them. At present
                    the only non essential job is the replica registration
                    job.</para>
                  </listitem>
                </orderedlist></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section>
      <title>The Pegasus Profile Namespace</title>

      <para>The <emphasis>pegasus</emphasis> profiles allow users to configure
      extra options to the Pegasus Workflow Planner that can be applied
      selectively to a job or a group of jobs. Site selectors may use a
      sub-set of <emphasis>pegasus</emphasis> profiles for their
      decision-making.</para>

      <para>Table 8 shows some of the useful configuration option Pegasus
      understands.</para>

      <table>
        <title>Table 8: Useful pegasus Profiles.</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry>workdir</entry>

              <entry>Sets the remote initial dir for a Condor-G job. Overrides
              the work directory algorithm that uses the site catalog and
              properties.</entry>
            </row>

            <row>
              <entry>clusters.num</entry>

              <entry>Please refer to the <link
              linkend="horizontal_clustering">Pegasus Clustering Guide</link>
              for detailed description. This option determines the total
              number of clusters per level. Jobs are evenly spread across
              clusters.</entry>
            </row>

            <row>
              <entry>clusters.size</entry>

              <entry>Please refer to the <link
              linkend="horizontal_clustering">Pegasus Clustering Guide</link>
              for detailed description. This profile determines the number of
              jobs in each cluster. The number of clusters depends on the
              total number of jobs on the level.</entry>
            </row>

            <row>
              <entry>cores</entry>

              <entry>The number of cores, associated with the job. This is
              solely used for accounting purposes in the database while
              generating statistics. It corresponds to the multiplier_factor
              in the job_instance table described <link
              linkend="stampede-schema">here</link>.</entry>
            </row>

            <row>
              <entry>runtime</entry>

              <entry>Please refer to the <link
              linkend="runtime_clustering">Pegasus Clustering Guide</link> for
              detailed description. This profile specifies the expected
              runtime of a job.</entry>
            </row>

            <row>
              <entry>clusters.maxruntime</entry>

              <entry>Please refer to the <link
              linkend="runtime_clustering">Pegasus Clustering Guide</link> for
              detailed description. This profile specifies the maximum runtime
              of a job.</entry>
            </row>

            <row>
              <entry>job.aggregator</entry>

              <entry>Indicates the clustering executable that is used to run
              the clustered job on the remote site.</entry>
            </row>

            <row>
              <entry>gridstart</entry>

              <entry>Determines the executable for launching a job. Possible
              values are <emphasis role="bold"><emphasis>Kickstart |
              NoGridStart</emphasis></emphasis> at the moment.</entry>
            </row>

            <row>
              <entry>gridstart.path</entry>

              <entry>Sets the path to the gridstart . This profile is best set
              in the Site Catalog.</entry>
            </row>

            <row>
              <entry>gridstart.arguments</entry>

              <entry>Sets the arguments with which GridStart is used to launch
              a job on the remote site.</entry>
            </row>

            <row>
              <entry>stagein.clusters</entry>

              <entry>This key determines the maximum number of
              <emphasis>stage-in</emphasis> jobs that are can executed locally
              or remotely per compute site per workflow. This is used to
              configure the <emphasis>Bundle</emphasis> Transfer Refiner,
              which is the Default Refiner used in Pegasus. This profile is
              best set in the Site Catalog or in the Properties file</entry>
            </row>

            <row>
              <entry>stagein.local.clusters</entry>

              <entry>This key provides finer grained control in determining
              the number of stage-in jobs that are executed locally and are
              responsible for staging data to a particular remote site. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry>stagein.remote.clusters</entry>

              <entry>This key provides finer grained control in determining
              the number of stage-in jobs that are executed remotely on the
              remote site and are responsible for staging data to it. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry>stageout.clusters</entry>

              <entry>This key determines the maximum number of
              <emphasis>stage-out</emphasis> jobs that are can executed
              locally or remotely per compute site per workflow. This is used
              to configure the <emphasis>Bundle</emphasis> Transfer Refiner, ,
              which is the Default Refiner used in Pegasus.</entry>
            </row>

            <row>
              <entry>stageout.local.clusters</entry>

              <entry>This key provides finer grained control in determining
              the number of stage-out jobs that are executed locally and are
              responsible for staging data from a particular remote site. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry>stageout.remote.clusters</entry>

              <entry>This key provides finer grained control in determining
              the number of stage-out jobs that are executed remotely on the
              remote site and are responsible for staging data from it. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry>group</entry>

              <entry>Tags a job with an arbitrary group identifier. The group
              site selector makes use of the tag.</entry>
            </row>

            <row>
              <entry>change.dir</entry>

              <entry>If true, tells <emphasis>kickstart</emphasis> to change
              into the remote working directory. Kickstart itself is executed
              in whichever directory the remote scheduling system chose for
              the job.</entry>
            </row>

            <row>
              <entry>create.dir</entry>

              <entry>If true, tells <emphasis>kickstart</emphasis> to create
              the the remote working directory before changing into the remote
              working directory. Kickstart itself is executed in whichever
              directory the remote scheduling system chose for the
              job.</entry>
            </row>

            <row>
              <entry>transfer.proxy</entry>

              <entry>If true, tells Pegasus to explicitly transfer the proxy
              for transfer jobs to the remote site. This is useful, when you
              want to use a full proxy at the remote end, instead of the
              limited proxy that is transferred by CondorG.</entry>
            </row>

            <row>
              <entry>transfer.arguments</entry>

              <entry>Allows the user to specify the arguments with which the
              transfer executable is invoked. However certain options are
              always generated for the transfer executable. The profile
              applies to the separate data transfer nodes added by Pegasus to
              the executable workflow.</entry>
            </row>

            <row>
              <entry>transfer.threads</entry>

              <entry>the number of threads launched by pegasus-transfer when
              doing the transfers. The profile applies to the separate data
              transfer nodes added by Pegasus to the executable
              workflow.</entry>
            </row>

            <row>
              <entry>transfer.lite.arguments</entry>

              <entry>Similar to transfer.arguments, but applies to the
              transfers performed in the PegasusLite jobs in the nonsharedfs
              data configuration.</entry>
            </row>

            <row>
              <entry>transfer.lite.threads</entry>

              <entry>Similar to threads, but applies to the transfers
              performed in the PegasusLite jobs in the nonsharedfs data
              configuration.</entry>
            </row>

            <row>
              <entry>style</entry>

              <entry>Sets the condor submit file style. If set to globus,
              submit file generated refers to CondorG job submissions. If set
              to condor, submit file generated refers to direct Condor
              submission to the local Condor pool. It applies for glidein,
              where nodes from remote grid sites are glided into the local
              condor pool. The default style that is applied is
              globus.</entry>
            </row>

            <row>
              <entry>pmc_request_memory</entry>

              <entry>This key is used to set the -m option for
              pegasus-mpi-cluster. It specifies the amount of memory in MB
              that a job requires. This profile is usually set in the DAX for
              each job.</entry>
            </row>

            <row>
              <entry>pmc_request_cpus</entry>

              <entry>This key is used to set the -c option for
              pegasus-mpi-cluster. It specifies the number of cpu's that a job
              requires. This profile is usually set in the DAX for each
              job.</entry>
            </row>

            <row>
              <entry>pmc_priority</entry>

              <entry>This key is used to set the -p option for
              pegasus-mpi-cluster. It specifies the priority for a job . This
              profile is usually set in the DAX for each job. Negative values
              are allowed for priorities.</entry>
            </row>

            <row>
              <entry>pmc_task_arguments</entry>

              <entry>The key is used to pass any extra arguments to the PMC
              task during the planning time. They are added to the very end of
              the argument string constructed for the task in the PMC file.
              Hence, allows for overriding of any argument constructed by the
              planner for any particular task in the PMC job.</entry>
            </row>

            <row>
              <entry>exitcode.failuremsg</entry>

              <entry>The message string that pegasus-exitcode searches for in
              the stdout and stderr of the job to flag failures.</entry>
            </row>

            <row>
              <entry>exitcode.successmsg</entry>

              <entry>The message string that pegasus-exitcode searches for in
              the stdout and stderr of the job to determine whether a job
              logged it's success message or not. Note this value is used to
              check for whether a job failed or not i.e if this profile is
              specified, and pegasus-exitcode DOES NOT find the string in the
              job stdout or stderr, the job is flagged as failed. The complete
              rules for determining failure are described in the man page for
              pegasus-exitcode.</entry>
            </row>

            <row>
              <entry>checkpoint_time</entry>

              <entry>the expected time in seconds for a job after which it
              should be sent a TERM signal to generate a job checkpoint
              file</entry>
            </row>

            <row>
              <entry>maxwalltime</entry>

              <entry>the maximum walltime for a single execution of a
              job.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </section>

  <section>
    <title>Sources for Profiles</title>

    <para>Profiles may enter the job-processing stream at various stages.
    Depending on the requirements and scope a profile is to apply, profiles
    can be associated at</para>

    <itemizedlist>
      <listitem>
        <para>as user property settings.</para>
      </listitem>

      <listitem>
        <para>dax level</para>
      </listitem>

      <listitem>
        <para>in the site catalog</para>
      </listitem>

      <listitem>
        <para>in the transformation catalog</para>
      </listitem>
    </itemizedlist>

    <para>Unfortunately, a different syntax applies to each level and context.
    This section shows the different profile sources and syntaxes. However, at
    the foundation of each profile lies the triple of namespace, key and
    value.</para>

    <section>
      <title>User Profiles in Properties</title>

      <para>Users can specify all profiles in the properties files where the
      property name is <emphasis role="bold">[namespace].key</emphasis> and
      <emphasis role="bold">value</emphasis> of the property is the value of
      the profile.</para>

      <para>Namespace can be env|condor|globus|dagman|pegasus</para>

      <para>Any profile specified as a property applies to the whole workflow
      unless overridden at the DAX level , Site Catalog , Transformation
      Catalog Level.</para>

      <para>Some profiles that they can be set in the properties file are
      listed below</para>

      <programlisting>env.JAVA_HOME "/software/bin/java"

condor.periodic_release 5
condor.periodic_remove  my_own_expression
condor.stream_error true
condor.stream_output fa

globus.maxwalltime  1000
globus.maxtime      900
globus.maxcputime   10
globus.project      test_project
globus.queue        main_queue

dagman.post.arguments --test arguments
dagman.retry  4
dagman.post simple_exitcode
dagman.post.path.simple_exitcode  /bin/exitcode/exitcode.sh
dagman.post.scope all
dagman.maxpre  12
dagman.priority 13

dagman.bigjobs.maxjobs 1


pegasus.clusters.size 5

pegasus.stagein.clusters 3</programlisting>
    </section>

    <section>
      <title>Profiles in DAX</title>

      <para>The user can associate profiles with logical transformations in
      DAX. Environment settings required by a job's application, or a maximum
      estimate on the run-time are examples for profiles at this stage.</para>

      <programlisting>&lt;job id="ID000001" namespace="asdf" name="preprocess" version="1.0"
 level="3" dv-namespace="voeckler" dv-name="top" dv-version="1.0"&gt;
  &lt;argument&gt;-a top -T10  -i &lt;filename file="voeckler.f.a"/&gt;
 -o &lt;filename file="voeckler.f.b1"/&gt;
 &lt;filename file="voeckler.f.b2"/&gt;&lt;/argument&gt;
  <emphasis role="bold">&lt;profile namespace="pegasus" key="walltime"&gt;2&lt;/profile&gt;
  &lt;profile namespace="pegasus" key="diskspace"&gt;1&lt;/profile&gt;</emphasis>
  &amp;mldr;
&lt;/job&gt;
</programlisting>
    </section>

    <section>
      <title>Profiles in Site Catalog</title>

      <para>If it becomes necessary to limit the scope of a profile to a
      single site, these profiles should go into the site catalog. A profile
      in the site catalog applies to all jobs and all application run at the
      site. Commonly, site catalog profiles set environment settings like the
      LD_LIBRARY_PATH, or globus rsl parameters like queue and project
      names.</para>

      <para>Currently, there is no tool to manipulate the site catalog, e.g.
      by adding profiles. Modifying the site catalog requires that you load it
      into your editor.</para>

      <para>The XML version of the site catalog uses the following
      syntax:</para>

      <programlisting><emphasis role="bold">&lt;profile namespace=</emphasis>"<emphasis>namespace</emphasis>" <emphasis
          role="bold">key=</emphasis>"<emphasis>key</emphasis>"&gt;<emphasis>value</emphasis><emphasis
          role="bold">&lt;/profile&gt;</emphasis></programlisting>

      <para>The XML schema requires that profiles are the first children of a
      pool element. If the element ordering is wrong, the XML parser will
      produce errors and warnings:</para>

      <programlisting>&lt;pool handle="isi_condor" gridlaunch="/home/shared/pegasus/bin/kickstart"&gt;
  <emphasis role="bold">&lt;profile namespace="env"
   key="GLOBUS_LOCATION"&gt;/home/shared/globus/&lt;/profile&gt;
  &lt;profile namespace="env"
   key="LD_LIBRARY_PATH" &gt;/home/shared/globus/lib&lt;/profile&gt;</emphasis>
  &lt;lrc url="rls://sukhna.isi.edu" /&gt;
  &amp;mldr;
&lt;/pool&gt;
</programlisting>

      <para>The multi-line textual version of the site catalog uses the
      following syntax:</para>

      <programlisting><emphasis role="bold">profile</emphasis> <emphasis>namespace "key" "value"</emphasis></programlisting>

      <para>The order within the textual pool definition is not important.
      Profiles can appear anywhere:</para>

      <programlisting>pool isi_condor {
  gridlaunch "/home/shared/pegasus/bin/kickstart"
  <emphasis role="bold">profile env "GLOBUS_LOCATION" "/home/shared/globus"
  profile env "LD_LIBRARY_PATH" "/home/shared/globus/lib"</emphasis>
  &amp;mldr;
}
</programlisting>
    </section>

    <section>
      <title>Profiles in Transformation Catalog</title>

      <para>Some profiles require a narrower scope than the site catalog
      offers. Some profiles only apply to certain applications on certain
      sites, or change with each application and site. Transformation-specific
      and CPU-specific environment variables, or job clustering profiles are
      good candidates. Such profiles are best specified in the transformation
      catalog.</para>

      <para>Profiles associate with a physical transformation and site in the
      transformation catalog. The Database version of the transformation
      catalog also permits the convenience of connecting a transformation with
      a profile.</para>

      <para>The Pegasus tc-client tool is a convenient helper to associate
      profiles with transformation catalog entries. As benefit, the user does
      not have to worry about formats of profiles in the various
      transformation catalog instances.</para>

      <programlisting>tc-client -a -P -E -p /home/shared/executables/analyze -t INSTALLED -r isi_condor -e env::GLOBUS_LOCATION=&amp;rdquor;/home/shared/globus&amp;rdquor;</programlisting>

      <para>The above example adds an environment variable GLOBUS_LOCATION to
      the application /home/shared/executables/analyze on site isi_condor. The
      transformation catalog guide has more details on the usage of the
      tc-client.</para>
    </section>
  </section>

  <section>
    <title>Profiles Conflict Resolution</title>

    <para>Irrespective of where the profiles are specified, eventually the
    profiles are associated with jobs. Multiple sources may specify the same
    profile for the same job. For instance, DAX may specify an environment
    variable X. The site catalog may also specify an environment variable X
    for the chosen site. The transformation catalog may specify an environment
    variable X for the chosen site and application. When the job is
    concretized, these three conflicts need to be resolved.</para>

    <para>Pegasus defines a priority ordering of profiles. The higher priority
    takes precedence (overwrites) a profile of a lower priority.</para>

    <orderedlist>
      <listitem>
        <para>Transformation Catalog Profiles</para>
      </listitem>

      <listitem>
        <para>Site Catalog Profiles</para>
      </listitem>

      <listitem>
        <para>DAX Profiles</para>
      </listitem>

      <listitem>
        <para>Profiles in Properties</para>
      </listitem>
    </orderedlist>
  </section>

  <section>
    <title>Details of Profile Handling</title>

    <para>The previous sections omitted some of the finer details for the sake
    of clarity. To understand some of the constraints that Pegasus imposes, it
    is required to look at the way profiles affect jobs.</para>

    <section>
      <title>Details of env Profiles</title>

      <para>Profiles in the env namespace are translated to a
      semicolon-separated list of key-value pairs. The list becomes the
      argument for the Condor environment command in the job's submit
      file.</para>

      <programlisting>######################################################################
# Pegasus WMS  SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
globusrsl = (jobtype=single)
<emphasis role="bold">environment=GLOBUS_LOCATION=/shared/globus;LD_LIBRARY_PATH=/shared/globus/lib;</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

      <para>Condor-G, in turn, will translate the
      <emphasis>environment</emphasis> command for any remote job into Globus
      RSL environment settings, and append them to any existing RSL syntax it
      generates. To permit proper mixing, all <emphasis>environment</emphasis>
      setting should solely use the env profiles, and none of the Condor nor
      Globus environment settings.</para>

      <para>If <emphasis>kickstart</emphasis> starts a job, it may make use of
      environment variables in its executable and arguments setting.</para>
    </section>

    <section>
      <title>Details of globus Profiles</title>

      <para>Profiles in the <emphasis>globus</emphasis> Namespaces are
      translated into a list of paranthesis-enclosed equal-separated key-value
      pairs. The list becomes the value for the Condor
      <emphasis>globusrsl</emphasis> setting in the job's submit file:</para>

      <programlisting>######################################################################
# Pegasus WMS SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
<emphasis role="bold">globusrsl = (jobtype=single)(queue=fast)(project=nvo)</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

      <para>For this reason, Pegasus prohibits the use of the
      <emphasis>globusrsl</emphasis> key in the <emphasis>condor</emphasis>
      profile namespace.</para>
    </section>
  </section>
</section>
