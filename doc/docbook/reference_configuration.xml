<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="configuration">
  <title>Configuration</title>

  <para>Pegasus has configuration options to configure</para>

  <orderedlist>
    <listitem>
      <para>the behavior of an individual job via <emphasis
      role="bold">profiles</emphasis></para>
    </listitem>

    <listitem>
      <para>the behavior of the whole system via <emphasis
      role="bold">properties</emphasis></para>
    </listitem>
  </orderedlist>

  <para>For job level configuration ( such as what environment a job is set
  with ), the Pegasus Workflow Mapper uses the concept of profiles. Profiles
  encapsulate configurations for various aspects of dealing with the Grid
  infrastructure. They provide an abstract yet uniform interface to specify
  configuration options for various layers from planner/mapper behavior to
  remote environment settings. At various stages during the mapping process,
  profiles may be added associated with the job. The system supports five
  diffferent namespaces, with each namespace refers to a different aspect of a
  job's runtime settings. A profile's representation in the executable
  workflow (e.g. the Condor submit files) depends on its namespace. Pegasus
  supports the following Namespaces for profiles:</para>

  <itemizedlist>
    <listitem>
      <para><emphasis role="bold">env</emphasis> permits remote environment
      variables to be set.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">globus</emphasis> sets Globus RSL
      parameters.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">condor</emphasis> sets Condor configuration
      parameters for the submit file.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">dagman</emphasis> introduces Condor DAGMan
      configuration parameters.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">pegasus</emphasis> configures the behaviour
      of various planner/mapper components.</para>
    </listitem>

    <listitem>
      <para><emphasis role="bold">hints</emphasis> allows to override site
      selection behavior of the planner. Can be specified only in the
      DAX.</para>
    </listitem>
  </itemizedlist>

  <para>Properties are primarily used to configure the behavior of the Pegasus
  WMS system at a global level. The properties file is actually a java
  properties file and follows the same conventions as that to specify the
  properties.</para>

  <para>This chapter describes various types of profiles and properties,
  levels of priorities for intersecting profiles, and how to specify profiles
  in different contexts.</para>

  <section>
    <title>Differences between Profiles and Properties</title>

    <para>The main difference between properties and profiles is that profiles
    eventually get associated at a per job level in the workflow. On the other
    hand, properties are a way of configuring and controlling the behavior of
    the whole system. While all profiles can be specified in the properties
    file, not all properties can be used as profiles. This section lists out
    the properties supported by Pegasus and if any can be used as a profile,
    it is clearly indicated.</para>
  </section>

  <section id="profiles">
    <title>Profiles</title>

    <para/>

    <section>
      <title>Profile Structure Heading</title>

      <para>All profiles are triples comprised of a namespace, a name or key,
      and a value. The namespace is a simple identifier. The key has only
      meaning within its namespace, and it's yet another identifier. There are
      no constraints on the contents of a value</para>

      <para>Profiles may be represented with different syntaxes in different
      context. However, each syntax will describe the underlying
      triple.</para>
    </section>

    <section>
      <title>Sources for Profiles</title>

      <para>Profiles may enter the job-processing stream at various stages.
      Depending on the requirements and scope a profile is to apply, profiles
      can be associated at</para>

      <itemizedlist>
        <listitem>
          <para>as user property settings.</para>
        </listitem>

        <listitem>
          <para>dax level</para>
        </listitem>

        <listitem>
          <para>in the site catalog</para>
        </listitem>

        <listitem>
          <para>in the transformation catalog</para>
        </listitem>
      </itemizedlist>

      <para>Unfortunately, a different syntax applies to each level and
      context. This section shows the different profile sources and syntaxes.
      However, at the foundation of each profile lies the triple of namespace,
      key and value.</para>

      <section>
        <title>User Profiles in Properties</title>

        <para>Users can specify all profiles in the properties files where the
        property name is <emphasis role="bold">[namespace].key</emphasis> and
        <emphasis role="bold">value</emphasis> of the property is the value of
        the profile.</para>

        <para>Namespace can be env|condor|globus|dagman|pegasus</para>

        <para>Any profile specified as a property applies to the whole
        workflow i.e (all jobs in the workflow) unless overridden at the DAX
        level , Site Catalog , Transformation Catalog Level.</para>

        <para>Some profiles that they can be set in the properties file are
        listed below</para>

        <programlisting>env.JAVA_HOME "/software/bin/java"

condor.periodic_release 5
condor.periodic_remove  my_own_expression
condor.stream_error true
condor.stream_output fa

globus.maxwalltime  1000
globus.maxtime      900
globus.maxcputime   10
globus.project      test_project
globus.queue        main_queue

dagman.post.arguments --test arguments
dagman.retry  4
dagman.post simple_exitcode
dagman.post.path.simple_exitcode  /bin/exitcode/exitcode.sh
dagman.post.scope all
dagman.maxpre  12
dagman.priority 13

dagman.bigjobs.maxjobs 1


pegasus.clusters.size 5

pegasus.stagein.clusters 3</programlisting>
      </section>

      <section>
        <title>Profiles in DAX</title>

        <para>The user can associate profiles with logical transformations in
        DAX. Environment settings required by a job's application, or a
        maximum estimate on the run-time are examples for profiles at this
        stage.</para>

        <programlisting>&lt;job id="ID000001" namespace="asdf" name="preprocess" version="1.0"
 level="3" dv-namespace="voeckler" dv-name="top" dv-version="1.0"&gt;
  &lt;argument&gt;-a top -T10  -i &lt;filename file="voeckler.f.a"/&gt;
 -o &lt;filename file="voeckler.f.b1"/&gt;
 &lt;filename file="voeckler.f.b2"/&gt;&lt;/argument&gt;
  <emphasis role="bold">&lt;profile namespace="pegasus" key="walltime"&gt;2&lt;/profile&gt;
  &lt;profile namespace="pegasus" key="diskspace"&gt;1&lt;/profile&gt;</emphasis>
  &amp;mldr;
&lt;/job&gt;
</programlisting>
      </section>

      <section>
        <title>Profiles in Site Catalog</title>

        <para>If it becomes necessary to limit the scope of a profile to a
        single site, these profiles should go into the site catalog. A profile
        in the site catalog applies to all jobs and all application run at the
        site. Commonly, site catalog profiles set environment settings like
        the LD_LIBRARY_PATH, or globus rsl parameters like queue and project
        names.</para>

        <para>Currently, there is no tool to manipulate the site catalog, e.g.
        by adding profiles. Modifying the site catalog requires that you load
        it into your editor.</para>

        <para>The XML version of the site catalog uses the following
        syntax:</para>

        <programlisting><emphasis role="bold">&lt;profile namespace=</emphasis>"<emphasis>namespace</emphasis>" <emphasis
            role="bold">key=</emphasis>"<emphasis>key</emphasis>"&gt;<emphasis>value</emphasis><emphasis
            role="bold">&lt;/profile&gt;</emphasis></programlisting>

        <programlisting>&lt;site  handle="CCG" arch="x86_64" os="LINUX"&gt;
     &lt;grid  type="gt5" contact="obelix.isi.edu/jobmanager-fork" scheduler="Fork" jobtype="auxillary"/&gt;
        
     &lt;directory type="shared-scratch" path="/shared-scratch"&gt;
            &lt;file-server operation="all" url="gsiftp://headnode.isi.edu/shared-scratch"/&gt;
     &lt;/directory&gt;
     &lt;directory type="local-storage" path="/local-storage"&gt;
            &lt;file-server operation="all" url="gsiftp://headnode.isi.edu/local-storage"/&gt;
     &lt;/directory&gt; 
     &lt;profile namespace="pegasus" key="clusters.num"&gt;1&lt;/profile&gt;
     &lt;profile namespace="env" key="PEGASUS_HOME"&gt;/usr&lt;/profile&gt;        
&lt;/site&gt;
</programlisting>
      </section>

      <section>
        <title>Profiles in Transformation Catalog</title>

        <para>Some profiles require a narrower scope than the site catalog
        offers. Some profiles only apply to certain applications on certain
        sites, or change with each application and site.
        Transformation-specific and CPU-specific environment variables, or job
        clustering profiles are good candidates. Such profiles are best
        specified in the transformation catalog.</para>

        <para>Profiles associate with a physical transformation and site in
        the transformation catalog. The Database version of the transformation
        catalog also permits the convenience of connecting a transformation
        with a profile.</para>

        <para>The Pegasus tc-client tool is a convenient helper to associate
        profiles with transformation catalog entries. As benefit, the user
        does not have to worry about formats of profiles in the various
        transformation catalog instances.</para>

        <programlisting>tc-client -a -P -E -p /home/shared/executables/analyze -t INSTALLED -r isi_condor -e env::GLOBUS_LOCATION=&amp;rdquor;/home/shared/globus&amp;rdquor;</programlisting>

        <para>The above example adds an environment variable GLOBUS_LOCATION
        to the application /home/shared/executables/analyze on site
        isi_condor. The transformation catalog guide has more details on the
        usage of the tc-client.</para>

        <programlisting>tr example::keg:1.0 { 

#specify profiles that apply for all the sites for the transformation 
#in each site entry the profile can be overriden 

  profile env "APP_HOME" "/tmp/myscratch"
  profile env "JAVA_HOME" "/opt/java/1.6"

  site isi {
    <emphasis role="bold">profile env "HELLo" "WORLD"
    profile condor "FOO" "bar"
    profile env "JAVA_HOME" "/bin/java.1.6"</emphasis>
    pfn "/path/to/keg"
    arch "x86"
    os "linux"
    osrelease "fc"
    osversion "4"
    type "INSTALLED"
  }

  site wind {
    profile env "CPATH" "/usr/cpath"
    profile condor "universe" "condor"
    pfn "file:///path/to/keg"
    arch "x86"
    os "linux"
    osrelease "fc"
    osversion "4"
    type "STAGEABLE"
  }
}</programlisting>

        <para>Most of the users prefer to edit the transformation catalog file
        directly in the editor.</para>
      </section>
    </section>

    <section>
      <title>Profiles Conflict Resolution</title>

      <para>Irrespective of where the profiles are specified, eventually the
      profiles are associated with jobs. Multiple sources may specify the same
      profile for the same job. For instance, DAX may specify an environment
      variable X. The site catalog may also specify an environment variable X
      for the chosen site. The transformation catalog may specify an
      environment variable X for the chosen site and application. When the job
      is concretized, these three conflicts need to be resolved.</para>

      <para>Pegasus defines a priority ordering of profiles. The higher
      priority takes precedence (overwrites) a profile of a lower
      priority.</para>

      <orderedlist>
        <listitem>
          <para>Transformation Catalog Profiles</para>
        </listitem>

        <listitem>
          <para>Site Catalog Profiles</para>
        </listitem>

        <listitem>
          <para>DAX Profiles</para>
        </listitem>

        <listitem>
          <para>Profiles in Properties</para>
        </listitem>
      </orderedlist>
    </section>

    <section>
      <title>Details of Profile Handling</title>

      <para>The previous sections omitted some of the finer details for the
      sake of clarity. To understand some of the constraints that Pegasus
      imposes, it is required to look at the way profiles affect jobs.</para>

      <section>
        <title>Details of env Profiles</title>

        <para>Profiles in the env namespace are translated to a
        semicolon-separated list of key-value pairs. The list becomes the
        argument for the Condor environment command in the job's submit
        file.</para>

        <programlisting>######################################################################
# Pegasus WMS  SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
globusrsl = (jobtype=single)
<emphasis role="bold">environment=GLOBUS_LOCATION=/shared/globus;LD_LIBRARY_PATH=/shared/globus/lib;</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

        <para>Condor-G, in turn, will translate the
        <emphasis>environment</emphasis> command for any remote job into
        Globus RSL environment settings, and append them to any existing RSL
        syntax it generates. To permit proper mixing, all
        <emphasis>environment</emphasis> setting should solely use the env
        profiles, and none of the Condor nor Globus environment
        settings.</para>

        <para>If <emphasis>kickstart</emphasis> starts a job, it may make use
        of environment variables in its executable and arguments
        setting.</para>
      </section>

      <section>
        <title>Details of globus Profiles</title>

        <para>Profiles in the <emphasis>globus</emphasis> Namespaces are
        translated into a list of paranthesis-enclosed equal-separated
        key-value pairs. The list becomes the value for the Condor
        <emphasis>globusrsl</emphasis> setting in the job's submit
        file:</para>

        <programlisting>######################################################################
# Pegasus WMS SUBMIT FILE GENERATOR
# DAG : black-diamond, Index = 0, Count = 1
# SUBMIT FILE NAME : findrange_ID000002.sub
######################################################################
<emphasis role="bold">globusrsl = (jobtype=single)(queue=fast)(project=nvo)</emphasis>
executable = /shared/software/linux/pegasus/default/bin/kickstart
globusscheduler = columbus.isi.edu/jobmanager-condor
remote_initialdir = /shared/CONDOR/workdir/isi_hourglass
universe = globus
&amp;mldr;
queue
######################################################################
# END OF SUBMIT FILE
</programlisting>

        <para>For this reason, Pegasus prohibits the use of the
        <emphasis>globusrsl</emphasis> key in the <emphasis>condor</emphasis>
        profile namespace.</para>
      </section>
    </section>

    <section id="env_profiles">
      <title>The Env Profile Namespace</title>

      <para>The <emphasis>env</emphasis> namespace allows users to specify
      environment variables of remote jobs. Globus transports the environment
      variables, and ensure that they are set before the job starts.</para>

      <para>The key used in conjunction with an <emphasis>env</emphasis>
      profile denotes the name of the environment variable. The value of the
      profile becomes the value of the remote environment variable.</para>

      <para>Grid jobs usually only set a minimum of environment variables by
      virtue of Globus. You cannot compare the environment variables visible
      from an interactive login with those visible to a grid job. Thus, it
      often becomes necessary to set environment variables like
      LD_LIBRARY_PATH for remote jobs.</para>

      <para>If you use any of the Pegasus worker package tools like transfer
      or the rc-client, it becomes necessary to set PEGASUS_HOME and
      GLOBUS_LOCATION even for jobs that run locally</para>

      <table>
        <title>Useful Environment Settings</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>env.PEGASUS_HOME<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>PEGASUS_HOME<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
</literallayout></entry>

              <entry>Used by auxillary jobs created by Pegasus both on remote
              site and local site. Should be set usually set in the Site
              Catalog for the sites</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>env.GLOBUS_LOCATION<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>GLOBUS_LOCATION<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Used by auxillary jobs created by Pegasus both on remote
              site and local site. Should be set usually set in the Site
              Catalog for the sites</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>env.LD_LIBRARY_PATH<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>LD_LIBRARY_PATH<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Point this to $GLOBUS_LOCATION/lib, except you cannot use
              the dollar variable. You must use the full path. Applies to
              both, local and remote jobs that use Globus components and
              should be usually set in the site catalog for the sites</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Even though Condor and Globus both permit environment variable
      settings through their profiles, all remote environment variables must
      be set through the means of <emphasis>env</emphasis> profiles.</para>
    </section>

    <section>
      <title id="globus_profiles">The Globus Profile Namespace</title>

      <para>The <emphasis>globus</emphasis> profile namespace encapsulates
      Globus resource specification language (RSL) instructions. The RSL
      configures settings and behavior of the remote scheduling system. Some
      systems require queue name to schedule jobs, a project name for
      accounting purposes, or a run-time estimate to schedule jobs. The Globus
      RSL addresses all these issues.</para>

      <para>A key in the <emphasis>globus</emphasis> namespace denotes the
      command name of an RSL instruction. The profile value becomes the RSL
      value. Even though Globus RSL is typically shown using parentheses
      around the instruction, the out pair of parentheses is not necessary in
      globus profile specifications</para>

      <para>The table below shows some commonly used RSL instructions. For an
      authoritative list of all possible RSL instructions refer to the Globus
      RSL specification.</para>

      <table>
        <title>Useful Globus RSL Instructions</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.count<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>count<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the number of times an executable is started.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.jobtype<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>jobtype<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>specifies how the job manager should start the remote
              job. While Pegasus defaults to single, use mpi when running MPI
              jobs.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.maxcputime<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>maxcputime<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the max CPU time in minutes for a single execution of a
              job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.maxmemory<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>maxmemory<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the maximum memory in MB required for the job</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.maxtime<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>maxtime<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the maximum time or walltime in minutes for a single
              execution of a job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.maxwalltime<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>maxwalltime<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the maximum walltime in minutes for a single execution of
              a job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.minmemory<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>minmemory<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the minumum amount of memory required for this
              job</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.project<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>project<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>associates an account with a job at the remote
              end.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>globus.queue<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>queue<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>the remote queue in which the job should be run. Used
              when remote scheduler is PBS that supports queues.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Pegasus prevents the user from specifying certain RSL instructions
      as globus profiles, because they are either automatically generated or
      can be overridden through some different means. For instance, if you
      need to specify remote environment settings, do not use the environment
      key in the globus profiles. Use one or more env profiles instead.</para>

      <table>
        <title>RSL Instructions that are not permissible</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Reason for
              Prohibition</emphasis></entry>
            </row>

            <row>
              <entry>arguments</entry>

              <entry>you specify arguments in the arguments section for a job
              in the DAX</entry>
            </row>

            <row>
              <entry>directory</entry>

              <entry>the site catalog and properties determine which directory
              a job will run in.</entry>
            </row>

            <row>
              <entry>environment</entry>

              <entry>use multiple env profiles instead</entry>
            </row>

            <row>
              <entry>executable</entry>

              <entry>the physical executable to be used is specified in the
              transformation catalog and is also dependant on the gridstart
              module being used. If you are launching jobs via kickstart then
              the executable created is the path to kickstart and the
              application executable path appears in the arguments for
              kickstart</entry>
            </row>

            <row>
              <entry>stdin</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>

            <row>
              <entry>stdout</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>

            <row>
              <entry>stderr</entry>

              <entry>you specify in the DAX for the job</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section id="condor_profiles">
      <title>The Condor Profile Namespace</title>

      <para>The Condor submit file controls every detail how and where a job
      is run. The <emphasis>condor</emphasis> profiles permit to add or
      overwrite instructions in the Condor submit file.</para>

      <para>The <emphasis>condor</emphasis> namespace directly sets commands
      in the Condor submit file for a job the profile applies to. Keys in the
      <emphasis>condor</emphasis> profile namespace denote the name of the
      Condor command. The profile value becomes the command's argument. All
      <emphasis>condor</emphasis> profiles are translated into key=value lines
      in the Condor submit file</para>

      <para>Some of the common condor commands that a user may need to specify
      are listed below. For an authoritative list refer to the online condor
      documentation. Note: Pegasus Workflow Planner/Mapper by default specify
      a lot of condor commands in the submit files depending upon the job, and
      where it is being run.</para>

      <table>
        <title>Useful Condor Commands</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.universe<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>universe<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Pegasus defaults to either globus or scheduler universes.
              Set to standard for compute jobs that require standard universe.
              Set to vanilla to run natively in a condor pool, or to run on
              resources grabbed via condor glidein.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.periodic_release<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>periodic_release<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>is the number of times job is released back to the queue
              if it goes to HOLD, e.g. due to Globus errors. Pegasus defaults
              to 3.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.periodic_remove<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>periodic_remove<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>is the number of times a job is allowed to get into HOLD
              state before being removed from the queue. Pegasus defaults to
              3.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.filesystemdomain<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>filesystemdomain<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Useful for Condor glide-ins to pin a job to a remote
              site.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.stream_error<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stream_error <emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>boolean to turn on the streaming of the stderr of the
              remote job back to submit host.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.stream_output<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stream_output<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>boolean to turn on the streaming of the stdout of the
              remote job back to submit host.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.priority<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>priority<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>integer value to assign the priority of a job. Higher
              value means higher priority. The priorities are only applied for
              vanilla / standard/ local universe jobs. Determines the order in
              which a users own jobs are executed.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.request_cpus<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>request_cpus<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>New in Condor 7.8.0 . Number of CPU's a job
              requires.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.request_gpus<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>request_cpus<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Number of GPU's a job requires.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.request_memory<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>request_memory<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>New in Condor 7.8.0 . Amount of memory a job
              requires.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>condor.request_disk<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>request_disk<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>New in Condor 7.8.0 . Amount of disk a job
              requires.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para>Other useful condor keys, that advanced users may find useful and
      can be set by profiles are</para>

      <orderedlist>
        <listitem>
          <para>should_transfer_files</para>
        </listitem>

        <listitem>
          <para>transfer_output</para>
        </listitem>

        <listitem>
          <para>transfer_error</para>
        </listitem>

        <listitem>
          <para>whentotransferoutput</para>
        </listitem>

        <listitem>
          <para>requirements</para>
        </listitem>

        <listitem>
          <para>rank</para>
        </listitem>
      </orderedlist>

      <para>Pegasus prevents the user from specifying certain Condor commands
      in condor profiles, because they are automatically generated or can be
      overridden through some different means. The table below shows
      prohibited Condor commands.</para>

      <table>
        <title>Condor commands prohibited in condor profiles</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key</emphasis></entry>

              <entry><emphasis role="bold">Reason for
              Prohibition</emphasis></entry>
            </row>

            <row>
              <entry>arguments</entry>

              <entry>you specify arguments in the arguments section for a job
              in the DAX</entry>
            </row>

            <row>
              <entry>environment</entry>

              <entry>use multiple env profiles instead</entry>
            </row>

            <row>
              <entry>executable</entry>

              <entry>the physical executable to be used is specified in the
              transformation catalog and is also dependant on the gridstart
              module being used. If you are launching jobs via kickstart then
              the executable created is the path to kickstart and the
              application executable path appears in the arguments for
              kickstart</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section id="dagman_profiles">
      <title>The Dagman Profile Namespace</title>

      <para>DAGMan is Condor's workflow manager. While planners generate most
      of DAGMan's configuration, it is possible to tweak certain job-related
      characteristics using dagman profiles. A dagman profile can be used to
      specify a DAGMan pre- or post-script.</para>

      <para>Pre- and post-scripts execute on the submit machine. Both inherit
      the environment settings from the submit host when pegasus-submit-dag or
      pegasus-run is invoked.</para>

      <para>By default, kickstart launches all jobs except standard universe
      and MPI jobs. Kickstart tracks the execution of the job, and returns
      usage statistics for the job. A DAGMan post-script starts the Pegasus
      application exitcode to determine, if the job succeeded. DAGMan receives
      the success indication as exit status from exitcode.</para>

      <para>If you need to run your own post-script, you have to take over the
      job success parsing. The planner is set up to pass the file name of the
      remote job's stdout, usually the output from kickstart, as sole argument
      to the post-script.</para>

      <para>The table below shows the keys in the dagman profile domain that
      are understood by Pegasus and can be associated at a per job
      basis.</para>

      <para><table>
          <title>Useful dagman Commands that can be associated at a per job
          basis</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Property Key </emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.pre<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>PRE<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>is the path to the pre-script. DAGMan executes the
                pre-script before it runs the job.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.pre.arguments<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>PRE.ARGUMENTS<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>are command-line arguments for the pre-script, if
                any.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.post<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>POST<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>is the postscript type/mode that a user wants to
                associate with a job. <orderedlist>
                    <listitem>
                      <para><emphasis role="bold">pegasus-exitcode</emphasis>
                      - pegasus will by default associate this postscript with
                      all jobs launched via kickstart, as long the POST.SCOPE
                      value is not set to NONE.</para>
                    </listitem>

                    <listitem>
                      <para><emphasis role="bold">none</emphasis> -means that
                      no postscript is generated for the jobs. This is useful
                      for MPI jobs that are not launched via kickstart
                      currently.</para>
                    </listitem>

                    <listitem>
                      <para><emphasis role="bold">any legal
                      identifier</emphasis> - Any other identifier of the form
                      ([_A-Za-z][_A-Za-z0-9]*), than one of the 2 reserved
                      keywords above, signifies a user postscript. This allows
                      the user to specify their own postscript for the jobs in
                      the workflow. The path to the postscript can be
                      specified by the dagman profile <emphasis
                      role="bold">POST.PATH.[value</emphasis>] where [value]
                      is this legal identifier specified. The user postscript
                      is passed the name of the .out file of the job as the
                      last argument on the command line.</para>

                      <para>For e.g. if the following dagman profiles were
                      associated with a job X</para>

                      <orderedlist>
                        <listitem>
                          <para>POST with value user_script
                          /bin/user_postscript</para>
                        </listitem>

                        <listitem>
                          <para>POST.PATH.user_script with value
                          /path/to/user/script</para>
                        </listitem>

                        <listitem>
                          <para>POST.ARGUMENTS with value -verbose</para>
                        </listitem>
                      </orderedlist>

                      <para>then the following postscript will be associated
                      with the job X in the .dag file</para>

                      <para>/path/to/user/script -verbose X.out where X.out
                      contains the stdout of the job X</para>
                    </listitem>
                  </orderedlist></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.post.path.[value of dagman.post]<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>post.path.[value of dagman.post]<emphasis
                      role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>the path to the post script on the submit host.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.post.arguments<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>POST.ARGUMENTS<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>are the command line arguments for the post script, if
                any.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.retry<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>RETRY<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer
<emphasis role="bold">Default     :</emphasis> 1</literallayout></entry>

                <entry>is the number of times DAGMan retries the full job
                cycle from pre-script through post-script, if failure was
                detected.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.category<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>CATEGORY<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>the DAGMan category the job belongs to.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.priority<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>PRIORITY<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

                <entry>the priority to apply to a job. DAGMan uses this to
                select what jobs to release when MAXJOBS is enforced for the
                DAG.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>dagman.abort-dag-on<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>ABORT-DAG-ON 
<emphasis role="bold">Scope       :</emphasis> TC, DAX,
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

                <entry>The ABORT-DAG-ON key word provides a way to abort the
                entire DAG if a given node returns a specific exit code
                (AbortExitValue). The syntax for the value of the key is
                AbortExitValue [RETURN DAGReturnValue] . When a DAG aborts, by
                default it exits with the node return value that caused the
                abort. This can be changed by using the optional RETURN key
                word along with specifying the desired DAGReturnValue</entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>

      <para/>

      <para>The table below shows the keys in the dagman profile domain that
      are understood by Pegasus and can be used to apply to the whole
      workflow. These are used to control DAGMan's behavior at the workflow
      level, and are recommended to be specified in the properties
      file.</para>

      <table id="dagman_throttling_profiles">
        <title>Useful dagman Commands that can be specified in the properties
        file.</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.maxpre<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>MAXPRE<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>sets the maximum number of PRE scripts within the DAG
              that may be running at one time</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.maxpost<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>MAXPOST<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>sets the maximum number of POST scripts within the DAG
              that may be running at one time</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.maxjobs<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>MAXJOBS<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>sets the maximum number of jobs within the DAG that will
              be submitted to Condor at one time.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.maxidle<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>MAXIDLE<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Sets the maximum number of idle jobs allowed before
              HTCondor DAGMan stops submitting more jobs. Once idle jobs start
              to run, HTCondor DAGMan will resume submitting jobs. If the
              option is omitted, the number of idle jobs is unlimited.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.[CATEGORY-NAME].maxjobs<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>[CATEGORY-NAME].MAXJOBS<emphasis
                    role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>is the value of maxjobs for a particular category. Users
              can associate different categories to the jobs at a per job
              basis. However, the value of a dagman knob for a category can
              only be specified at a per workflow basis in the
              properties.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>dagman.post.scope<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>POST.SCOPE<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>scope for the postscripts. <orderedlist>
                  <listitem>
                    <para>If set to <emphasis role="bold">all</emphasis> ,
                    means each job in the workflow will have a postscript
                    associated with it.</para>
                  </listitem>

                  <listitem>
                    <para>If set to <emphasis role="bold">none</emphasis> ,
                    means no job has postscript associated with it. None mode
                    should be used if you are running vanilla / standard/
                    local universe jobs, as in those cases Condor traps the
                    remote exitcode correctly. None scope is not recommended
                    for grid universe jobs.</para>
                  </listitem>

                  <listitem>
                    <para>If set to <emphasis
                    role="bold">essential</emphasis>, means only essential
                    jobs have post scripts associated with them. At present
                    the only non essential job is the replica registration
                    job.</para>
                  </listitem>
                </orderedlist></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section id="pegasus_profiles">
      <title>The Pegasus Profile Namespace</title>

      <para>The <emphasis>pegasus</emphasis> profiles allow users to configure
      extra options to the Pegasus Workflow Planner that can be applied
      selectively to a job or a group of jobs. Site selectors may use a
      sub-set of <emphasis>pegasus</emphasis> profiles for their
      decision-making.</para>

      <para>The table below shows some of the useful configuration option
      Pegasus understands.</para>

      <table>
        <title>Useful pegasus Profiles.</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusters.num<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>clusters.num<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 3.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>Please refer to the <link
              linkend="horizontal_clustering">Pegasus Clustering Guide</link>
              for detailed description. This option determines the total
              number of clusters per level. Jobs are evenly spread across
              clusters.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusters.size<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>clusters.size<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 3.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>Please refer to the <link
              linkend="horizontal_clustering">Pegasus Clustering Guide</link>
              for detailed description. This profile determines the number of
              jobs in each cluster. The number of clusters depends on the
              total number of jobs on the level.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.job.aggregator<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>job.aggregator<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>Indicates the clustering executable that is used to run
              the clustered job on the remote site.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.gridstart<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>gridstart<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Determines the executable for launching a job. This
              covers both tasks ( jobs specified by the user in the DAX) and
              additional jobs added by Pegasus during the planning operation.
              Possible values are <emphasis role="bold"><emphasis>Kickstart |
              NoGridStart</emphasis></emphasis> | PegasusLite | Distribute at
              the moment. <note>
                  <para>This profile should only be set by users if you know
                  what you are doing. Otherwise, let Pegasus do the right
                  thing based on your configuration.</para>
                </note><para><variablelist>
                  <varlistentry>
                    <term>Kickstart</term>

                    <listitem>
                       By default, all jobs executed are launched using a lightweight C executable called pegasus-kickstart. This generates valuable runtime provenance information for the job as it is executed on a remote node. This information serves as the basis for the monitoring and debugging capabilities provided by Pegasus. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>NoGridStart</term>

                    <listitem>
                       This explicity disables the wrapping of the jobs with pegasus-kickstart. This is internally used by the planner to launch dax jobs directly. If this is set, then the information populated in the monitording database is on the basis of what is recorded in the DAGMan out file. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>PegasusLite</term>

                    <listitem>
                       This value is automatically associated by the Planner whenever the job runs in either nonsharedfs or condorio mode. The property pegasus.data.configuration decides whether a job is launched via PegasusLite or not. PegasusLite is a lightweight Pegasus wrapper generated for each job that allows a job to run in a nonshared file system environment and is responsible for staging in the input data and staging out the output data back to a remote staging site for the job. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Distribute</term>

                    <listitem>
                      <para>This wrapper is a HubZero specfiic wrapper that
                      allows compute jobs that are scheduled for a local PBS
                      cluster to be run locally on the submit host. The jobs
                      are wrapped with a distribute wrapper that is
                      responsible for doing the qsub and tracking of the
                      status of the jobs in the PBS cluster.</para>
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.gridstart.path<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>gridstart.path<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path</literallayout></entry>

              <entry>Sets the path to the gridstart . This profile is best set
              in the Site Catalog.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.gridstart.arguments<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>gridstart.arguments<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Sets the arguments with which GridStart is used to launch
              a job on the remote site.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stagein.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stagein.clusters<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key determines the maximum number of
              <emphasis>stage-in</emphasis> jobs that are can executed locally
              or remotely per compute site per workflow. This is used to
              configure the <emphasis><link
              linkend="transfer-refiner-balanced-cluster">BalancedCluster</link></emphasis>
              Transfer Refiner, which is the Default Refiner used in Pegasus.
              This profile is best set in the Site Catalog or in the
              Properties file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stagein.local.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stagein.local.clusters<emphasis
                    role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key provides finer grained control in determining
              the number of stage-in jobs that are executed locally and are
              responsible for staging data to a particular remote site. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stagein.remote.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stagein.remote.clusters<emphasis
                    role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key provides finer grained control in determining
              the number of stage-in jobs that are executed remotely on the
              remote site and are responsible for staging data to it. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stageout.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stageout.clusters<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key determines the maximum number of
              <emphasis>stage-out</emphasis> jobs that are can executed
              locally or remotely per compute site per workflow. This is used
              to configure the <emphasis><link
              linkend="transfer-refiner-balanced-cluster">BalancedCluster</link></emphasis>
              Transfer Refiner, , which is the Default Refiner used in
              Pegasus.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stageout.local.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stageout.local.clusters<emphasis
                    role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key provides finer grained control in determining
              the number of stage-out jobs that are executed locally and are
              responsible for staging data from a particular remote site. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.stageout.remote.clusters<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>stageout.remote.clusters<emphasis
                    role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key provides finer grained control in determining
              the number of stage-out jobs that are executed remotely on the
              remote site and are responsible for staging data from it. This
              profile is best set in the Site Catalog or in the Properties
              file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.group<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>group<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Tags a job with an arbitrary group identifier. The group
              site selector makes use of the tag.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.change.dir<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>change.dir<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>If true, tells <emphasis>kickstart</emphasis> to change
              into the remote working directory. Kickstart itself is executed
              in whichever directory the remote scheduling system chose for
              the job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.create.dir<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>create.dir<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>If true, tells <emphasis>kickstart</emphasis> to create
              the the remote working directory before changing into the remote
              working directory. Kickstart itself is executed in whichever
              directory the remote scheduling system chose for the
              job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.proxy<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>transfer.proxy<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>If true, tells Pegasus to explicitly transfer the proxy
              for transfer jobs to the remote site. This is useful, when you
              want to use a full proxy at the remote end, instead of the
              limited proxy that is transferred by CondorG.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.style<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>style<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>Sets the condor submit file style. If set to globus,
              submit file generated refers to CondorG job submissions. If set
              to condor, submit file generated refers to direct Condor
              submission to the local Condor pool. It applies for glidein,
              where nodes from remote grid sites are glided into the local
              condor pool. The default style that is applied is
              globus.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.pmc_request_memory<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pmc_request_memory<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key is used to set the -m option for
              pegasus-mpi-cluster. It specifies the amount of memory in MB
              that a job requires. This profile is usually set in the DAX for
              each job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.pmc_request_cpus<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pmc_request_cpus<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key is used to set the -c option for
              pegasus-mpi-cluster. It specifies the number of cpu's that a job
              requires. This profile is usually set in the DAX for each
              job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.pmc_priority<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pmc_priority<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>This key is used to set the -p option for
              pegasus-mpi-cluster. It specifies the priority for a job . This
              profile is usually set in the DAX for each job. Negative values
              are allowed for priorities.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.pmc_task_arguments<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pmc_task_arguments<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>The key is used to pass any extra arguments to the PMC
              task during the planning time. They are added to the very end of
              the argument string constructed for the task in the PMC file.
              Hence, allows for overriding of any argument constructed by the
              planner for any particular task in the PMC job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.exitcode.failuremsg<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>exitcode.failuremsg<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.4
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>The message string that pegasus-exitcode searches for in
              the stdout and stderr of the job to flag failures.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.exitcode.successmsg<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>exitcode.successmsg<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.4
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>The message string that pegasus-exitcode searches for in
              the stdout and stderr of the job to determine whether a job
              logged it's success message or not. Note this value is used to
              check for whether a job failed or not i.e if this profile is
              specified, and pegasus-exitcode DOES NOT find the string in the
              job stdout or stderr, the job is flagged as failed. The complete
              rules for determining failure are described in the man page for
              pegasus-exitcode.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.checkpoint.time<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>checkpoint_time<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the expected time in minutes for a job after which it
              should be sent a TERM signal to generate a job checkpoint
              file</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.maxwalltime<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>maxwalltime<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

              <entry>the maximum walltime in minutes for a single execution of
              a job.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.glite.arguments<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>glite.arguments<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>specifies the extra arguments that must appear in the
              local PBS generated script for a job, when running workflows on
              a local cluster with submissions through Glite. This is useful
              when you want to pass through special options to underlying LRMS
              such as PBS e.g. you can set value -l walltime=01:23:45 -l
              nodes=2 to specify your job's resource requirements.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Profile  Key: </emphasis></emphasis>auxillary.local<emphasis
                    role="bold">
Scope       :</emphasis> SC
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>indicates whether auxillary jobs associated with a
              compute site X, can be run on local site. This CAN ONLY be
              specified as a profile in the site catalog and should be set
              when the compute site filesystem is accessible locally on the
              submit host.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key:</emphasis> pegasus.condor.arguments.quote<emphasis
                    role="bold">
Profile  Key: </emphasis>condor.arguments.quote<emphasis role="bold">
Scope       :</emphasis> SC, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Boolean</literallayout></entry>

              <entry>indicates whether condor quoting rules should be applied
              for writing out the arguments key in the condor submit file. By
              default it is true unless the job is schedule to a glite style
              site. The value is automatically set to false for glite style
              sites, as condor quoting is broken in batch_gahp.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <section id="task_resource_profiles">
        <title>Task Resource Requirements Profiles</title>

        <para>Startng Pegasus 4.6.0 Release, users can specify pegasus
        profiles to describe resources requirements for their job. The planner
        will automatically translate them to appropriate execution environment
        specific directives. For example, the profiles are automatically
        translated to Globus RSL keys if submitting job via CondorG to remote
        GRAM instances, Condor Classad keys when running in a vanilla condor
        pool and to appropriate shell variables for Glite that can be picked
        up by the local attributes.sh. The profiles are described
        below.</para>

        <para><table>
            <title>Task Resource Requirement Profiles.</title>

            <tgroup cols="2">
              <tbody>
                <row>
                  <entry><emphasis role="bold">Property Key
                  </emphasis></entry>

                  <entry><emphasis role="bold">Description</emphasis></entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.runtime<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>runtime<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Long</literallayout></entry>

                  <entry>This profile specifies the expected runtime of a job
                  in seconds. Refer to the <link
                  linkend="runtime_clustering">Pegasus Clustering Guide</link>
                  for description on using it for runtime clustering.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>clusters.maxruntime<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pegasus.clusters.maxruntime<emphasis
                        role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

                  <entry>Please refer to the <link
                  linkend="runtime_clustering">Pegasus Clustering Guide</link>
                  for detailed description. This profile specifies the maximum
                  runtime of a job.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.cores<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>cores<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.0
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

                  <entry>The total number of cores, required for a job. This
                  is also used for accounting purposes in the database while
                  generating statistics. It corresponds to the
                  multiplier_factor in the job_instance table described <link
                  linkend="stampede_schema_overview">here</link>.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.nodes<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>nodes<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

                  <entry>Indicates the the number of nodes a job
                  requires.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.ppn<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>ppn<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Integer</literallayout></entry>

                  <entry>Indicates the number of processors per node . This
                  profile is best set in the Site Catalog and usually set when
                  running workflows with MPI jobs.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.memory<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>memory<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Long</literallayout></entry>

                  <entry>Indicates the maximum memory a job requires in
                  MB.</entry>
                </row>

                <row>
                  <entry><literallayout><emphasis role="bold"><emphasis
                          role="bold">Property Key: </emphasis></emphasis>pegasus.diskspace<emphasis
                        role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>diskspace<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>Long</literallayout></entry>

                  <entry>Indicates the maximum diskspace a job requires in
                  MB.</entry>
                </row>
              </tbody>
            </tgroup>
          </table>The automatic translation to various execution environment
        specific directives is explained below. It is important, to note that
        execution environment specific keys take precedence over the Pegasus
        profile keys. For example, Globus profile key maxruntime will be
        preferred over Pegasus profile key runtime when running jobs via
        HTCondorG.</para>

        <table>
          <title>Table mapping translation of Pegasus Task Requirements to
          corresponding execution environment keys.</title>

          <tgroup cols="4">
            <thead>
              <row>
                <entry align="center">Pegasus Task Resource Requirement
                Profile Key</entry>

                <entry align="center">Corresponding Globus RSL Key</entry>

                <entry align="center">Corresponding Condor Classad Key</entry>

                <entry align="center">KEY in +remote_cerequirements classad
                for GLITE</entry>
              </row>
            </thead>

            <tbody>
              <row>
                <entry>runtime</entry>

                <entry>maxruntime</entry>

                <entry>-</entry>

                <entry>WALLTIME</entry>
              </row>

              <row>
                <entry>cores</entry>

                <entry>count</entry>

                <entry>request_cpus</entry>

                <entry>CORES</entry>
              </row>

              <row>
                <entry>nodes</entry>

                <entry>hostcount</entry>

                <entry>-</entry>

                <entry>NODES</entry>
              </row>

              <row>
                <entry>ppn</entry>

                <entry>xcount</entry>

                <entry>-</entry>

                <entry>PROCS</entry>
              </row>

              <row>
                <entry>memory</entry>

                <entry>maxmemory</entry>

                <entry>request_memory</entry>

                <entry>PER_PROCESS_MEMORY</entry>
              </row>

              <row>
                <entry>diskspace</entry>

                <entry>-</entry>

                <entry>request_diskspace</entry>

                <entry>-</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </section>
    </section>

    <section id="hints_profiles">
      <title>The Hints Profile Namespace</title>

      <para>The <emphasis>hints</emphasis> namespace allows users to override
      the behavior of the Workflow Mapper during site selection. This gives
      you finer grained control over where a job executes and what executable
      it refers to. The hints namespace keys ( execution.site and pfn ) can
      only be specified in the DAX. It is important to note that these
      particular keys once specified in the DAX, cannot be overriden like
      other profiles.</para>

      <table>
        <title>Useful Hints Profile Keys</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>N/A<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>execution.site<emphasis role="bold">
Scope       :</emphasis> DAX
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>String
</literallayout></entry>

              <entry>the execution site where a job should be
              executed.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>N/A<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>pfn<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>the physical file name to the main executable that a job
              refers to. Overrides any entries specified in the transformation
              catalog.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>hints.grid.jobtype<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>grid.jobtype<emphasis role="bold">
Scope       :</emphasis> TC, SC, DAX, Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type        : </emphasis>String</literallayout></entry>

              <entry>applicable when submitting to remote sites via GRAM. The
              site catalog allows you to associate multiple jobmanagers with a
              GRAM site, for different type of jobs [compute, auxillary,
              transfer, register, cleanup ] that Pegasus generates in the
              executable workflow. This profile is usually used to ensure that
              a compute job executes on another job manager. For example, if
              in site catalog you have headnode.example.com/jobmanager-condor
              for compute jobs, and headnode.example.com/jobmanager-fork for
              auxillary jobs. Associating this profile and setting value to
              auxillary for a compute job, will cause the compute job to run
              on the fork jobmanager instead of the condor jobmanager.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </section>

  <section id="properties">
    <title>Properties</title>

    <para>Properties are primarily used to configure the behavior of the
    Pegasus Workflow Planner at a global level. The properties file is
    actually a java properties file and follows the same conventions as that
    to specify the properties.</para>

    <para>Please note that the values rely on proper capitalization, unless
    explicitly noted otherwise.</para>

    <para>Some properties rely with their default on the value of other
    properties. As a notation, the curly braces refer to the value of the
    named property. For instance, ${pegasus.home} means that the value depends
    on the value of the pegasus.home property plus any noted additions. You
    can use this notation to refer to other properties, though the extent of
    the subsitutions are limited. Usually, you want to refer to a set of the
    standard system properties. Nesting is not allowed. Substitutions will
    only be done once.</para>

    <para>There is a priority to the order of reading and evaluating
    properties. Usually one does not need to worry about the priorities.
    However, it is good to know the details of when which property applies,
    and how one property is able to overwrite another. The following is a
    mutually exclusive list ( highest priority first ) of property file
    locations.</para>

    <para><orderedlist>
        <listitem>
           --conf option to the tools. Almost all of the clients that use properties have a --conf option to specify the property file to pick up. 
        </listitem>

        <listitem>
           submit-dir/pegasus.xxxxxxx.properties file. All tools that work on the submit directory ( i.e after pegasus has planned a workflow) pick up the pegasus.xxxxx.properties file from the submit directory. The location for the pegasus.xxxxxxx.propertiesis picked up from the braindump file. 
        </listitem>

        <listitem>
           The properties defined in the user property file 

          <emphasis>${user.home}/.pegasusrc</emphasis>

           have lowest priority. 
        </listitem>
      </orderedlist></para>

    <para>Commandline properties have the highest priority. These override any
    property loaded from a property file. Each commandline property is
    introduced by a -D argument. Note that these arguments are parsed by the
    shell wrapper, and thus the -D arguments must be the first arguments to
    any command. Commandline properties are useful for debugging
    purposes.</para>

    <para>From Pegasus 3.1 release onwards, support has been dropped for the
    following properties that were used to signify the location of the
    properties file</para>

    <para><itemizedlist>
        <listitem>
           pegasus.properties 
        </listitem>

        <listitem>
           pegasus.user.properties 
        </listitem>
      </itemizedlist></para>

    <para>The following example provides a sensible set of properties to be
    set by the user property file. These properties use mostly non-default
    settings. It is an example only, and will not work for you:</para>

    <para><screen>
pegasus.catalog.replica              File
pegasus.catalog.replica.file         ${pegasus.home}/etc/sample.rc.data
pegasus.catalog.transformation       Text
pegasus.catalog.transformation.file  ${pegasus.home}/etc/sample.tc.text
pegasus.catalog.site.file            ${pegasus.home}/etc/sample.sites.xml
</screen></para>

    <para>If you are in doubt which properties are actually visible, pegasus
    during the planning of the workflow dumps all properties after reading and
    prioritizing in the submit directory in a file with the suffix
    properties.</para>

    <section id="local_dir_props">
      <title>Local Directories Properties</title>

      <para>This section describes the GNU directory structure conventions.
      GNU distinguishes between architecture independent and thus sharable
      directories, and directories with data specific to a platform, and thus
      often local. It also distinguishes between frequently modified data and
      rarely changing data. These two axis form a space of four distinct
      directories.</para>

      <para><table>
          <title>Local Directories Related Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes
                </emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.home.datadir<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home}/share</literallayout></entry>

                <entry>The datadir directory contains broadly visible and
                possibly exported configuration files that rarely change. This
                directory is currently unused.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.home.sysconfdir<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">


Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home}/etc</literallayout></entry>

                <entry>The system configuration directory contains
                configuration files that are specific to the machine or
                installation, and that rarely change. This is the directory
                where the XML schema definition copies are stored, and where
                the base pool configuration file is stored.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.home.sharedstatedir<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home}/com</literallayout></entry>

                <entry>Frequently changing files that are broadly visible are
                stored in the shared state directory. This is currently
                unused.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.home.localstatedir<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home}/var</literallayout></entry>

                <entry>Frequently changing files that are specific to a
                machine and/or installation are stored in the local state
                directory. This is currently unused</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.dir.submit.logs<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

                <entry><para>This property can be used to specify the
                directory where the condor logs for the workflow should go to.
                By default, starting 4.2.1 release, Pegasus will setup the log
                to be in the workflow submit directory. This can create
                problems, in case users submit directories are on
                NSF.</para><para>This is done to ensure that the logs are
                created in a local directory even though the submit directory
                maybe on NFS</para></entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="site_dir_props">
      <title>Site Directories Properties</title>

      <para>The site directory properties modify the behavior of remotely run
      jobs. In rare occasions, it may also pertain to locally run compute
      jobs.</para>

      <table>
        <title>Site Directories Related Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.useTimestamp<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.1
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false</literallayout></entry>

              <entry>While creating the submit directory, Pegasus employs a
              run numbering scheme. Users can use this Boolean property to use
              a timestamp based numbering scheme instead of the runxxxx
              scheme.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.exec<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry>This property modifies the remote location work directory
              in which all your jobs will run. If the path is relative then it
              is appended to the work directory (associated with the site), as
              specified in the site catalog. If the path is absolute then it
              overrides the work directory specified in the site
              catalog.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.submit.mapper<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.7
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Values      :</emphasis> Flat|Hashed
<emphasis role="bold">Default     :</emphasis> Hashed</literallayout></entry>

              <entry>This property modifies determines how the directory for
              job submit files are mapped on the submit host.<variablelist>
                  <varlistentry>
                    <term>Flat</term>

                    <listitem>
                       This mapper results in Pegasus placing all the job submit files in the submit directory as determined from the planner options. This can result in too many files in one directory for large workflows, and was the only option before Pegasus 4.7.0 release. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Hashed</term>

                    <listitem>
                       This mapper results in the creation of a deep directory structure rooted at the submit directory. The base directory is the submit directory as determined from the planner options. By default, the directory structure created is two levels deep. To control behavior of this mapper, users can specify the following properties 

                      <screen>
pegasus.dir.submit.mapper.hashed.levels     the number of directory levels used 
                                            to accomodate the files. Defaults to 2.
pegasus.dir.submit.mapper.hashed.multiplier the number of files associated with a job
                                            in the submit directory. defaults to 5.
</screen>

                       
                    </listitem>
                  </varlistentry>
                </variablelist></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.staging.mapper<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.7
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Values      :</emphasis> Flat|Hashed
<emphasis role="bold">Default     :</emphasis> Hashed</literallayout></entry>

              <entry>This property modifies determines how the job input and
              output files are mapped on the staging site. This only applies
              when the pegasus data configuration is set to
              nonsharedfs.<variablelist>
                  <varlistentry>
                    <term>Flat</term>

                    <listitem>
                       This mapper results in Pegasus placing all the job submit files in the staging site directory as determined from the Site Catalog and planner options. This can result in too many files in one directory for large workflows, and was the only option before Pegasus 4.7.0 release. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Hashed</term>

                    <listitem>
                       This mapper results in the creation of a deep directory structure rooted at the staging site directory created by the create dir jobs. The binning is at the job level, and not at the file level i.e each job will push out it's outputs to the same directory on the staging site, independent of the number of output files. To control behavior of this mapper, users can specify the following properties 

                      <screen>
pegasus.dir.staging.mapper.hashed.levels     the number of directory levels used 
                                            to accomodate the files. Defaults to 2.
pegasus.dir.staging.mapper.hashed.multiplier the number of files associated with a job
                                            in the submit directory. defaults to 5.
</screen>

                       
                    </listitem>
                  </varlistentry>
                </variablelist></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.storage.mapper<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.3
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Values      :</emphasis> Flat|Fixed|Hashed|Replica
<emphasis role="bold">Default     :</emphasis> Flat</literallayout></entry>

              <entry>This property modifies determines how the output files
              are mapped on the output site storage location. <para/>In order
              to preserve backward compatibility, setting the boolean property
              pegasus.dir.storage.deep results in the Hashed output mapper to
              be loaded, if no output mapper property is specified.
              <variablelist>
                  <varlistentry>
                    <term>Flat</term>

                    <listitem>
                       By default, Pegasus will place the output files in the storage directory specified in the site catalog for the output site. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Fixed</term>

                    <listitem>
                       Using this mapper, users can specify an externally accesible url to the storage directory in their properties file. The following property needs to be set. 

                      <screen>
pegasus.dir.storage.mapper.fixed.url  an externally accessible URL to the
storage directory on the output site
e.g. gsiftp://outputs.isi.edu/shared/outputs
</screen>

                       Note: For hierarchal workflows, the above property needs to be set separately for each dax job, if you want the sub workflow outputs to goto a different directory. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Hashed</term>

                    <listitem>
                       This mapper results in the creation of a deep directory structure on the output site, while populating the results. The base directory on the remote end is determined from the site catalog. Depending on the number of files being staged to the remote site a Hashed File Structure is created that ensures that only 256 files reside in one directory. To create this directory structure on the storage site, Pegasus relies on the directory creation feature of the Grid FTP server, which appeared in globus 4.0.x 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Replica</term>

                    <listitem>
                       This mapper determines the path for an output file on the output site by querying an output replica catalog. The output site is one that is passed on the command line. The output replica catalog can be configured by specifiing the properties with the prefix pegasus.dir.storage.replica. By default, a Regex File based backend is assumed unless overridden. For example 

                      <screen>
pegasus.dir.storage.mapper.replica       Regex|File
pegasus.dir.storage.mapper.replica.file  the RC file at the backend to use if using a file based RC
</screen>

                       
                    </listitem>
                  </varlistentry>
                </variablelist></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.storage.deep<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.1
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false</literallayout></entry>

              <entry><para>This Boolean property results in the creation of a
              deep directory structure on the output site, while populating
              the results. The base directory on the remote end is determined
              from the site catalog.</para><para>To this base directory, the
              relative submit directory structure (
              $user/$vogroup/$label/runxxxx ) is
              appended.</para><para>$storage = $base +
              $relative_submit_directory</para><para>This is the base
              directory that is passed to the storage
              mapper.</para><para>Note: To preserve backward compatibilty,
              setting this property results in the Hashed mapper to be loaded
              unless pegasus.dir.storage.mapper is explicitly specified.
              Before 4.3, this property resulted in HashedDirectory
              structure.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dir.create.strategy<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Values      :</emphasis> HourGlass|Tentacles|Minimal<emphasis
                    role="bold">
Default     :</emphasis> Minimal</literallayout></entry>

              <entry><para>If the <screen>--randomdir</screen> option is given
              to the Planner at runtime, the Pegasus planner adds nodes that
              create the random directories at the remote pool sites, before
              any jobs are actually run. The two modes determine the placement
              of these nodes and their dependencies to the rest of the
              graph.</para><para><variablelist>
                  <varlistentry>
                    <term>HourGlass</term>

                    <listitem>
                       It adds a make directory node at the top level of the graph, and all these concat to a single dummy job before branching out to the root nodes of the original/ concrete dag so far. So we introduce a classic X shape at the top of the graph. Hence the name HourGlass. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Tentacles</term>

                    <listitem>
                       This option places the jobs creating directories at the top of the graph. However instead of constricting it to an hour glass shape, this mode links the top node to all the relevant nodes for which the create dir job is necessary. It looks as if the node spreads its tentacleas all around. This puts more load on the DAGMan because of the added dependencies but removes the restriction of the plan progressing only when all the create directory jobs have progressed on the remote pools, as is the case in the HourGlass model. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Minimal</term>

                    <listitem>
                       The strategy involves in walking the graph in a BFS order, and updating a bit set associated with each job based on the BitSet of the parent jobs. The BitSet indicates whether an edge exists from the create dir job to an ancestor of the node. For a node, the bit set is the union of all the parents BitSets. The BFS traversal ensures that the bitsets are of a node are only updated once the parents have been processed. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para/>
    </section>

    <section id="schema_props">
      <title>Schema File Location Properties</title>

      <para>This section defines the location of XML schema files that are
      used to parse the various XML document instances in the PEGASUS. The
      schema backups in the installed file-system permit PEGASUS operations
      without being online.</para>

      <para><table>
          <title>Schema File Location Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes
                </emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.schema.dax<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home.sysconfdir}/dax-3.4.xsd</literallayout></entry>

                <entry>This file is a copy of the XML schema that describes
                abstract DAG files that are the result of the abstract
                planning process, and input into any concrete planning.
                Providing a copy of the schema enables the parser to use the
                local copy instead of reaching out to the Internet, and
                obtaining the latest version from the Pegasus website
                dynamically.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.schema.sc<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home.sysconfdir}/sc-4.0.xsd</literallayout></entry>

                <entry>This file is a copy of the XML schema that describes
                the xml description of the site catalog. Providing a copy of
                the schema enables the parser to use the local copy instead of
                reaching out to the internet, and obtaining the latest version
                from the GriPhyN website dynamically.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.schema.ivr<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> ${pegasus.home.sysconfdir}/iv-2.0.xsd</literallayout></entry>

                <entry>This file is a copy of the XML schema that describes
                invocation record files that are the result of the a grid
                launch in a remote or local site. Providing a copy of the
                schema enables the parser to use the local copy instead of
                reaching out to the Internet, and obtaining the latest version
                from the Pegasus website dynamically.</entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="db_props">
      <title>Database Drivers For All Relational Catalogs</title>

      <para/>

      <table>
        <title>Database Driver Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Property Key </emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.db.driver<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Values      : </emphasis>MySQL|PostGres|SQLite<emphasis
                    role="bold">
Default     :</emphasis> (no default)</literallayout></entry>

              <entry><para>The database driver class is dynamically loaded, as
              required by the schema. Currently, only MySQL 5.x, PostGreSQL
              &gt;= 8.1 and SQlite are supported. Their respective JDBC3 driver is
              provided as part and parcel of the PEGASUS.</para><para>The * in
              the property name can be replaced by a catalog name to apply the
              property only for that catalog. Valid catalog names
              are</para><para><screen>replica
</screen></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.db.url<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Database URL
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry>Each database has its own string to contact the database
              on a given host, port, and database. Although most driver URLs
              allow to pass arbitrary arguments, please use the
              pegasus.catalog.[catalog-name].db.* keys or
              pegasus.catalog.*.db.* to preload these arguments. <para/>THE
              URL IS A MANDATORY PROPERTY FOR ANY DBMS BACKEND.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.db.user<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> </literallayout></entry>

              <entry><para>In order to access a database, you must provide the
              name of your account on the DBMS. This property is
              database-independent. THIS IS A MANDATORY PROPERTY FOR MANY DBMS
              BACKENDS.</para><para>The * in the property name can be replaced
              by a catalog name to apply the property only for that catalog.
              Valid catalog names are</para><para><screen>replica</screen></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.db.password<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry><para>In order to access a database, you must provide an
              optional password of your account on the DBMS. This property is
              database-independent. THIS IS A MANDATORY PROPERTY, IF YOUR DBMS
              BACKEND ACCOUNT REQUIRES A PASSWORD.</para><para>The * in the
              property name can be replaced by a catalog name to apply the
              property only for that catalog. Valid catalog names are<screen>replica</screen></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.db.*<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry><para/><para>Each database has a multitude of options to
              control in fine detail the further behaviour. You may want to
              check the JDBC3 documentation of the JDBC driver for your
              database for details. The keys will be passed as part of the
              connect properties by stripping the
              "pegasus.catalog.[catalog-name].db." prefix from them. The
              catalog-name can be replaced by the following values provenance
              for Provenance Catalog (PTC), replica for Replica Catalog
              (RC)</para><para>Postgres &gt;= 8.1 parses the following properties:
              <screen>
pegasus.catalog.*.db.user
pegasus.catalog.*.db.password
pegasus.catalog.*.db.PGHOST
pegasus.catalog.*.db.PGPORT
pegasus.catalog.*.db.charSet
pegasus.catalog.*.db.compatible
</screen></para><para>MySQL 5.0 parses the following
              properties:</para><para><screen>
pegasus.catalog.*.db.user
pegasus.catalog.*.db.password
pegasus.catalog.*.db.databaseName
pegasus.catalog.*.db.serverName
pegasus.catalog.*.db.portNumber
pegasus.catalog.*.db.socketFactory
pegasus.catalog.*.db.strictUpdates
pegasus.catalog.*.db.ignoreNonTxTables
pegasus.catalog.*.db.secondsBeforeRetryMaster
pegasus.catalog.*.db.queriesBeforeRetryMaster
pegasus.catalog.*.db.allowLoadLocalInfile
pegasus.catalog.*.db.continueBatchOnError
pegasus.catalog.*.db.pedantic
pegasus.catalog.*.db.useStreamLengthsInPrepStmts
pegasus.catalog.*.db.useTimezone
pegasus.catalog.*.db.relaxAutoCommit
pegasus.catalog.*.db.paranoid
pegasus.catalog.*.db.autoReconnect
pegasus.catalog.*.db.capitalizeTypeNames
pegasus.catalog.*.db.ultraDevHack
pegasus.catalog.*.db.strictFloatingPoint
pegasus.catalog.*.db.useSSL
pegasus.catalog.*.db.useCompression
pegasus.catalog.*.db.socketTimeout
pegasus.catalog.*.db.maxReconnects
pegasus.catalog.*.db.initialTimeout
pegasus.catalog.*.db.maxRows
pegasus.catalog.*.db.useHostsInPrivileges
pegasus.catalog.*.db.interactiveClient
pegasus.catalog.*.db.useUnicode
pegasus.catalog.*.db.characterEncoding
</screen></para><para>MS SQL Server 2000 support the following properties
              (keys are case-insensitive, e.g. both "user" and "User" are
              valid):</para><para><screen>
pegasus.catalog.*.db.User
pegasus.catalog.*.db.Password
pegasus.catalog.*.db.DatabaseName
pegasus.catalog.*.db.ServerName
pegasus.catalog.*.db.HostProcess
pegasus.catalog.*.db.NetAddress
pegasus.catalog.*.db.PortNumber
pegasus.catalog.*.db.ProgramName
pegasus.catalog.*.db.SendStringParametersAsUnicode
pegasus.catalog.*.db.SelectMethod
</screen></para><para>The * in the property name can be replaced by a catalog
              name to apply the property only for that catalog. Valid catalog
              names are</para><para><screen>replica</screen></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.*.timeout<emphasis
                    role="bold"><emphasis role="bold">
                      Profile  Key: </emphasis></emphasis>N/A<emphasis
                    role="bold">
                      Scope       :</emphasis> Properties
                      <emphasis role="bold">Since       :</emphasis> 4.5.1
                      <emphasis role="bold">Type        : </emphasis>Integer
                      <emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry><para>This property sets a busy handler that sleeps for a
              specified amount of time (in seconds) when a table is locked.
              This property has effect only in a sqlite database.</para>
              <para>The * in the property name can be replaced by a catalog
              name to apply the property only for that catalog. Valid catalog
              names are</para><para><screen>master
workflow</screen></para></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section id="catalog_props">
      <title>Catalog Related Properties</title>

      <para/>

      <table>
        <title>Replica Catalog Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.catalog.replica<emphasis
                    role="bold">
Profile  Key: </emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> File
</literallayout></entry>

              <entry><para>Pegasus queries a Replica Catalog to discover the
              physical filenames (PFN) for input files specified in the DAX.
              Pegasus can interface with various types of Replica Catalogs.
              This property specifies which type of Replica Catalog to use
              during the planning process.</para><para><variablelist>
                  <varlistentry>
                    <term>JDBCRC</term>

                    <listitem>
                       In this mode, Pegasus queries a SQL based replica catalog that is accessed via JDBC. To use JDBCRC, the user additionally needs to set the following properties 

                      <orderedlist>
                        <listitem>pegasus.catalog.replica.db.driver = mysql |
                        postgres |sqlite</listitem>

                        <listitem>pegasus.catalog.replica.db.url = &lt;jdbc
                        url to the database&gt; e.g
                        jdbc:mysql://database-host.isi.edu/database-name |
                        jdbc:sqlite:/shared/jdbcrc.db</listitem>

                        <listitem>pegasus.catalog.replica.db.user =
                        database-user</listitem>

                        <listitem>pegasus.catalog.replica.db.password =
                        database-password</listitem>
                      </orderedlist>

                       
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>File</term>

                    <listitem>
                      <para>In this mode, Pegasus queries a file based replica
                      catalog. It is neither transactionally safe, nor advised
                      to use for production purposes in any way. Multiple
                      concurrent instances <emphasis>will clobber</emphasis>
                      each other!. The site attribute should be specified
                      whenever possible. The attribute key for the site
                      attribute is "site".</para>

                      <para>The LFN may or may not be quoted. If it contains
                      linear whitespace, quotes, backslash or an equality
                      sign, it must be quoted and escaped. Ditto for the PFN.
                      The attribute key-value pairs are separated by an
                      equality sign without any whitespaces. The value may be
                      in quoted. The LFN sentiments about quoting
                      apply.</para>

                      <para><screen>
LFN PFN
LFN PFN a=b [..]
LFN PFN a="b" [..]
"LFN w/LWS" "PFN w/LWS" [..]
</screen></para>

                      <para>To use File, the user additionally needs to
                      specify <emphasis
                      role="bold">pegasus.catalog.replica.file</emphasis>
                      property to specify the path to the file based RC. IF
                      not specified , defaults to $PWD/rc.txt file.</para>
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Regex</term>

                    <listitem>
                      <para>In this mode, Pegasus queries a file based replica
                      catalog. It is neither transactionally safe, nor advised
                      to use for production purposes in any way. Multiple
                      concurrent access to the File will end up clobbering the
                      contents of the file. The site attribute should be
                      specified whenever possible. The attribute key for the
                      site attribute is "site".</para>

                      <para>The LFN may or may not be quoted. If it contains
                      linear whitespace, quotes, backslash or an equality
                      sign, it must be quoted and escaped. Ditto for the PFN.
                      The attribute key-value pairs are separated by an
                      equality sign without any whitespaces. The value may be
                      in quoted. The LFN sentiments about quoting
                      apply.</para>

                      <para>In addition users can specifiy regular expression
                      based LFN's. A regular expression based entry should be
                      qualified with an attribute named 'regex'. The attribute
                      regex when set to true identifies the catalog entry as a
                      regular expression based entry. Regular expressions
                      should follow Java regular expression syntax.</para>

                      <para>For example, consider a replica catalog as shown
                      below.</para>

                      <para>Entry 1 refers to an entry which does not use a
                      resular expressions. This entry would only match a file
                      named 'f.a', and nothing else. Entry 2 referes to an
                      entry which uses a regular expression. In this entry f.a
                      referes to files having name as f[any-character]a i.e.
                      faa, f.a, f0a, etc.</para>

                      <para><screen>
f.a file:///Vol/input/f.a site="local"
f.a file:///Vol/input/f.a site="local" regex="true"
</screen></para>

                      <para>Regular expression based entries also support
                      substitutions. For example, consider the regular
                      expression based entry shown below.</para>

                      <para>Entry 3 will match files with name alpha.csv,
                      alpha.txt, alpha.xml. In addition, values matched in the
                      expression can be used to generate a PFN.</para>

                      <para>For the entry below if the file being looked up is
                      alpha.csv, the PFN for the file would be generated as
                      file:///Volumes/data/input/csv/alpha.csv. Similary if
                      the file being lookedup was alpha.csv, the PFN for the
                      file would be generated as
                      file:///Volumes/data/input/xml/alpha.xml i.e. The
                      section [0], [1] will be replaced. Section [0] refers to
                      the entire string i.e. alpha.csv. Section [1] refers to
                      a partial match in the input i.e. csv, or txt, or xml.
                      Users can utilize as many sections as they wish.</para>

                      <para><screen>
alpha\.(csv|txt|xml) file:///Vol/input/[1]/[0] site="local" regex="true"
</screen></para>

                      <para>To use File, the user additionally needs to
                      specify pegasus.catalog.replica.file property to specify
                      the path to the file based RC.</para>
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Directory</term>

                    <listitem>
                      <para>In this mode, Pegasus does a directory listing on
                      an input directory to create the LFN to PFN mappings.
                      The directory listing is performed recursively,
                      resulting in deep LFN mappings. For example, if an input
                      directory $input is specified with the following
                      structure <screen>
$input
$input/f.1
$input/f.2
$input/D1
$input/D1/f.3
</screen> Pegasus will create the mappings the following LFN PFN mappings
                      internally <screen>
f.1 file://$input/f.1  site="local"
f.2 file://$input/f.2  site="local"
D1/f.3 file://$input/D2/f.3 site="local"
</screen></para>

                      <para>If you don't want the deep lfn's to be created
                      then, you can set
                      pegasus.catalog.replica.directory.flat.lfn to true In
                      that case, for the previous example, Pegasus will create
                      the following LFN PFN mappings internally. <screen>
f.1 file://$input/f.1  site="local"
f.2 file://$input/f.2  site="local"
f.3 file://$input/D2/f.3 site="local"
</screen></para>

                      <para>pegasus-plan has --input-dir option that can be
                      used to specify an input directory.</para>

                      <para>Users can optionally specify additional properties
                      to configure the behvavior of this
                      implementation.</para>

                      <para><emphasis
                      role="bold">pegasus.catalog.replica.directory</emphasis>
                      to specify the path to the directory containing the
                      files</para>

                      <para><emphasis
                      role="bold">pegasus.catalog.replica.directory.site</emphasis>
                      to specify a site attribute other than local to
                      associate with the mappings.</para>

                      <para><emphasis
                      role="bold">pegasus.catalog.replica.directory.url.prefix</emphasis>
                      to associate a URL prefix for the PFN's constructed. If
                      not specified, the URL defaults to file://</para>
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>MRC</term>

                    <listitem>
                      <para>In this mode, Pegasus queries multiple replica
                      catalogs to discover the file locations on the grid. To
                      use it set</para>

                      <para><screen>
pegasus.catalog.replica MRC
</screen></para>

                      <para>Each associated replica catalog can be configured
                      via properties as follows.</para>

                      <para>The user associates a variable name referred to as
                      [value] for each of the catalogs, where [value] is any
                      legal identifier (concretely [A-Za-z][_A-Za-z0-9]*) For
                      each associated replica catalogs the user specifies the
                      following properties.</para>

                      <para><screen>
pegasus.catalog.replica.mrc.[value]       specifies the type of \
                                          replica catalog.
pegasus.catalog.replica.mrc.[value].key   specifies a property name\
                                          key for a particular catalog
</screen></para>

                      <para><screen>
pegasus.catalog.replica.mrc.directory1 Directory
pegasus.catalog.replica.mrc.directory1.directory /input/dir1
pegasus.catalog.replica.mrc.directory1.directory.site  siteX
pegasus.catalog.replica.mrc.directory2 Directory
pegasus.catalog.replica.mrc.directory2.directory /input/dir2
pegasus.catalog.replica.mrc.directory1.directory.site  siteY
</screen></para>

                      <para>In the above example, directory1, directory2 are
                      any valid identifier names and url is the property key
                      that needed to be specified.</para>
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                            role="bold">Property Key:</emphasis></emphasis></emphasis></emphasis><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"> </emphasis></emphasis></emphasis></emphasis>pegasus.catalog.replica.chunk.size<emphasis
                    role="bold"><emphasis role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> 1000
</literallayout></entry>

              <entry><para>The pegasus-rc-client takes in an input file
              containing the mappings upon which to work. This property
              determines, the number of lines that are read in at a time, and
              worked upon at together. This allows the various operations like
              insert, delete happen in bulk if the underlying replica
              implementation supports it.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                            role="bold"><emphasis role="bold"><emphasis
                                role="bold"><emphasis role="bold">Property Key:</emphasis></emphasis></emphasis></emphasis></emphasis></emphasis> </emphasis></emphasis>pegasus.catalog.replica.cache.asrc<emphasis
                    role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                          role="bold">
Profile Key :</emphasis></emphasis></emphasis></emphasis><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"> </emphasis></emphasis></emphasis>N/A<emphasis
                    role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> false
</literallayout></entry>

              <entry><para>This Boolean property determines whether to treat
              the cache file specified as a supplemental replica catalog or
              not. User can specify on the command line to pegasus-plan a
              comma separated list of cache files using the --cache option. By
              default, the LFN-&gt;PFN mappings contained in the cache file
              are treated as cache, i.e if an entry is found in a cache file
              the replica catalog is not queried. This results in only the
              entry specified in the cache file to be available for replica
              selection.</para>Setting this property to true, results in the
              cache files to be treated as supplemental replica catalogs. This
              results in the mappings found in the replica catalog (as
              specified by pegasus.catalog.replica) to be merged with the ones
              found in the cache files. Thus, mappings for a particular LFN
              found in both the cache and the replica catalog are available
              for replica selection.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                            role="bold"><emphasis role="bold"><emphasis
                                role="bold"><emphasis role="bold">Property Key:</emphasis></emphasis></emphasis></emphasis></emphasis></emphasis> </emphasis></emphasis>pegasus.catalog.replica.dax.asrc<emphasis
                    role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                          role="bold">
Profile Key :</emphasis></emphasis></emphasis></emphasis><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"> </emphasis></emphasis></emphasis>N/A<emphasis
                    role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5.2
<emphasis role="bold">Default     :</emphasis> false
</literallayout></entry>

              <entry><para>This Boolean property determines whether to treat
              the locations of files recorded in the DAX as a supplemental
              replica catalog or not. By default, the LFN-&gt;PFN mappings
              contained in the DAX file overrides any specified in a replica
              catalog. This results in only the entry specified in the DAX
              file to be available for replica selection.</para>Setting this
              property to true, results in the locations of files recorded in
              the DAX files to be treated as a supplemental replica catalog.
              This results in the mappings found in the replica catalog (as
              specified by pegasus.catalog.replica) to be merged with the ones
              found in the cache files. Thus, mappings for a particular LFN
              found in both the DAX and the replica catalog are available for
              replica selection.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                            role="bold"><emphasis role="bold"><emphasis
                                role="bold"><emphasis role="bold">Property Key:</emphasis></emphasis></emphasis></emphasis></emphasis></emphasis> </emphasis></emphasis>pegasus.catalog.replica.output<emphasis
                    role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                          role="bold">.*
Profile Key :</emphasis></emphasis></emphasis></emphasis><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"> </emphasis></emphasis></emphasis>N/A<emphasis
                    role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5.3
<emphasis role="bold">Default     :</emphasis> None
</literallayout></entry>

              <entry><para>Normally, the registration jobs in the executable
              workflow register to the replica catalog specified by the user
              in the properties file . This property prefix allows the user to
              specify a separate output replica catalog that is different from
              the one used for discovery of input files. This is normally the
              case, when a Directory or MRC based replica catalog backend that
              don't support insertion of entries are used for discovery of
              input files. For example to specify a separate file based output
              replica catalog, specify </para><screen>pegasus.catalog.replica.output        File
pegasus.catalog.replica.output.file   /workflow/output.rc
</screen></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <table>
        <title>Site Catalog Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold"><emphasis role="bold"><emphasis
                            role="bold"><emphasis role="bold"><emphasis
                                role="bold"><emphasis role="bold"><emphasis
                                    role="bold">Property Key: </emphasis></emphasis></emphasis></emphasis></emphasis></emphasis></emphasis></emphasis></emphasis>pegasus.catalog.site<emphasis
                    role="bold">
Profile  Key: </emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> XML
</literallayout></entry>

              <entry>Pegasus supports two different types of site catalogs in
              XML format conforming <itemizedlist>
                  <listitem>
                    <para>sc-3.0.xsd
                    http://pegasus.isi.edu/schema/sc-3.0.xsd</para>
                  </listitem>

                  <listitem>
                    <para>sc-4.0.xsd
                    http://pegasus.isi.edu/schema/sc-4.0.xsd</para>
                  </listitem>
                </itemizedlist>Pegasus is able to auto-detect what schema a
              user site catalog refers to. Hence, this property may no longer
              be set.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key:</emphasis> </emphasis>pegasus.catalog.site.file<emphasis
                    role="bold"><emphasis role="bold">
Profile Key : </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> $PWD/sites.xml</literallayout></entry>

              <entry>The path to the site catalog file, that describes the
              various sites and their layouts to Pegasus.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <table>
        <title>Transformation Catalog Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.catalog.transformation<emphasis
                    role="bold">
Profile  Key: </emphasis>N/A<emphasis role="bold">
Scope       : </emphasis>Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> Text
</literallayout></entry>

              <entry><para>The only recommended and supported version of
              Transformation Catalog for Pegasus is Text. For the old File
              based formats, users should use pegasus-tc-converter to convert
              File format to Text Format.</para><para><variablelist>
                  <varlistentry>
                    <term>Text</term>

                    <listitem>
                      <para>In this mode, a multiline file based format is
                      understood. The file is read and cached in memory. Any
                      modifications, as adding or deleting, causes an update
                      of the memory and hence to the file underneath. All
                      queries are done against the memory
                      representation.</para>

                      <para>The file sample.tc.text in the etc directory
                      contains an example</para>

                      <para>Here is a sample textual format for transfomation
                      catalog containing one transformation on two
                      sites</para>

                      <para><screen>
tr example::keg:1.0 {
#specify profiles that apply for all the sites for the transformation
#in each site entry the profile can be overriden
profile env "APP_HOME" "/tmp/karan"
profile env "JAVA_HOME" "/bin/app"
site isi {
profile env "me" "with"
profile condor "more" "test"
profile env "JAVA_HOME" "/bin/java.1.6"
pfn "/path/to/keg"
arch  "x86"
os    "linux"
osrelease "fc"
osversion "4"
type "INSTALLED"
site wind {
profile env "me" "with"
profile condor "more" "test"
pfn "/path/to/keg"
arch  "x86"
os    "linux"
osrelease "fc"
osversion "4"
type "STAGEABLE"
</screen></para>
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold"><emphasis role="bold">Property Key: </emphasis></emphasis></emphasis>pegasus.catalog.transformation<emphasis
                    role="bold"><emphasis role="bold">
Profile Key : </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> $PWD/tc.txt</literallayout></entry>

              <entry>The path to the transformation catalog file, that
              describes the locations of the executables.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>

    <section id="replica_sel_props">
      <title>Replica Selection Properties</title>

      <para><table>
          <title>Replica Selection Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes</emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.selector.replica<emphasis
                      role="bold">
Profile  Key: </emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> Default
<emphasis role="bold">See Also    :</emphasis> pegasus.selector.replica.*.ignore.stagein.sites<emphasis
                      role="bold">
See Also    :</emphasis> pegasus.selector.replica.*.prefer.stagein.sites
</literallayout></entry>

                <entry><para>Each job in the DAX maybe associated with input
                LFN's denoting the files that are required for the job to run.
                To determine the physical replica (PFN) for a LFN, Pegasus
                queries the replica catalog to get all the PFN's (replicas)
                associated with a LFN. Pegasus then calls out to a replica
                selector to select a replica amongst the various replicas
                returned. This property determines the replica selector to use
                for selecting the replicas.</para><para><variablelist>
                    <varlistentry>
                      <term>Default</term>

                      <listitem>
                        <para>The selector orders the various candidate
                        replica's according to the following rules</para>

                        <orderedlist>
                          <listitem>
                            <para>valid file URL's . That is URL's that have the
                            site attribute matching the site where the
                            executable <emphasis>pegasus-transfer</emphasis> is
                            executed.</para>
                          </listitem>

                          <listitem>
                            <para>all URL's from preferred site (usually the
                            compute site)</para>
                          </listitem>

                          <listitem>
                            <para>all other remotely accessible ( non file)
                            URL's</para>
                          </listitem>
                        </orderedlist>
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>Regex</term>

                      <listitem>
                        <para>This replica selector allows the user allows the
                        user to specific regular expressions that can be used
                        to rank various PFN's returned from the Replica
                        Catalog for a particular LFN. This replica selector
                        orders the replicas based on the rank. Lower the rank
                        higher the preference.</para>

                        <para>The regular expressions are assigned different
                        rank, that determine the order in which the
                        expressions are employed. The rank values for the
                        regex can expressed in user properties using the
                        property.</para>

                        <para><screen>
pegasus.selector.replica.regex.rank.[value]   regex-expression
</screen></para>

                        <para>The value is an integer value that denotes the
                        rank of an expression with a rank value of 1 being the
                        highest rank.</para>

                        <para>Please note that before applying any regular
                        expressions on the PFN's, the file URL's that dont
                        match the preferred site are explicitly filtered
                        out.</para>
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>Restricted</term>

                      <listitem>
                        <para>This replica selector, allows the user to
                        specify good sites and bad sites for staging in data
                        to a particular compute site. A good site for a
                        compute site X, is a preferred site from which
                        replicas should be staged to site X. If there are more
                        than one good sites having a particular replica, then
                        a random site is selected amongst these preferred
                        sites.</para>

                        <para>A bad site for a compute site X, is a site from
                        which replica's should not be staged. The reason of
                        not accessing replica from a bad site can vary from
                        the link being down, to the user not having
                        permissions on that site's data.</para>

                        <para>The good | bad sites are specified by the
                        properties</para>

                        <para><screen>
pegasus.replica.*.prefer.stagein.sites
pegasus.replica.*.ignore.stagein.sites
</screen></para>

                        <para>where the * in the property name denotes the
                        name of the compute site. A * in the property key is
                        taken to mean all sites.</para>

                        <para>The pegasus.replica.*.prefer.stagein.sites
                        property takes precedence over
                        pegasus.replica.*.ignore.stagein.sites property i.e.
                        if for a site X, a site Y is specified both in the
                        ignored and the preferred set, then site Y is taken to
                        mean as only a preferred site for a site X.</para>
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>Local</term>

                      <listitem>
                         This replica selector prefers replicas from the local host and that start with a file: URL scheme. It is useful, when users want to stagin files to a remote site from your submit host using the Condor file transfer mechanism. 
                      </listitem>
                    </varlistentry>
                  </variablelist></para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.replica.*.ignore.stagein.sites<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> (no default)<emphasis
                      role="bold">
See Also    :</emphasis> pegasus.selector.replica<emphasis role="bold">
See Also    :</emphasis> pegasus.selector.replica.*.prefer.stagein.sites</literallayout></entry>

                <entry><para>A comma separated list of storage sites from
                which to never stage in data to a compute site. The property
                can apply to all or a single compute site, depending on how
                the * in the property name is expanded.</para><para>The * in
                the property name means all compute sites unless replaced by a
                site name.</para><para>For e.g setting
                pegasus.selector.replica.*.ignore.stagein.sites to usc means
                that ignore all replicas from site usc for staging in to any
                compute site. Setting pegasus.replica.isi.ignore.stagein.sites
                to usc means that ignore all replicas from site usc for
                staging in data to site isi.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.replica.*.prefer.stagein.sites<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> (no default)<emphasis
                      role="bold">
See Also    :</emphasis> pegasus.selector.replica<emphasis role="bold">
See Also    :</emphasis> pegasus.selector.replica.*.ignore.stagein.sites</literallayout></entry>

                <entry><para>A comma separated list of preferred storage sites
                from which to stage in data to a compute site. The property
                can apply to all or a single compute site, depending on how
                the * in the property name is expanded.</para><para>The * in
                the property name means all compute sites unless replaced by a
                site name.</para><para>For e.g setting
                pegasus.selector.replica.*.prefer.stagein.sites to usc means
                that prefer all replicas from site usc for staging in to any
                compute site. Setting pegasus.replica.isi.prefer.stagein.sites
                to usc means that prefer all replicas from site usc for
                staging in data to site isi.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.replica.regex.rank.[value]<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3.0
<emphasis role="bold">Default     :</emphasis> (no default)<emphasis
                      role="bold">
See Also    :</emphasis> pegasus.selector.replica</literallayout></entry>

                <entry><para>Specifies the regex expressions to be applied on
                the PFNs returned for a particular LFN. Refer to <screen>
http://java.sun.com/javase/6/docs/api/java/util/regex/Pattern.html
</screen> on information of how to construct a regex
                expression.</para><para>The [value] in the property key is to
                be replaced by an int value that designates the rank value for
                the regex expression to be applied in the Regex replica
                selector.</para><para>The example below indicates preference
                for file URL's over URL's referring to gridftp server at
                example.isi.edu</para><para><screen>
pegasus.selector.replica.regex.rank.1 file://.*
pegasus.selector.replica.regex.rank.2 gsiftp://example\.isi\.edu.*
</screen></para></entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="site_sel_props">
      <title>Site Selection Properties</title>

      <para><table>
          <title>Site Selection Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes</emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.selector.site<emphasis
                      role="bold">
Profile  Key: </emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> Random
<emphasis role="bold">See Also    :</emphasis> pegasus.selector.site.path<emphasis
                      role="bold">
See Also    :</emphasis> pegasus.selector.site.timeout
<emphasis role="bold">See Also    :</emphasis> pegasus.selector.site.keep.tmp<emphasis
                      role="bold">
See Also    : </emphasis>pegasus.selector.site.env.*</literallayout></entry>

                <entry><para>The site selection in Pegasus can be on basis of
                any of the following strategies.</para><para><variablelist>
                    <varlistentry>
                      <term>Random</term>

                      <listitem>
                         In this mode, the jobs will be randomly distributed among the sites that can execute them. 
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>RoundRobin</term>

                      <listitem>
                         In this mode. the jobs will be assigned in a round robin manner amongst the sites that can execute them. Since each site cannot execute everytype of job, the round robin scheduling is done per level on a sorted list. The sorting is on the basis of the number of jobs a particular site has been assigned in that level so far. If a job cannot be run on the first site in the queue (due to no matching entry in the transformation catalog for the transformation referred to by the job), it goes to the next one and so on. This implementation defaults to classic round robin in the case where all the jobs in the workflow can run on all the sites. 
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>NonJavaCallout</term>

                      <listitem>
                        <para>In this mode, Pegasus will callout to an
                        external site selector.In this mode a temporary file
                        is prepared containing the job information that is
                        passed to the site selector as an argument while
                        invoking it. The path to the site selector is
                        specified by setting the property
                        pegasus.site.selector.path. The environment variables
                        that need to be set to run the site selector can be
                        specified using the properties with a
                        pegasus.site.selector.env. prefix. The temporary file
                        contains information about the job that needs to be
                        scheduled. It contains key value pairs with each key
                        value pair being on a new line and separated by a
                        =.</para>

                        <para>The following pairs are currently generated for
                        the site selector temporary file that is generated in
                        the NonJavaCallout.</para>

                        <para><informaltable frame="none">
                            <tgroup align="left" cols="2" colsep="1" rowsep="1">
                              <tbody>
                                <row>
                                  <entry>version</entry>

                                  <entry>is the version of the site selector
                                  api,currently 2.0.</entry>
                                </row>

                                <row>
                                  <entry>transformation</entry>

                                  <entry>is the fully-qualified definition identifier
                                  for the transformation (TR)
                                  namespace::name:version.</entry>
                                </row>

                                <row>
                                  <entry>derivation</entry>

                                  <entry>is teh fully qualified definition identifier
                                  for the derivation (DV),
                                  namespace::name:version.</entry>
                                </row>

                                <row>
                                  <entry>job.level</entry>

                                  <entry>is the job's depth in the tree of the
                                  workflow DAG.</entry>
                                </row>

                                <row>
                                  <entry>job.id</entry>

                                  <entry>is the job's ID, as used in the DAX
                                  file.</entry>
                                </row>

                                <row>
                                  <entry>resource.id</entry>

                                  <entry>is a site handle, followed by whitespace,
                                  followed by a gridftp server. Typically, each
                                  gridftp server is enumerated once, so you may have
                                  multiple occurances of the same site. There can be
                                  multiple occurances of this key.</entry>
                                </row>

                                <row>
                                  <entry>input.lfn</entry>

                                  <entry>is an input LFN, optionally followed by a
                                  whitespace and file size. There can be multiple
                                  occurances of this key,one for each input LFN
                                  required by the job.</entry>
                                </row>

                                <row>
                                  <entry>wf.name</entry>

                                  <entry>label of the dax, as found in the DAX's root
                                  element. wf.index is the DAX index, that is
                                  incremented for each partition in case of deferred
                                  planning.</entry>
                                </row>

                                <row>
                                  <entry>wf.time</entry>

                                  <entry>is the mtime of the workflow.</entry>
                                </row>

                                <row>
                                  <entry>wf.manager</entry>

                                  <entry>is the name of the workflow manager being
                                  used .e.g condor</entry>
                                </row>

                                <row>
                                  <entry>vo.name</entry>

                                  <entry>is the name of the virtual organization that
                                  is running this workflow. It is currently set to
                                  NONE</entry>
                                </row>

                                <row>
                                  <entry>vo.group</entry>

                                  <entry>unused at present and is set to NONE.</entry>
                                </row>

                                <row>
                                  <entry/>
                                </row>
                              </tbody>
                            </tgroup>
                          </informaltable></para>
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>Group</term>

                      <listitem>
                         In this mode, a group of jobs will be assigned to the same site that can execute them. The use of the PEGASUS profile key group in the dax, associates a job with a particular group. The jobs that do not have the profile key associated with them, will be put in the default group. The jobs in the default group are handed over to the "Random" Site Selector for scheduling. 
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>Heft</term>

                      <listitem>
                        <para>In this mode, a version of the HEFT processor
                        scheduling algorithm is used to schedule jobs in the
                        workflow to multiple grid sites. The implementation
                        assumes default data communication costs when jobs are
                        not scheduled on to the same site. Later on this may
                        be made more configurable.</para>

                        <para>The runtime for the jobs is specified in the
                        transformation catalog by associating the pegasus
                        profile key runtime with the entries.</para>

                        <para>The number of processors in a site is picked up
                        from the attribute idle-nodes associated with the
                        vanilla jobmanager of the site in the site
                        catalog.</para>
                      </listitem>
                    </varlistentry>
                  </variablelist></para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.site.path<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

                <entry>If one calls out to an external site selector using the
                NonJavaCallout mode, this refers to the path where the site
                selector is installed. In case other strategies are used it
                does not need to be set.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.site.env.*<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

                <entry><para>The environment variables that need to be set
                while callout to the site selector. These are the variables
                that the user would set if running the site selector on the
                command line. The name of the environment variable is got by
                stripping the keys of the prefix "pegasus.site.selector.env."
                prefix from them. The value of the environment variable is the
                value of the property.</para><para>e.g
                pegasus.site.selector.path.LD_LIBRARY_PATH /globus/lib would
                lead to the site selector being called with the
                LD_LIBRARY_PATH set to /globus/lib.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.site.timeout<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3.0
<emphasis role="bold">Default     :</emphasis> 60<emphasis role="bold">
See Also    :</emphasis> pegasus.selector.site</literallayout></entry>

                <entry>It sets the number of seconds Pegasus waits to hear
                back from an external site selector using the NonJavaCallout
                interface before timing out.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.selector.site.keep.tmp<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3.0
<emphasis role="bold">Values</emphasis>      : onerror|always|never
<emphasis role="bold">Default     :</emphasis> onerror<emphasis role="bold">
See Also    :</emphasis> pegasus.selector.site</literallayout></entry>

                <entry><para>It determines whether Pegasus deletes the
                temporary input files that are generated in the temp directory
                or not. These temporary input files are passed as input to the
                external site selectors.</para><para>A temporary input file is
                created for each that needs to be scheduled.</para></entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="data_conf_props">
      <title>Data Staging Configuration Properties</title>

      <para><table>
          <title>Data Configuration Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes</emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.data.configuration<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>data.configuration<emphasis role="bold">
Scope       :</emphasis> Properties, Site Catalog
<emphasis role="bold">Since       :</emphasis> 4.0.0
<emphasis role="bold">Values</emphasis>      : sharedfs|nonsharedfs|condorio
<emphasis role="bold">Default     :</emphasis> sharedfs<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.bypass.input.staging</literallayout></entry>

                <entry><para>This property sets up Pegasus to run in different
                environments. For Pegasus 4.5.0 and above, users can set the
                pegasus profile data.configuration with the sites in their
                site catalog, to run multisite workflows with each site having
                a different data configuration.</para><para><variablelist>
                    <varlistentry>
                      <term>sharedfs</term>

                      <listitem>
                         If this is set, Pegasus will be setup to execute jobs on the shared filesystem on the execution site. This assumes, that the head node of a cluster and the worker nodes share a filesystem. The staging site in this case is the same as the execution site. Pegasus adds a create dir job to the executable workflow that creates a workflow specific directory on the shared filesystem . The data transfer jobs in the executable workflow ( stage_in_ , stage_inter_ , stage_out_ ) transfer the data to this directory.The compute jobs in the executable workflow are launched in the directory on the shared filesystem. 
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>condorio</term>

                      <listitem>
                         If this is set, Pegasus will be setup to run jobs in a pure condor pool, with the nodes not sharing a filesystem. Data is staged to the compute nodes from the submit host using Condor File IO. The planner is automatically setup to use the submit host ( site local ) as the staging site. All the auxillary jobs added by the planner to the executable workflow ( create dir, data stagein and stage-out, cleanup ) jobs refer to the workflow specific directory on the local site. The data transfer jobs in the executable workflow ( stage_in_ , stage_inter_ , stage_out_ ) transfer the data to this directory. When the compute jobs start, the input data for each job is shipped from the workflow specific directory on the submit host to compute/worker node using Condor file IO. The output data for each job is similarly shipped back to the submit host from the compute/worker node. This setup is particularly helpful when running workflows in the cloud environment where setting up a shared filesystem across the VM's may be tricky. 

                        <screen>pegasus.gridstart                    PegasusLite
pegasus.transfer.worker.package      true
</screen>

                         
                      </listitem>
                    </varlistentry>

                    <varlistentry>
                      <term>nonsharedfs</term>

                      <listitem>
                         If this is set, Pegasus will be setup to execute jobs on an execution site without relying on a shared filesystem between the head node and the worker nodes. You can specify staging site ( using --staging-site option to pegasus-plan) to indicate the site to use as a central storage location for a workflow. The staging site is independant of the execution sites on which a workflow executes. All the auxillary jobs added by the planner to the executable workflow ( create dir, data stagein and stage-out, cleanup ) jobs refer to the workflow specific directory on the staging site. The data transfer jobs in the executable workflow ( stage_in_ , stage_inter_ , stage_out_ ) transfer the data to this directory. When the compute jobs start, the input data for each job is shipped from the workflow specific directory on the submit host to compute/worker node using pegasus-transfer. The output data for each job is similarly shipped back to the submit host from the compute/worker node. The protocols supported are at this time SRM, GridFTP, iRods, S3. This setup is particularly helpful when running workflows on OSG where most of the execution sites don't have enough data storage. Only a few sites have large amounts of data storage exposed that can be used to place data during a workflow run. This setup is also helpful when running workflows in the cloud environment where setting up a shared filesystem across the VM's may be tricky. On loading this property, internally the following properies are set 

                        <screen>pegasus.gridstart                    PegasusLite
pegasus.transfer.worker.package      true
</screen>

                         
                      </listitem>
                    </varlistentry>
                  </variablelist></para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.bypass.input.staging<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.3.0
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false<emphasis role="bold">
See Also    :</emphasis> pegasus.data.configuration</literallayout></entry>

                <entry><para>When executiing in a non shared filesystem setup
                i.e data configuration set to nonsharedfs or condorio, Pegasus
                always stages the input files through the staging site i.e the
                stage-in job stages in data from the input site to the staging
                site. The PegasusLite jobs that start up on the worker nodes,
                then pull the input data from the staging site for each
                job.</para><para>This property can be used to setup the
                PegasusLite jobs to pull input data directly from the input
                site without going through the staging server. This is based
                on the assumption that the worker nodes can access the input
                site. If users set this to true, they should be aware that the
                access to the input site is no longer throttled ( as in case
                of stage in jobs). If large number of compute jobs start at
                the same time in a workflow, the input server will see a
                connection from each job.</para></entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="transfer_props">
      <title>Transfer Configuration Properties</title>

      <para><table>
          <title>Transfer Configuration Properties</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry><emphasis role="bold">Key Attributes</emphasis></entry>

                <entry><emphasis role="bold">Description</emphasis></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.*.impl<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Values</emphasis>      : Transfer|GUC
<emphasis role="bold">Default     :</emphasis> Transfer<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.refiner</literallayout></entry>

                <entrytbl cols="1">
                  <tbody>
                    <row>
                      <entry><para>Each compute job usually has data products
                      that are required to be staged in to the execution site,
                      materialized data products staged out to a final resting
                      place, or staged to another job running at a different
                      site. This property determines the underlying grid
                      transfer tool that is used to manage the
                      transfers.</para><para>The * in the property name can be
                      replaced to achieve finer grained control to dictate
                      what type of transfer jobs need to be managed with which
                      grid transfer tool.</para><para>Usually,the arguments
                      with which the client is invoked can be specified by
                      <screen>
- the property pegasus.transfer.arguments
- associating the PEGASUS profile key transfer.arguments
</screen></para><para>The table below illustrates all the possible variations
                      of the property.</para><para><informaltable frame="none">
                          <tgroup align="left" cols="2" colsep="1" rowsep="1">
                            <tbody>
                              <row>
                                <entry>Property Name</entry>

                                <entry>Applies to</entry>
                              </row>

                              <row>
                                <entry>pegasus.transfer.stagein.impl</entry>

                                <entry>the stage in transfer jobs</entry>
                              </row>

                              <row>
                                <entry>pegasus.transfer.stageout.impl</entry>

                                <entry>the stage out transfer jobs</entry>
                              </row>

                              <row>
                                <entry>pegasus.transfer.inter.impl</entry>

                                <entry>the inter site transfer jobs</entry>
                              </row>

                              <row>
                                <entry>pegasus.transfer.setup.impl</entry>

                                <entry>the setup transfer job</entry>
                              </row>

                              <row>
                                <entry>pegasus.transfer.*.impl</entry>

                                <entry>apply to types of transfer jobs</entry>
                              </row>

                              <row>
                                <entry/>
                              </row>
                            </tbody>
                          </tgroup>
                        </informaltable></para><para>Note: Since version 2.2.0
                      the worker package is staged automatically during
                      staging of executables to the remote site. This is
                      achieved by adding a setup transfer job to the workflow.
                      The setup transfer job by default uses GUC to stage the
                      data. The implementation to use can be configured by
                      setting the property <screen>pegasus.transfer.setup.impl </screen>property.
                      However, if you have pegasus.transfer.*.impl set in your
                      properties file, then you need to set
                      pegasus.transfer.setup.impl to GUC</para><para>The
                      various grid transfer tools that can be used to manage
                      data transfers are explained
                      below</para><para><variablelist>
                          <varlistentry>
                            <term>Transfer</term>

                            <listitem>
                              <para>This results in pegasus-transfer to be used
                              for transferring of files. It is a python based
                              wrapper around various transfer clients like
                              globus-url-copy, lcg-copy, wget, cp, ln .
                              pegasus-transfer looks at source and destination url
                              and figures out automatically which underlying
                              client to use. pegasus-transfer is distributed with
                              the PEGASUS and can be found at
                              $PEGASUS_HOME/bin/pegasus-transfer.</para>

                              <para>For remote sites, Pegasus constructs the
                              default path to pegasus-transfer on the basis of
                              PEGASUS_HOME env profile specified in the site
                              catalog. To specify a different path to the
                              pegasus-transfer client , users can add an entry
                              into the transformation catalog with fully qualified
                              logical name as pegasus::pegasus-transfer</para>
                            </listitem>
                          </varlistentry>

                          <varlistentry>
                            <term>GUC</term>

                            <listitem>
                               This refers to the new guc client that does multiple file transfers per invocation. The globus-url-copy client distributed with Globus 4.x is compatible with this mode. 
                            </listitem>
                          </varlistentry>
                        </variablelist></para></entry>
                    </row>
                  </tbody>
                </entrytbl>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.arguments<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>transfer.arguments<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>String<emphasis role="bold">
Default     :</emphasis> (no default)<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.lite.arguments</literallayout></entry>

                <entry><para>This determines the extra arguments with which
                the transfer implementation is invoked. The transfer
                executable that is invoked is dependant upon the transfer mode
                that has been selected. The property can be overloaded by
                associated the pegasus profile key transfer.arguments either
                with the site in the site catalog or the corresponding
                transfer executable in the transformation
                catalog.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.threads<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>transfer.threads<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.4.0
<emphasis role="bold">Type        : </emphasis>Integer<emphasis role="bold">
Default     :</emphasis> 2</literallayout></entry>

                <entry><para>This property set the number of threads
                pegasus-transfer uses to transfer the files. This property to
                applies to the separate data transfer nodes that are added by
                Pegasus to the executable workflow. The property can be
                overloaded by associated the pegasus profile key
                transfer.threads either with the site in the site catalog or
                the corresponding transfer executable in the transformation
                catalog.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.lite.arguments<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>transfer.lite.arguments<emphasis
                      role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.4.0
<emphasis role="bold">Type        : </emphasis>String<emphasis role="bold">
Default     :</emphasis> (no default)<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.arguments</literallayout></entry>

                <entry>This determines the extra arguments with which the
                PegasusLite transfer implementation is invoked. The transfer
                executable that is invoked is dependant upon the PegasusLite
                transfer implementation that has been selected.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.worker.package<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>Boolean<emphasis role="bold">
Default     :</emphasis> false<emphasis role="bold">
See Also    :</emphasis> pegasus.data.configuration</literallayout></entry>

                <entry><para>By default, Pegasus relies on the worker package
                to be installed in a directory accessible to the worker nodes
                on the remote sites . Pegasus uses the value of PEGASUS_HOME
                environment profile in the site catalog for the remote sites,
                to then construct paths to pegasus auxillary executables like
                kickstart, pegasus-transfer, seqexec etc.</para><para>If the
                Pegasus worker package is not installed on the remote sites
                users can set this property to true to get Pegasus to deploy
                worker package on the nodes.</para><para>In the case of
                sharedfs setup, the worker package is deployed on the shared
                scratch directory for the workflow , that is accessible to all
                the compute nodes of the remote sites.</para><para>When
                running in nonsharefs environments, the worker package is
                first brought to the submit directory and then transferred to
                the worker node filesystem using Condor file
                IO.</para></entry>
              </row>

              <row>
                <entry><literallayout><anchor id="pegasus.transfer.worker.package.autodownload"/>
                      <emphasis role="bold"><emphasis role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.worker.package.autodownload<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.6.1
<emphasis role="bold">Type        : </emphasis>Boolean<emphasis role="bold">
Default     :</emphasis> true<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.worker.package</literallayout></entry>

                <entry>If PegasusLite does not find a worker package install
                matching the pegasus lite job on the worker node, it
                automatically downloads the correct worker package from the
                Pegasus website. However, this can mask user errors in
                configuration. This property can be set to false to disable
                auto downloads.</entry>
              </row>

              <row>
                <entry><literallayout><anchor id="pegasus.transfer.worker.package.strict"/><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.worker.package.strict<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.6.1
<emphasis role="bold">Type        : </emphasis>Boolean<emphasis role="bold">
Default     :</emphasis> true<emphasis role="bold">
See Also    :</emphasis> pegasus.transfer.worker.package</literallayout></entry>

                <entry><para>In PegasusLite mode, the pegasus worker package
                for the jobs is shipped along with the jobs. This property
                controls whether PegasusLite will do a strict match against
                the architecture and os on the local worker node, along with
                pegasus version. If the strict match fails, then PegasusLite
                will revert to the pegasus website to download the correct
                worker package.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.links<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>Boolean<emphasis role="bold">
Default     :</emphasis> false<emphasis role="bold">
</emphasis></literallayout></entry>

                <entry>If this is set, and the transfer implementation is set
                to Transfer i.e. using the transfer executable distributed
                with the PEGASUS. On setting this property, if Pegasus while
                fetching data from the Replica Catalog sees a "site" attribute
                associated with the PFN that matches the execution site on
                which the data has to be transferred to, Pegasus instead of
                the URL returned by the Replica Catalog replaces it with a
                file based URL. This is based on the assumption that the if
                the "site" attributes match, the filesystems are visible to
                the remote execution directory where input data resides. On
                seeing both the source and destination urls as file based URLs
                the transfer executable spawns a job that creates a symbolic
                link by calling ln -s on the remote site.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.*.remote.sites<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>comma separated list of sites<emphasis
                      role="bold">
Default     :</emphasis> (no default)<emphasis role="bold">
</emphasis></literallayout></entry>

                <entry><para>By default Pegasus looks at the source and
                destination URL's for to determine whether the associated
                transfer job runs on the submit host or the head node of a
                remote site, with preference set to run a transfer job to run
                on submit host.</para><para>Pegasus will run transfer jobs on
                the remote sites</para><para><screen>
-  if the file server for the compute site is a file server i.e url prefix file://
-  symlink jobs need to be added that require the symlink transfer jobs to
be run remotely.
</screen></para><para>This property can be used to change the default
                behaviour of Pegasus and force pegasus to run different types
                of transfer jobs for the sites specified on the remote
                site.</para><para>The table below illustrates all the possible
                variations of the property.</para><para><informaltable
                    frame="none">
                    <tgroup align="left" cols="2" colsep="1" rowsep="1">
                      <tbody>
                        <row>
                          <entry>Property Name</entry>

                          <entry>Applies to</entry>
                        </row>

                        <row>
                          <entry>pegasus.transfer.stagein.remote.sites</entry>

                          <entry>the stage in transfer jobs</entry>
                        </row>

                        <row>
                          <entry>pegasus.transfer.stageout.remote.sites</entry>

                          <entry>the stage out transfer jobs</entry>
                        </row>

                        <row>
                          <entry>pegasus.transfer.inter.remote.sites</entry>

                          <entry>the inter site transfer jobs</entry>
                        </row>

                        <row>
                          <entry>pegasus.transfer.*.remote.sites</entry>

                          <entry>apply to types of transfer jobs</entry>
                        </row>

                        <row>
                          <entry/>
                        </row>
                      </tbody>
                    </tgroup>
                  </informaltable></para><para>In addition * can be specified
                as a property value, to designate that it applies to all
                sites.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.staging.delimiter<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>String<emphasis role="bold">
Default     :</emphasis> :<emphasis role="bold">
</emphasis></literallayout></entry>

                <entry>Pegasus supports executable staging as part of the
                workflow. Currently staging of statically linked executables
                is supported only. An executable is normally staged to the
                work directory for the workflow/partition on the remote site.
                The basename of the staged executable is derived from the
                namespace,name and version of the transformation in the
                transformation catalog. This property sets the delimiter that
                is used for the construction of the name of the staged
                executable.</entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.disable.chmod.sites<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>comma separated list of sites<emphasis
                      role="bold">
Default     :</emphasis> (no default)<emphasis role="bold">
</emphasis></literallayout></entry>

                <entry><para>During staging of executables to remote sites,
                chmod jobs are added to the workflow. These jobs run on the
                remote sites and do a chmod on the staged executable. For some
                sites, this maynot be required. The permissions might be
                preserved, or there maybe an automatic mechanism that does
                it.</para><para>This property allows you to specify the list
                of sites, where you do not want the chmod jobs to be executed.
                For those sites, the chmod jobs are replaced by NoOP jobs. The
                NoOP jobs are executed by Condor, and instead will immediately
                have a terminate event written to the job log file and removed
                from the queue.</para></entry>
              </row>

              <row>
                <entry><literallayout><emphasis role="bold"><emphasis
                        role="bold">Property Key: </emphasis></emphasis>pegasus.transfer.setup.source.base.url<emphasis
                      role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0.0
<emphasis role="bold">Type        : </emphasis>URL
<emphasis role="bold">Default     :</emphasis> (no default)<emphasis
                      role="bold">
</emphasis></literallayout></entry>

                <entry>This property specifies the base URL to the directory
                containing the Pegasus worker package builds. During Staging
                of Executable, the Pegasus Worker Package is also staged to
                the remote site. The worker packages are by default pulled
                from the http server at pegasus.isi.edu. This property can be
                used to override the location from where the worker package
                are staged. This maybe required if the remote computes sites
                don't allows files transfers from a http server.</entry>
              </row>
            </tbody>
          </tgroup>
        </table></para>
    </section>

    <section id="monitoring_props">
      <title>Monitoring Properties</title>

      <table>
        <title>Monitoring Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.events<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.0.2
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> true<emphasis role="bold">
See Also    : </emphasis>pegasus.catalog.workflow.url</literallayout></entry>

              <entry>This property determines whether pegasus-monitord
              generates log events. If log events are disabled using this
              property, no bp file, or database will be created, even if the
              pegasus.monitord.output property is specified.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.workflow.url<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> SQlite database in submit
              directory.
<emphasis role="bold">See Also    :</emphasis> pegasus.monitord.events</literallayout></entry>

              <entry><para>This property specifies the destination for
              generated log events in pegasus-monitord. By default, events are
              stored in a sqlite database in the workflow directory, which
              will be created with the workflow's name, and a ".stampede.db"
              extension. Users can specify an alternative database by using a
              SQLAlchemy connection string. Details are available at: <screen>
http://www.sqlalchemy.org/docs/05/reference/dialects/index.html
</screen> It is important to note that users will need to have the appropriate
              db interface library installed. Which is to say, SQLAlchemy is a
              wrapper around the mysql interface library (for instance), it
              does not provide a MySQL driver itself. The Pegasus distribution
              includes both SQLAlchemy and the SQLite Python driver. As a
              final note, it is important to mention that unlike when using
              SQLite databases, using SQLAlchemy with other database servers,
              e.g. MySQL or Postgres , the target database needs to exist.
              Users can also specify a file name using this property in order
              to create a file with the log events.</para><para>Example values
              for the SQLAlchemy connection string for various end points are
              listed below</para><para><informaltable frame="none">
                  <tgroup align="left" cols="2" colsep="1" rowsep="1">
                    <tbody>
                      <row>
                        <entry>SQL Alchemy End Point</entry>

                        <entry>Example Value</entry>
                      </row>

                      <row>
                        <entry>Netlogger BP File</entry>

                        <entry>file:///submit/dir/myworkflow.bp</entry>
                      </row>

                      <row>
                        <entry>SQL Lite Database</entry>

                        <entry>sqlite:///submit/dir/myworkflow.db</entry>
                      </row>

                      <row>
                        <entry>MySQL Database</entry>

                        <entry>mysql://user:password@host:port/databasename</entry>
                      </row>

                      <row>
                        <entry/>
                      </row>
                    </tbody>
                  </tgroup>
                </informaltable></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.master.url<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> sqlite database in $HOME/.pegasus/workflow.db<emphasis
                    role="bold">
See Also    :</emphasis> pegasus.catalog.workflow.url</literallayout></entry>

              <entry><para>This property specifies the destination for the
              workflow dashboard database. By default, the workflow dashboard
              datbase defaults to a sqlite database named workflow.db in the
              $HOME/.pegasus directory. This is database is shared for all
              workflows run as a particular user. Users can specify an
              alternative database by using a SQLAlchemy connection string.
              Details are available at: <screen>
http://www.sqlalchemy.org/docs/05/reference/dialects/index.html
</screen> It is important to note that users will need to have the appropriate
              db interface library installed. Which is to say, SQLAlchemy is a
              wrapper around the mysql interface library (for instance), it
              does not provide a MySQL driver itself. The Pegasus distribution
              includes both SQLAlchemy and the SQLite Python driver. As a
              final note, it is important to mention that unlike when using
              SQLite databases, using SQLAlchemy with other database servers,
              e.g. MySQL or Postgres , the target database needs to exist.
              Users can also specify a file name using this property in order
              to create a file with the log events.</para><para>Example values
              for the SQLAlchemy connection string for various end points are
              listed below</para><para><informaltable frame="none">
                  <tgroup align="left" cols="2" colsep="1" rowsep="1">
                    <tbody>
                      <row>
                        <entry>SQL Alchemy End Point</entry>

                        <entry>Example Value</entry>
                      </row>

                      <row>
                        <entry>SQL Lite Database</entry>

                        <entry>sqlite:///shared/myworkflow.db</entry>
                      </row>

                      <row>
                        <entry>MySQL Database</entry>

                        <entry>mysql://user:password@host:port/databasename</entry>
                      </row>

                      <row>
                        <entry/>
                      </row>
                    </tbody>
                  </tgroup>
                </informaltable></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.output<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.0.2
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> SQlite database in submit
              directory.
<emphasis role="bold">See Also    :</emphasis> pegasus.monitord.events</literallayout></entry>

              <entry><para>This property has been deprecated in favore of
              pegasus.catalog.workflow.url that introduced in 4.5 release.
              Support for this property will be dropped in future releases.
              </para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.dashboard.output<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.2
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> sqlite database in $HOME/.pegasus/workflow.db<emphasis
                    role="bold">
See Also    :</emphasis> pegasus.monitord.output</literallayout></entry>

              <entry><para>This property has been deprecated in favore of
              pegasus.catalog.master.url that introduced in 4.5 release.
              Support for this property will be dropped in future releases.
              </para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.notifications<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.1.0
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> true<emphasis role="bold">
See Also    :</emphasis> pegasus.monitord.notifications.max<emphasis
                    role="bold">
See Also    :</emphasis> pegasus.monitord.notifications.timeout</literallayout></entry>

              <entry>This property determines how many notification scripts
              pegasus-monitord will call concurrently. Upon reaching this
              limit, pegasus-monitord will wait for one notification script to
              finish before issuing another one. This is a way to keep the
              number of processes under control at the submit host. Setting
              this property to 0 will disable notifications
              completely.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.notifications.max<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.1.0
<emphasis role="bold">Type        : </emphasis>Integer
<emphasis role="bold">Default     :</emphasis> 10<emphasis role="bold">
See Also    :</emphasis> pegasus.monitord.notifications <emphasis role="bold">
See Also    :</emphasis> pegasus.monitord.notifications.timeout</literallayout></entry>

              <entry>This property determines whether pegasus-monitord
              processes notifications. When notifications are enabled,
              pegasus-monitord will parse the .notify file generated by
              pegasus-plan and will invoke notification scripts whenever
              conditions matches one of the notifications.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.notifications.timeout<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.1.0
<emphasis role="bold">Type        : </emphasis>Integer
<emphasis role="bold">Default     :</emphasis> true<emphasis role="bold">
See Also    :</emphasis> pegasus.monitord.notifications.<emphasis role="bold">
See Also    :</emphasis> pegasus.monitord.notifications.max</literallayout></entry>

              <entry>This property determines how long will pegasus-monitord
              let notification scripts run before terminating them. When this
              property is set to 0 (default), pegasus-monitord will not
              terminate any notification scripts, letting them run
              indefinitely. If some notification scripts missbehave, this has
              the potential problem of starving pegasus-monitord's
              notification slots (see the pegasus.monitord.notifications.max
              property), and block further notifications. In addition, users
              should be aware that pegasus-monitord will not exit until all
              notification scripts are finished.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.stdout.disable.parsing<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.1.1
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false</literallayout></entry>

              <entry>By default, pegasus-monitord parses the stdout/stderr
              section of the kickstart to populate the applications captured
              stdout and stderr in the job instance table for the stampede
              schema. For large workflows, this may slow down monitord
              especially if the application is generating a lot of output to
              it's stdout and stderr. This property, can be used to turn of
              the database population.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.monitord.arguments<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.6
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> N/A</literallayout></entry>

              <entry>This property specifies additional command-line arguments
              that should be passed to pegasus-monitord at startup. These
              additional arguments are appended to the arguments given to
              pegasus-monitord.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para/>
    </section>

    <section id="job_clustering_props">
      <title>Job Clustering Properties</title>

      <table>
        <title>Job Clustering Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusterer.job.aggregator<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Values</emphasis>      : seqexec|mpiexec
<emphasis role="bold">Default     :</emphasis> seqexec</literallayout></entry>

              <entry><para>A large number of workflows executed through the
              Virtual Data System, are composed of several jobs that run for
              only a few seconds or so. The overhead of running any job on the
              grid is usually 60 seconds or more. Hence, it makes sense to
              collapse small independent jobs into a larger job. This property
              determines, the executable that will be used for running the
              larger job on the remote site.</para><para><variablelist>
                  <varlistentry>
                    <term>seqexec</term>

                    <listitem>
                       In this mode, the executable used to run the merged job is "pegasus-cluster" that runs each of the smaller jobs sequentially on the same node. The executable "pegasus-cluster" is a PEGASUS tool distributed in the PEGASUS worker package, and can be usually found at {pegasus.home}/bin/seqexec. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>mpiexec</term>

                    <listitem>
                       In this mode, the executable used to run the merged job is "pegasus-mpi-cluster" (PMC) that runs the smaller jobs via mpi on n nodes where n is the nodecount associated with the merged job. The executable "pegasus-mpi-cluster" is a PEGASUS tool distributed in the PEGASUS distribution and is built only if mpi compiler is available. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusterer.job.aggregator.seqexec.log<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false<emphasis role="bold">
See Also    :</emphasis> pegasus.clusterer.job.aggregator<emphasis role="bold">
See Also    :</emphasis> pegasus.clusterer.job.aggregator.seqexec.log.global</literallayout></entry>

              <entry><para>The tool pegasus-cluster logs the progress of the
              jobs that are being run by it in a progress file on the remote
              cluster where it is executed.</para><para>This property sets the
              Boolean flag, that indicates whether to turn on the logging or
              not.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusterer.job.aggregator.seqexec.log<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false<emphasis role="bold">
See Also    :</emphasis> pegasus.clusterer.job.aggregator<emphasis role="bold">
See Also    :</emphasis> pegasus.clusterer.job.aggregator.seqexec.log.global</literallayout></entry>

              <entry><para>The tool pegasus-cluster logs the progress of the
              jobs that are being run by it in a progress file on the remote
              cluster where it is executed. The progress log is useful for you
              to track the progress of your computations and remote grid
              debugging. The progress log file can be shared by multiple
              pegasus-cluster jobs that are running on a particular cluster as
              part of the same workflow. Or it can be per
              job.</para><para>This property sets the Boolean flag, that
              indicates whether to have a single global log for all the
              pegasus-cluster jobs on a particular cluster or progress log per
              job.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusterer.job.aggregator.seqexec.firstjobfail<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> true<emphasis role="bold">
See Also    :</emphasis> pegasus.clusterer.job.aggregator</literallayout></entry>

              <entry><para>By default "pegasus-cluster" does not stop
              execution even if one of the clustered jobs it is executing
              fails. This is because "pegasus-cluster" tries to get as much
              work done as possible.</para><para>This property sets the
              Boolean flag, that indicates whether to make "pegasus-cluster"
              stop on the first job failure it detects.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.clusterer.label.key<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Default     :</emphasis> label
</literallayout></entry>

              <entrytbl cols="1">
                <tbody>
                  <row>
                    <entry><para>While clustering jobs in the workflow into
                    larger jobs, you can optionally label your graph to
                    control which jobs are clustered and to which clustered
                    job they belong. This done using a label based clustering
                    scheme and is done by associating a profile/label key in
                    the PEGASUS namespace with the jobs in the DAX. Each job
                    that has the same value/label value for this profile key,
                    is put in the same clustered job.</para><para>This
                    property allows you to specify the PEGASUS profile key
                    that you want to use for label based
                    clustering.</para></entry>
                  </row>
                </tbody>
              </entrytbl>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para/>
    </section>

    <section id="logging_props">
      <title>Logging Properties</title>

      <table>
        <title>Logging Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.log.manager<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2.0
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Values</emphasis>      : Default|Log4J
<emphasis role="bold">Default     :</emphasis> Default<emphasis role="bold">
See Also    :</emphasis>pegasus.log.manager.formatter</literallayout></entry>

              <entry><para>This property sets the logging implementation to
              use for logging.</para><para><variablelist>
                  <varlistentry>
                    <term>Default</term>

                    <listitem>
                       This implementation refers to the legacy Pegasus logger, that logs directly to stdout and stderr. It however, does have the concept of levels similar to log4j or syslog. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Log4j</term>

                    <listitem>
                       This implementation, uses Log4j to log messages. The log4j properties can be specified in a properties file, the location of which is specified by the property 

                      <screen>
pegasus.log.manager.log4j.conf
</screen>

                       
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.log.manager.formatter<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2.0
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Values</emphasis>      : Simple|Netlogger
<emphasis role="bold">Default     :</emphasis> Simple<emphasis role="bold">
See Also    :</emphasis>pegasus.log.manager</literallayout></entry>

              <entrytbl cols="1">
                <tbody>
                  <row>
                    <entry><para>This property sets the formatter to use for
                    formatting the log messages while
                    logging.</para><para><variablelist>
                        <varlistentry>
                          <term>Simple</term>

                          <listitem>
                             This formats the messages in a simple format. The messages are logged as is with minimal formatting. Below are sample log messages in this format while ranking a dax according to performance. 

                            <screen>
event.pegasus.ranking dax.id se18-gda.dax  - STARTED
event.pegasus.parsing.dax dax.id se18-gda-nested.dax  - STARTED
event.pegasus.parsing.dax dax.id se18-gda-nested.dax  - FINISHED
job.id jobGDA
job.id jobGDA query.name getpredicted performace time 10.00
event.pegasus.ranking dax.id se18-gda.dax  - FINISHED
</screen>

                             
                          </listitem>
                        </varlistentry>

                        <varlistentry>
                          <term>Netlogger</term>

                          <listitem>
                            <para>This formats the messages in the Netlogger
                            format , that is based on key value pairs. The
                            netlogger format is useful for loading the logs into
                            a database to do some meaningful analysis. Below are
                            sample log messages in this format while ranking a
                            dax according to performance. <screen>
ts=2008-09-06T12:26:20.100502Z event=event.pegasus.ranking.start \
msgid=6bc49c1f-112e-4cdb-af54-3e0afb5d593c \
eventId=event.pegasus.ranking_8d7c0a3c-9271-4c9c-a0f2-1fb57c6394d5 \
dax.id=se18-gda.dax prog=Pegasus
ts=2008-09-06T12:26:20.100750Z event=event.pegasus.parsing.dax.start \
msgid=fed3ebdf-68e6-4711-8224-a16bb1ad2969 \
eventId=event.pegasus.parsing.dax_887134a8-39cb-40f1-b11c-b49def0c5232\
dax.id=se18-gda-nested.dax prog=Pegasus
ts=2008-09-06T12:26:20.100894Z event=event.pegasus.parsing.dax.end \
msgid=a81e92ba-27df-451f-bb2b-b60d232ed1ad \
eventId=event.pegasus.parsing.dax_887134a8-39cb-40f1-b11c-b49def0c5232
ts=2008-09-06T12:26:20.100395Z event=event.pegasus.ranking \
msgid=4dcecb68-74fe-4fd5-aa9e-ea1cee88727d \
eventId=event.pegasus.ranking_8d7c0a3c-9271-4c9c-a0f2-1fb57c6394d5 \
job.id="jobGDA"
ts=2008-09-06T12:26:20.100395Z event=event.pegasus.ranking \
msgid=4dcecb68-74fe-4fd5-aa9e-ea1cee88727d \
eventId=event.pegasus.ranking_8d7c0a3c-9271-4c9c-a0f2-1fb57c6394d5 \
job.id="jobGDA" query.name="getpredicted performace" time="10.00"
ts=2008-09-06T12:26:20.102003Z event=event.pegasus.ranking.end \
msgid=31f50f39-efe2-47fc-9f4c-07121280cd64 \
eventId=event.pegasus.ranking_8d7c0a3c-9271-4c9c-a0f2-1fb57c6394d5
</screen></para>
                          </listitem>
                        </varlistentry>
                      </variablelist></para></entry>
                  </row>
                </tbody>
              </entrytbl>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.log.*<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>file path
<emphasis role="bold">Default     :</emphasis> no default</literallayout></entry>

              <entry>This property sets the path to the file where all the
              logging for Pegasus can be redirected to. Both stdout and stderr
              are logged to the file specified.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.log.memory.usage<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.3.4
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false</literallayout></entry>

              <entry>This property if set to true, will result in the planner
              writing out JVM heap memory statistics at the end of the
              planning process at the INFO level. This is useful, if users
              want to fine tune their java memory settings by setting
              JAVA_HEAPMAX and JAVA_HEAPMIN for large workflows.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.metrics.app<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.3.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> (no default)</literallayout></entry>

              <entry><para>This property namespace allows users to pass
              application level metrics to the metrics server. The value of
              this property is the name of the
              application.</para><para>Additional application specific
              attributes can be passed by using the prefix pegasus.metrics.app
              <screen>
pegasus.metrics.app.[arribute-name]       attribute-value
</screen></para><para>Note: the attribute cannot be named name. This attribute
              is automatically assigned the value from
              pegasus.metrics.app</para></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para/>
    </section>

    <section id="cleanup_props">
      <title>Cleanup Properties</title>

      <table>
        <title>Cleanup Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.file.cleanup.strategy
<emphasis role="bold">Profile  Key: </emphasis>N/A
<emphasis role="bold">Scope       : </emphasis>Properties
<emphasis role="bold">Since       : </emphasis>2.2-
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     : </emphasis>InPlace
                  </literallayout></entry>

              <entry><para>This property is used to select the strategy of how
              the cleanup nodes are added to the executable workflow.</para>
              <para> <variablelist>
                  <varlistentry>
                    <term>InPlace</term>

                    <listitem>
                       The default cleanup strategy. Adds cleanup nodes per level of the workflow. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Constraint</term>

                    <listitem>
                       Adds cleanup nodes to constraint the amount of storage space used by a workflow. 
                    </listitem>
                  </varlistentry>
                </variablelist> </para> <para>Note that this property is
              overridden by the --cleanup option used in
              pegasus-plan.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.file.cleanup.impl<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     :</emphasis> Cleanup</literallayout></entry>

              <entry><para>This property is used to select the executable that
              is used to create the working directory on the compute
              sites.</para><para><variablelist>
                  <varlistentry>
                    <term>Cleanup</term>

                    <listitem>
                       The default executable that is used to delete files is the "pegasus-transfer" executable shipped with Pegasus. It is found at $PEGASUS_HOME/bin/pegasus-transfer in the Pegasus distribution. An entry for transformation pegasus::dirmanager needs to exist in the Transformation Catalog or the PEGASUS_HOME environment variable should be specified in the site catalog for the sites for this mode to work. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>RM</term>

                    <listitem>
                       This mode results in the rm executable to be used to delete files from remote directories. The rm executable is standard on *nix systems and is usually found at /bin/rm location. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.file.cleanup.clusters.num<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.2.0
<emphasis role="bold">Type        : </emphasis>Integer
</literallayout></entry>

              <entry>In case of the InPlace strategy for adding the cleanup
              nodes to the workflow, this property specifies the maximum
              number of cleanup jobs that are added to the executable workflow
              on each level.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.file.cleanup.clusters.size<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.2.0
<emphasis role="bold">Type        : </emphasis>Integer
<emphasis role="bold">Default     :</emphasis> 2</literallayout></entry>

              <entry>In case of the InPlace strategy this property sets the
              number of cleanup jobs that get clustered into a bigger cleanup
              job. This parameter is only used if
              pegasus.file.cleanup.clusters.num is not set.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.file.cleanup.scope<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.3.0
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Value       : </emphasis>fullahead|deferred
<emphasis role="bold">Default     :</emphasis> fullahead</literallayout></entry>

              <entry><para>By default in case of deferred planning InPlace
              file cleanup is turned OFF. This is because the cleanup
              algorithm does not work across partitions. This property can be
              used to turn on the cleanup in case of deferred planning.
              <variablelist>
                  <varlistentry>
                    <term>fullahead</term>

                    <listitem>
                       This is the default scope. The pegasus cleanup algorithm does not work across partitions in deferred planning. Hence the cleanup is always turned OFF , when deferred planning occurs and cleanup scope is set to full ahead. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>deferred</term>

                    <listitem>
                       If the scope is set to deferred, then Pegasus will not disable file cleanup in case of deferred planning. This is useful for scenarios where the partitions themselves are independant ( i.e. dont share files ). Even if the scope is set to deferred, users can turn off cleanup by specifying --nocleanup option to pegasus-plan. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.file.cleanup.constraint.*.maxspace
<emphasis role="bold">Profile  Key: </emphasis>N/A
<emphasis role="bold">Scope       : </emphasis>Properties
<emphasis role="bold">Since       : </emphasis>4.6.0
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     : </emphasis>10737418240
                  </literallayout></entry>

              <entry><para>This property is used to set the maximum avaialble
              space (i.e., constraint) per site in Bytes. The * in the
              property name denotes the name of the compute site. A * in the
              property key is taken to mean all sites.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.file.cleanup.constraint.deferstageins
<emphasis role="bold">Profile  Key: </emphasis>N/A
<emphasis role="bold">Scope       : </emphasis>Properties
<emphasis role="bold">Since       : </emphasis>4.6.0
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     : </emphasis>False
                  </literallayout></entry>

              <entry><para>This property is used to determine whether stage in
              jobs may be deferred. If this property is set to False
              (default), all stage in jobs will be marked as executing on the
              current compute site and will be executed before any task. This
              property has no effect when running in a multi site
              case.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold">Property Key: </emphasis>pegasus.file.cleanup.constraint.csv
<emphasis role="bold">Profile  Key: </emphasis>N/A
<emphasis role="bold">Scope       : </emphasis>Properties
<emphasis role="bold">Since       : </emphasis>4.6.1
<emphasis role="bold">Type        : </emphasis>String
<emphasis role="bold">Default     : </emphasis>(no default)
                  </literallayout></entry>

              <entry><para>This property is used to specify a CSV file with a
              list of LFNs and their respective sizes in Bytes. The CSV file
              must be composed of two columns: <emphasis role="bold">filename
              </emphasis> and <emphasis role="bold">length</emphasis>.
              </para></entry>
            </row>
          </tbody>
        </tgroup>
      </table>

      <para/>
    </section>

    <section id="misc__props">
      <title>Miscellaneous Properties</title>

      <table>
        <title>Miscellaneous Properties</title>

        <tgroup cols="2">
          <tbody>
            <row>
              <entry><emphasis role="bold">Key Attributes</emphasis></entry>

              <entry><emphasis role="bold">Description</emphasis></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.code.generator<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 3.0
<emphasis role="bold">Type  </emphasis>      : String
<emphasis role="bold">Values</emphasis>      : Condor|Shell|PMC
<emphasis role="bold">Default     :</emphasis> Condor<emphasis role="bold">
See Also    :</emphasis> pegasus.log.manager.formatter</literallayout></entry>

              <entry><para>This property is used to load the appropriate Code
              Generator to use for writing out the executable
              workflow.</para><para><variablelist>
                  <varlistentry>
                    <term>Condor</term>

                    <listitem>
                       This is the default code generator for Pegasus . This generator generates the executable workflow as a Condor DAG file and associated job submit files. The Condor DAG file is passed as input to Condor DAGMan for job execution. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Shell</term>

                    <listitem>
                       This Code Generator generates the executable workflow as a shell script that can be executed on the submit host. While using this code generator, all the jobs should be mapped to site local i.e specify --sites local to pegasus-plan. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>PMC</term>

                    <listitem>
                       This Code Generator generates the executable workflow as a PMC task workflow. This is useful to run on platforms where it not feasible to run Condor such as the new XSEDE machines such as Blue Waters. In this mode, Pegasus will generate the executable workflow as a PMC task workflow and a sample PBS submit script that submits this workflow. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.condor.concurrency.limits<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key:</emphasis></emphasis><emphasis role="bold"> </emphasis>N/A<emphasis
                    role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5.3
<emphasis role="bold">Type        : </emphasis>Boolean<emphasis role="bold">
Default     : </emphasis>False</literallayout></entry>

              <entry>This Boolean property is used to determine whether
              Pegasus associates default HTCondor concurrency limits with jobs
              or not. Setting this property to true, allows you to <link
              linkend="job_throttling_across_workflows">throttle</link> jobs
              across workflows, if the workflow are set to run in pure condor
              environment.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.register<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.1.-
<emphasis role="bold">Type  </emphasis>      : Boolean
<emphasis role="bold">Default     :</emphasis> true</literallayout></entry>

              <entry><para>Pegasus creates registration jobs to register the
              output files in the replica catalog. An output file is
              registered only if</para><para>1) a user has configured a
              replica catalog in the properties 2) the register flags for the
              output files in the DAX are set to true</para><para>This
              property can be used to turn off the creation of the
              registration jobs even though the files maybe marked to be
              registered in the replica catalog.</para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.register.deep<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5.3.-
<emphasis role="bold">Type  </emphasis>      : Boolean
<emphasis role="bold">Default     :</emphasis> true</literallayout></entry>

              <entry><para>By default, Pegasus always registers the complete
              LFN that is associated with the output files in the DAX i.e if
              the LFN has / in it, then lfn registered in the replica catalog
              has the whole part. For example, if in your DAX you have
              rupture/0001.rx as the name attribute for the uses tag, then in
              the Replica Catalog the LFN is registered as
              rupture/0001.rx</para><para>On setting this property to false,
              only the basename is considered while registering in the replica
              catalog. In the above case, 0001.rx will be registered instead
              of rupture/0001.rx </para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.data.reuse.scope<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.5.0
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Value       : </emphasis>none|partial|full
<emphasis role="bold">Default     :</emphasis> full</literallayout></entry>

              <entry><para>This property is used to control the behavior of
              the data reuse algorithm in Pegasus</para><para><variablelist>
                  <varlistentry>
                    <term>none</term>

                    <listitem>
                       This is same as disabling data reuse. It is equivalent to passing the --force option to pegasus-plan on the command line. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>partial</term>

                    <listitem>
                       In this case, only certain jobs ( those that have pegasus profile key enable_for_data_reuse set to true ) are checked for presence of output files in the replica catalog. This gives users control over what jobs are deleted as part of the data reuse algorithm. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>full</term>

                    <listitem>
                       This is the default behavior, where all the jobs output files are looked up in the replica catalog. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.catalog.transformation.mapper<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Value       : </emphasis>All|Installed|Staged|Submit
<emphasis role="bold">Default     :</emphasis> All</literallayout></entry>

              <entry><para>Pegasus supports transfer of statically linked
              executables as part of the executable workflow. At present,
              there is only support for staging of executables referred to by
              the compute jobs specified in the DAX file. Pegasus determines
              the source locations of the binaries from the transformation
              catalog, where it searches for entries of type STATIC_BINARY for
              a particular architecture type. The PFN for these entries should
              refer to a globus-url-copy valid and accessible remote URL. For
              transfer of executables, Pegasus constructs a soft state map
              that resides on top of the transformation catalog, that helps in
              determining the locations from where an executable can be staged
              to the remote site.</para><para>This property determines, how
              that map is created. <variablelist>
                  <varlistentry>
                    <term>All</term>

                    <listitem>
                       In this mode, all sources with entries of type STATIC_BINARY for a particular transformation are considered valid sources for the transfer of executables. This the most general mode, and results in the constructing the map as a result of the cartesian product of the matches. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Installed</term>

                    <listitem>
                       In this mode, only entries that are of type INSTALLED are used while constructing the soft state map. This results in Pegasus never doing any transfer of executables as part of the workflow. It always prefers the installed executables at the remote sites. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Staged</term>

                    <listitem>
                       In this mode, only entries that are of type STATIC_BINARY are used while constructing the soft state map. This results in the concrete workflow referring only to the staged executables, irrespective of the fact that the executables are already installed at the remote end. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Submit</term>

                    <listitem>
                       In this mode, only entries that are of type STATIC_BINARY and reside at the submit host ("site" local), are used while constructing the soft state map. This is especially helpful, when the user wants to use the latest compute code for his computations on the grid and that relies on his submit host. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.selector.transformation<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.0
<emphasis role="bold">Type        : </emphasis>Enumeration
<emphasis role="bold">Value       : </emphasis>Random|Installed|Staged|Submit
<emphasis role="bold">Default     :</emphasis> Random</literallayout></entry>

              <entry><para>In case of transfer of executables, Pegasus could
              have various transformations to select from when it schedules to
              run a particular compute job at a remote site. For e.g it can
              have the choice of staging an executable from a particular
              remote site, from the local (submit host) only, use the one that
              is installed on the remote site only.</para><para>This property
              determines, how a transformation amongst the various candidate
              transformations is selected, and is applied after the property
              pegasus.tc has been applied. For e.g specifying pegasus.tc as
              Staged and then pegasus.transformation.selector as INSTALLED
              does not work, as by the time this property is applied, the soft
              state map only has entries of type
              STAGED.</para><para><variablelist>
                  <varlistentry>
                    <term>Random</term>

                    <listitem>
                       In this mode, a random matching candidate transformation is selected to be staged to the remote execution site. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Installed</term>

                    <listitem>
                       In this mode, only entries that are of type INSTALLED are selected. This means that the concrete workflow only refers to the transformations already pre installed on the remote sites. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Staged</term>

                    <listitem>
                       In this mode, only entries that are of type STATIC_BINARY are selected, ignoring the ones that are installed at the remote site. 
                    </listitem>
                  </varlistentry>

                  <varlistentry>
                    <term>Submit</term>

                    <listitem>
                       In this mode, only entries that are of type STATIC_BINARY and reside at the submit host ("site" local), are selected as sources for staging the executables to the remote execution sites. 
                    </listitem>
                  </varlistentry>
                </variablelist></para></entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.parser.dax.preserver.linebreaks<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 2.2.0
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> false</literallayout></entry>

              <entry>The DAX Parser normally does not preserve line breaks
              while parsing the CDATA section that appears in the arguments
              section of the job element in the DAX. On setting this to true,
              the DAX Parser preserves any line line breaks that appear in the
              CDATA section.</entry>
            </row>

            <row>
              <entry><literallayout><emphasis role="bold"><emphasis
                      role="bold">Property Key: </emphasis></emphasis>pegasus.parser.dax.data.dependencies<emphasis
                    role="bold"><emphasis role="bold">
Profile  Key: </emphasis></emphasis>N/A<emphasis role="bold">
Scope       :</emphasis> Properties
<emphasis role="bold">Since       :</emphasis> 4.4.0
<emphasis role="bold">Type        : </emphasis>Boolean
<emphasis role="bold">Default     :</emphasis> true</literallayout></entry>

              <entry>If this property is set to true, then the planner will
              automatically add edges between jobs in the DAX on the basis of
              exisitng data dependencies between jobs. For example, if a JobA
              generates an output file that is listed as input for JobB, then
              the planner will automatically add an edge between JobA and
              JobB.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </section>
</chapter>
