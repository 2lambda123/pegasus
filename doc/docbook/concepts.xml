<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="concepts">
  <title>Concepts</title>

  <section>
    <title>Abstract Workflow (DAX)</title>

    <section>
      <title>Introduction to DAXs</title>

      <para>Pegasus takes an abstract workflow in XML format called DAX as its
      fundamental input. Pegasus plans the abstract workflow provided by the
      DAX using the concrete information found the in the replica catalog
      (RC), site catalog (SC), and transformation catalog (TC). The concrete
      behavior is controlled by the configuration (properties). Pegasus
      refines the abstract workflow to create a number of concretely runnable
      jobs that can be executed in the Grid, clouds, locally or
      remotely.</para>

      <para>The DAX format is described by the XML schema instance document
      <ulink
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.xsd">dax-3.2.xsd</ulink>.
      A local copy of the schema definition is provided in the
      <quote>etc</quote> directory. The documentation of the schema and its
      elements can be found in <ulink
      url="http://pegasus.isi.edu/wms/docs/schemas/dax-3.2/dax-3.2.html">dax-3.2.html</ulink>.
      The example below shows a workflow we call the "black diamond" for
      historical reasons and due to its shape. This simple workflow
      incorporates some of the elementary graph structures you will deal with
      in your own workflows:</para>

      <itemizedlist>
        <listitem>
          <para><emphasis>fan-out</emphasis>, <emphasis>scatter</emphasis>,
          and <emphasis>diverge</emphasis> all describe the fact that multiple
          siblings are dependent on a fewer parents.</para>

          <para>The example shows how the <emphasis>findrange</emphasis> nodes
          depend on the <emphasis>preprocess</emphasis> node.</para>
        </listitem>

        <listitem>
          <para><emphasis>fan-in</emphasis>, <emphasis>gather</emphasis>,
          <emphasis>join</emphasis>, and <emphasis>converge</emphasis>
          describe how multiple siblings are merged into fewer dependent child
          nodes.</para>

          <para>The example shows how the <emphasis>analyze</emphasis> node
          depends on both <emphasis>findrange</emphasis> nodes.</para>
        </listitem>
      </itemizedlist>

      <itemizedlist>
        <listitem>
          <para><emphasis>serial execution</emphasis> implies that nodes are
          dependent on one another, like pearls on a string.</para>
        </listitem>

        <listitem>
          <para><emphasis>parallel execution</emphasis> implies that nodes can
          be executed in parallel, as shown by the
          <emphasis>findrange</emphasis> nodes in the example.</para>

          <para>Note that even though it is possible to execute these nodes in
          parallel, planning constraints may limit the amount of parallelism
          achieved.</para>
        </listitem>
      </itemizedlist>

      <para><figure>
          <title>Black Diamond Dax</title>

          <mediaobject>
            <imageobject>
              <imagedata align="center" fileref="images/concepts-diamond.jpg"
                         valign="middle" />
            </imageobject>
          </mediaobject>
        </figure></para>

      <para>The example diamond workflow consits of four nodes representing
      jobs, and are linked by six files.</para>

      <itemizedlist>
        <listitem>
          <para>If you follow the arrows, you realize that one arrow end in
          file <filename>f.d</filename>, but not arrows are leaving it. This
          mean that <filename>f.d</filename> is a leaf file. It is a product
          or output of this workflow. Output files can be collected at a
          location.</para>
        </listitem>

        <listitem>
          <para>If you follow the arrows, you also realize that only one arrow
          comes from file <filename>f.a</filename>, but not arrows are leading
          to it. This means that <filename>f.a</filename> is a required input
          file to the workflow. Its location must be registered with the
          replica catalog in order for Pegasus to find it and integrate it
          into the workflow.</para>
        </listitem>

        <listitem>
          <para>The remaining files all have arrows leading to them and
          originating from them. These files are products of some job steps
          (arrows leading to them), and consumed by other job steps (arrows
          leading out of them). Often, these files represent intermediary
          results that can be cleaned.</para>
        </listitem>
      </itemizedlist>

      <para>There are two main ways of generating DAX's</para>

      <orderedlist>
        <listitem>
          <para>Using a DAX generating API in Java, Perl or Python.</para>

          <para>This option is what we recommend.</para>
        </listitem>

        <listitem>
          <para>Generating XML directly from your script.</para>

          <para>This option should only be considered by advanced users who
          can also read XML schema definitions. </para>
        </listitem>
      </orderedlist>

      <para>One example for a DAX representing the example workflow can look
      like the following:</para>

      <programlisting>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!-- generated: 2010-11-22T22:55:08Z --&gt;
&lt;adag xmlns="http://pegasus.isi.edu/schema/DAX" 
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
      xsi:schemaLocation="http://pegasus.isi.edu/schema/DAX http://pegasus.isi.edu/schema/dax-3.2.xsd" 
      version="3.2" name="diamond" index="0" count="1"&gt;
  &lt;!-- part 2: definition of all jobs (at least one) --&gt;
  &lt;job namespace="diamond" name="preprocess" version="2.0" id="ID000001"&gt;
    &lt;argument&gt;-a preprocess -T60 -i &lt;file name="f.a" /&gt; -o &lt;file name="f.b1" /&gt; &lt;file name="f.b2" /&gt;&lt;/argument&gt;
    &lt;uses name="f.b2" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.b1" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.a" link="input" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="findrange" version="2.0" id="ID000002"&gt;
    &lt;argument&gt;-a findrange -T60 -i &lt;file name="f.b1" /&gt; -o &lt;file name="f.c1" /&gt;&lt;/argument&gt;
    &lt;uses name="f.b1" link="input" register="false" transfer="false" /&gt;
    &lt;uses name="f.c1" link="output" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="findrange" version="2.0" id="ID000003"&gt;
    &lt;argument&gt;-a findrange -T60 -i &lt;file name="f.b2" /&gt; -o &lt;file name="f.c2" /&gt;&lt;/argument&gt;
    &lt;uses name="f.c2" link="output" register="false" transfer="false" /&gt;
    &lt;uses name="f.b2" link="input" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;job namespace="diamond" name="analyze" version="2.0" id="ID000004"&gt;
    &lt;argument&gt;-a analyze -T60 -i &lt;file name="f.c1" /&gt; &lt;file name="f.c2" /&gt; -o &lt;file name="f.d" /&gt;&lt;/argument&gt;
    &lt;uses name="f.c2" link="input" register="false" transfer="false" /&gt;
    &lt;uses name="f.d" link="output" register="false" transfer="true" /&gt;
    &lt;uses name="f.c1" link="input" register="false" transfer="false" /&gt;
  &lt;/job&gt;
  &lt;!-- part 3: list of control-flow dependencies --&gt;
  &lt;child ref="ID000002"&gt;
    &lt;parent ref="ID000001" /&gt;
  &lt;/child&gt;
  &lt;child ref="ID000003"&gt;
    &lt;parent ref="ID000001" /&gt;
  &lt;/child&gt;
  &lt;child ref="ID000004"&gt;
    &lt;parent ref="ID000002" /&gt;
    &lt;parent ref="ID000003" /&gt;
  &lt;/child&gt;
&lt;/adag&gt;</programlisting>

      <para>The example workflow representation in form of a DAX requires
      external catalogs, like a transformation catalog (TC) to resolve the
      logical job names like diamond::preprocess:2.0, and a replica catalog
      (RC) to resolve the input file <filename>f.a</filename>. The above
      workflow defines the four jobs just like the example picture, and the
      files that flow between the jobs. The intermediary files are neither
      registered nor staged out, and can be considered transient. Only the
      final result file <filename>f.d</filename> is staged out.</para>

      <para>The decision between not staging nor remembering intermediary
      files, and staging them, is a balance act of your faith into the
      workflow. If it is a very large workflow that is likely to fail at some
      point due to a site problem, or even a transient problem, you may want
      to be able to restart your workflow without losing too much work. If
      intermediary files were saved and registered, you can reduce the number
      of repeated, previously computed tasks, especially when
      re-planning.</para>
    </section>

    <section>
      <title>Workflow Gallery</title>

      <para>You can view a bunch of DAX's from various applications in our
      Workflow Gallery at [INSERT PROPER LINK HERE].</para>
    </section>
  </section>

  <section>
    <title>Executable Workflow (DAG)</title>

    <para>When you take the workflow DAX above, and plan it for a remote grid
    execution without clean-up nodes, the following concrete workflow is
    built:</para>

    <para><figure>
        <title>Black Diamond DAG</title>

        <mediaobject>
          <imageobject>
            <imagedata align="center"
                       fileref="images/concepts-diamond-dag.png"
                       valign="middle" />
          </imageobject>
        </mediaobject>
      </figure></para>

    <para>Planning augments the original abstract workflow with ancillary
    tasks to facility the proper execution of the workflow. These tasks
    include:</para>

    <itemizedlist>
      <listitem>
        <para>the creation of remote working directories. These directories
        typically have name that seeks to avoid conflicts with other
        simultaneously running similar workflows.</para>
      </listitem>

      <listitem>
        <para>the stage-in of input files before any task that requires these
        files. Any file consumed by a task needs to be staged to the task, if
        it does not already exist on that site. </para>
      </listitem>

      <listitem>
        <para>the original DAX job is concretized into a compute task in the
        DAG.</para>
      </listitem>

      <listitem>
        <para>the stage-out of data products to a collecting site. Data
        products with their <emphasis>transfer</emphasis> flag set to
        <literal>false</literal> will not be staged to the output site.
        However, they may still be eligible for staging to other, dependent
        tasks. </para>
      </listitem>

      <listitem>
        <para>the registration of data products in a replica catalog. Data
        products with their <emphasis>register</emphasis> flag set to
        <literal>false</literal> will not be registered. </para>
      </listitem>

      <listitem>
        <para>the clean-up of transient files and working directories. These
        steps can be omitted with the <command>--no-cleanup</command> option
        to the planner. </para>
      </listitem>
    </itemizedlist>

    <para>The DAG will be found in file <filename>diamond-0.dag</filename>,
    constructed from the <emphasis>name</emphasis> and
    <emphasis>index</emphasis> attributes found in the root element of the DAX
    file.</para>

    <programlisting>######################################################################
# PEGASUS WMS GENERATED DAG FILE
# DAG diamond
# Index = 0, Count = 1
######################################################################

JOB create_dir_diamond_0_hpcc create_dir_diamond_0_hpcc.sub
SCRIPT POST create_dir_diamond_0_hpcc /opt/pegasus/default/bin/pegasus-exitcode create_dir_diamond_0_hpcc.out

JOB stage_in_local_hpcc_0 stage_in_local_hpcc_0.sub
SCRIPT POST stage_in_local_hpcc_0 /opt/pegasus/default/bin/pegasus-exitcode stage_in_local_hpcc_0.out

JOB preprocess_ID000001 preprocess_ID000001.sub
SCRIPT POST preprocess_ID000001 /opt/pegasus/default/bin/pegasus-exitcode preprocess_ID000001.out

JOB findrange_ID000002 findrange_ID000002.sub
SCRIPT POST findrange_ID000002 /opt/pegasus/default/bin/pegasus-exitcode findrange_ID000002.out

JOB findrange_ID000003 findrange_ID000003.sub
SCRIPT POST findrange_ID000003 /opt/pegasus/default/bin/pegasus-exitcode findrange_ID000003.out

JOB analyze_ID000004 analyze_ID000004.sub
SCRIPT POST analyze_ID000004 /opt/pegasus/default/bin/pegasus-exitcode analyze_ID000004.out

JOB stage_out_local_hpcc_2_0 stage_out_local_hpcc_2_0.sub
SCRIPT POST stage_out_local_hpcc_2_0 /opt/pegasus/default/bin/pegasus-exitcode stage_out_local_hpcc_2_0.out

PARENT findrange_ID000002 CHILD analyze_ID000004
PARENT findrange_ID000003 CHILD analyze_ID000004
PARENT preprocess_ID000001 CHILD findrange_ID000002
PARENT preprocess_ID000001 CHILD findrange_ID000003
PARENT analyze_ID000004 CHILD stage_out_local_hpcc_2_0
PARENT stage_in_local_hpcc_0 CHILD preprocess_ID000001
PARENT create_dir_diamond_0_hpcc CHILD findrange_ID000002
PARENT create_dir_diamond_0_hpcc CHILD findrange_ID000003
PARENT create_dir_diamond_0_hpcc CHILD preprocess_ID000001
PARENT create_dir_diamond_0_hpcc CHILD analyze_ID000004
PARENT create_dir_diamond_0_hpcc CHILD stage_in_local_hpcc_0
######################################################################
# End of DAG
######################################################################
</programlisting>

    <para>The DAG file declares all jobs and links them to a Condor submit
    file that describes the planned, concrete job. In the same directory as
    the DAG file are all Condor submit files for the jobs from the picture
    plus a number of additional helper files. </para>

    <para>The various instructions that can be put into a DAG file are
    described in <ulink
    url="http://www.cs.wisc.edu/condor/manual/v7.5/2_10DAGMan_Applications.html">Condor's
    DAGMAN documentation</ulink>.</para>
  </section>

  <section>
    <title>Execution Environment</title>

    <para>...</para>
  </section>

  <section>
    <title>Pegasus Workflow Job States and Delays</title>

    <para>...</para>
  </section>
</chapter>
